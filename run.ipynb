{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from exp.exp_main import Exp_Main\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--random_seed RANDOM_SEED] --is_training\n",
      "                             IS_TRAINING --model_id MODEL_ID --model MODEL\n",
      "                             --data DATA [--root_path ROOT_PATH]\n",
      "                             [--data_path DATA_PATH] [--features FEATURES]\n",
      "                             [--target TARGET] [--freq FREQ]\n",
      "                             [--checkpoints CHECKPOINTS] [--seq_len SEQ_LEN]\n",
      "                             [--label_len LABEL_LEN] [--pred_len PRED_LEN]\n",
      "                             [--fc_dropout FC_DROPOUT]\n",
      "                             [--head_dropout HEAD_DROPOUT]\n",
      "                             [--patch_len PATCH_LEN] [--stride STRIDE]\n",
      "                             [--padding_patch PADDING_PATCH] [--revin REVIN]\n",
      "                             [--affine AFFINE] [--subtract_last SUBTRACT_LAST]\n",
      "                             [--decomposition DECOMPOSITION]\n",
      "                             [--kernel_size KERNEL_SIZE]\n",
      "                             [--individual INDIVIDUAL]\n",
      "                             [--embed_type EMBED_TYPE] [--enc_in ENC_IN]\n",
      "                             [--dec_in DEC_IN] [--c_out C_OUT]\n",
      "                             [--d_model D_MODEL] [--n_heads N_HEADS]\n",
      "                             [--e_layers E_LAYERS] [--d_layers D_LAYERS]\n",
      "                             [--d_ff D_FF] [--moving_avg MOVING_AVG]\n",
      "                             [--factor FACTOR] [--distil] [--dropout DROPOUT]\n",
      "                             [--embed EMBED] [--activation ACTIVATION]\n",
      "                             [--output_attention] [--do_predict]\n",
      "                             [--num_workers NUM_WORKERS] [--itr ITR]\n",
      "                             [--train_epochs TRAIN_EPOCHS]\n",
      "                             [--batch_size BATCH_SIZE] [--patience PATIENCE]\n",
      "                             [--learning_rate LEARNING_RATE] [--des DES]\n",
      "                             [--loss LOSS] [--lradj LRADJ]\n",
      "                             [--pct_start PCT_START] [--use_amp]\n",
      "                             [--use_gpu USE_GPU] [--gpu GPU] [--use_multi_gpu]\n",
      "                             [--devices DEVICES] [--test_flop]\n",
      "ipykernel_launcher.py: error: ambiguous option: --f=c:\\Users\\whdgu\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-18464J4cwa0kpqdEY.json could match --features, --freq, --fc_dropout, --factor\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
    "\n",
    "    # random seed\n",
    "    parser.add_argument('--random_seed', type=int, default=2021, help='random seed')\n",
    "\n",
    "    # basic config\n",
    "    parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
    "    parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')\n",
    "    parser.add_argument('--model', type=str, required=True, default='Autoformer',\n",
    "                        help='model name, options: [Autoformer, Informer, Transformer]')\n",
    "\n",
    "    # data loader\n",
    "    parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')\n",
    "    parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')\n",
    "    parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
    "    parser.add_argument('--features', type=str, default='M',\n",
    "                        help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "    parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "    parser.add_argument('--freq', type=str, default='h',\n",
    "                        help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "    parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "    # forecasting task\n",
    "    parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "    parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
    "    parser.add_argument('--pred_len', type=int, default=96, help='prediction sequence length')\n",
    "\n",
    "\n",
    "    # DLinear\n",
    "    #parser.add_argument('--individual', action='store_true', default=False, help='DLinear: a linear layer for each variate(channel) individually')\n",
    "\n",
    "    # PatchTST\n",
    "    parser.add_argument('--fc_dropout', type=float, default=0.05, help='fully connected dropout')\n",
    "    parser.add_argument('--head_dropout', type=float, default=0.0, help='head dropout')\n",
    "    parser.add_argument('--patch_len', type=int, default=16, help='patch length')\n",
    "    parser.add_argument('--stride', type=int, default=8, help='stride')\n",
    "    parser.add_argument('--padding_patch', default='end', help='None: None; end: padding on the end')\n",
    "    parser.add_argument('--revin', type=int, default=1, help='RevIN; True 1 False 0')\n",
    "    parser.add_argument('--affine', type=int, default=0, help='RevIN-affine; True 1 False 0')\n",
    "    parser.add_argument('--subtract_last', type=int, default=0, help='0: subtract mean; 1: subtract last')\n",
    "    parser.add_argument('--decomposition', type=int, default=0, help='decomposition; True 1 False 0')\n",
    "    parser.add_argument('--kernel_size', type=int, default=25, help='decomposition-kernel')\n",
    "    parser.add_argument('--individual', type=int, default=0, help='individual head; True 1 False 0')\n",
    "\n",
    "    # Formers \n",
    "    parser.add_argument('--embed_type', type=int, default=0, help='0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding')\n",
    "    parser.add_argument('--enc_in', type=int, default=7, help='encoder input size') # DLinear with --individual, use this hyperparameter as the number of channels\n",
    "    parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
    "    parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "    parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "    parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "    parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "    parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "    parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "    parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "    parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "    parser.add_argument('--distil', action='store_false',\n",
    "                        help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                        default=True)\n",
    "    parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "    parser.add_argument('--embed', type=str, default='timeF',\n",
    "                        help='time features encoding, options:[timeF, fixed, learned]')\n",
    "    parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "    parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "    parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "\n",
    "    # optimization\n",
    "    parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
    "    parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
    "    parser.add_argument('--train_epochs', type=int, default=100, help='train epochs')\n",
    "    parser.add_argument('--batch_size', type=int, default=128, help='batch size of train input data')\n",
    "    parser.add_argument('--patience', type=int, default=100, help='early stopping patience')\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "    parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "    parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
    "    parser.add_argument('--lradj', type=str, default='type3', help='adjust learning rate')\n",
    "    parser.add_argument('--pct_start', type=float, default=0.3, help='pct_start')\n",
    "    parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "    # GPU\n",
    "    parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "    parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "    parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "    parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
    "    parser.add_argument('--test_flop', action='store_true', default=False, help='See utils/tools for usage')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # random seed\n",
    "    fix_seed = args.random_seed\n",
    "    random.seed(fix_seed)\n",
    "    torch.manual_seed(fix_seed)\n",
    "    np.random.seed(fix_seed)\n",
    "\n",
    "\n",
    "    args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "    if args.use_gpu and args.use_multi_gpu:\n",
    "        args.dvices = args.devices.replace(' ', '')\n",
    "        device_ids = args.devices.split(',')\n",
    "        args.device_ids = [int(id_) for id_ in device_ids]\n",
    "        args.gpu = args.device_ids[0]\n",
    "\n",
    "    print('Args in experiment:')\n",
    "    print(args)\n",
    "\n",
    "    Exp = Exp_Main\n",
    "\n",
    "    if args.is_training:\n",
    "        for ii in range(args.itr):\n",
    "            # setting record of experiments\n",
    "            setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "                args.model_id,\n",
    "                args.model,\n",
    "                args.data,\n",
    "                args.features,\n",
    "                args.seq_len,\n",
    "                args.label_len,\n",
    "                args.pred_len,\n",
    "                args.d_model,\n",
    "                args.n_heads,\n",
    "                args.e_layers,\n",
    "                args.d_layers,\n",
    "                args.d_ff,\n",
    "                args.factor,\n",
    "                args.embed,\n",
    "                args.distil,\n",
    "                args.des,ii)\n",
    "\n",
    "            exp = Exp(args)  # set experiments\n",
    "            print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "            exp.train(setting)\n",
    "\n",
    "            print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            exp.test(setting)\n",
    "\n",
    "            if args.do_predict:\n",
    "                print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "                exp.predict(setting, True)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "    else:\n",
    "        ii = 0\n",
    "        setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n",
    "                                                                                                    args.model,\n",
    "                                                                                                    args.data,\n",
    "                                                                                                    args.features,\n",
    "                                                                                                    args.seq_len,\n",
    "                                                                                                    args.label_len,\n",
    "                                                                                                    args.pred_len,\n",
    "                                                                                                    args.d_model,\n",
    "                                                                                                    args.n_heads,\n",
    "                                                                                                    args.e_layers,\n",
    "                                                                                                    args.d_layers,\n",
    "                                                                                                    args.d_ff,\n",
    "                                                                                                    args.factor,\n",
    "                                                                                                    args.embed,\n",
    "                                                                                                    args.distil,\n",
    "                                                                                                    args.des, ii)\n",
    "\n",
    "        exp = Exp(args)  # set experiments\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting, test=1)\n",
    "        torch.cuda.empty_cache()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
