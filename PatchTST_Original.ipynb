{"cells":[{"cell_type":"markdown","metadata":{},"source":["### 전체 실험 결과 표"]},{"cell_type":"markdown","metadata":{},"source":["![image](./Experiment_image.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NYRX3cQb-_T"},"outputs":[],"source":["import argparse\n","import os\n","import torch\n","from exp.exp_main import Exp_Main\n","import random\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"8HtGQ4jncI7P"},"source":["### ETTh1 데이터셋 실험"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1701016409459,"user":{"displayName":"공자","userId":"09701607017816361852"},"user_tz":-540},"id":"5XqpOCPhuWEi","outputId":"5cec6349-8c3b-44d9-9ad7-4613186716d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","<__main__.Args object at 0x7f5eb3066e60>\n"]}],"source":["arg_seq_len=336\n","arg_pred_len = 96\n","\n","model_name='PatchTST'\n","\n","root_path_name='./dataset/'\n","data_path_name='ETTh1.csv'\n","model_id_name='ETTh1'\n","data_name='ETTh1'\n","\n","random_seed=2021\n","\n","class Args:\n","    random_seed = 2021\n","\n","    is_training = 1\n","    model_id = model_id_name\n","    model = model_name\n","\n","    data = data_name\n","    root_path = root_path_name\n","    data_path = data_path_name\n","    features = 'M'\n","    target = 'OT'\n","    freq = 'h'\n","    checkpoints = './checkpoints/'\n","\n","    seq_len = arg_seq_len\n","    fc_dropout= 0.3\n","    head_dropout = 0.0\n","    patch_len = 16\n","    stride = 8\n","    decomposition = 0\n","    enc_in = 7\n","    d_model = 16\n","    n_heads = 4\n","    e_layers = 3\n","    d_ff = 128\n","    dropout = 0.3\n","    itr = 1 # 학습 횟수\n","    train_epochs = 100\n","    batch_size = 128\n","    learning_rate = 0.0001\n","    des = 'Exp'\n","    use_gpu = True\n","    gpu = 0\n","    use_multi_gpu = False\n","    devices = '0'\n","    label_len = 48\n","    d_layers = 1\n","    factor = 1\n","    distil = True\n","    embed = 'timeF'\n","    individual = 0\n","    pred_len = arg_pred_len\n","    padding_patch = 'end'\n","    revin = 1\n","    affine = 0\n","    subtract_last = 0\n","    kernel_size = 25\n","    embed_type = 0\n","    dec_in = 7\n","    c_out = 7\n","    moving_avg = 25\n","    activation = 'gelu'\n","    output_attention = False\n","    do_predict = True\n","    patience = 100\n","    num_workers = 10 # DataLoader에 사용할 subprocess 개수\n","    loss = 'MSE'\n","    lradj = 'type1'\n","    pct_start = 0.3\n","    use_amp = False\n","    test_flop = False\n","\n","args = Args();\n","\n","# random seed\n","fix_seed = args.random_seed\n","random.seed(fix_seed)\n","torch.manual_seed(fix_seed)\n","np.random.seed(fix_seed)\n","\n","args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.dvices = args.devices.replace(' ', '')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1519930,"status":"ok","timestamp":1701017931387,"user":{"displayName":"공자","userId":"09701607017816361852"},"user_tz":-540},"id":"OFd61ZJuuH0W","outputId":"2a5ccbc7-148a-4834-e8c5-abf27092516a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current Prediction Length :  96\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  0\n","Exp_Main init!\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl96_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 8209\n","val 2785\n","test 2785\n","Epoch: 1 cost time: 1.7728190422058105\n","Epoch: 1, Steps: 64 | Train Loss: 0.7404664 Vali Loss: 1.4723815 Test Loss: 0.8135934\n","Validation loss decreased (inf --> 1.472381).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 1.8551592826843262\n","Epoch: 2, Steps: 64 | Train Loss: 0.5739448 Vali Loss: 0.8930840 Test Loss: 0.4752970\n","Validation loss decreased (1.472381 --> 0.893084).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 1.678483247756958\n","Epoch: 3, Steps: 64 | Train Loss: 0.4709831 Vali Loss: 0.8122665 Test Loss: 0.4430701\n","Validation loss decreased (0.893084 --> 0.812266).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 1.7093234062194824\n","Epoch: 4, Steps: 64 | Train Loss: 0.4497084 Vali Loss: 0.7924042 Test Loss: 0.4346228\n","Validation loss decreased (0.812266 --> 0.792404).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 1.6637225151062012\n","Epoch: 5, Steps: 64 | Train Loss: 0.4412201 Vali Loss: 0.7799913 Test Loss: 0.4309975\n","Validation loss decreased (0.792404 --> 0.779991).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 1.813016653060913\n","Epoch: 6, Steps: 64 | Train Loss: 0.4374674 Vali Loss: 0.7744005 Test Loss: 0.4292551\n","Validation loss decreased (0.779991 --> 0.774401).  Saving model ...\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 1.7560269832611084\n","Epoch: 7, Steps: 64 | Train Loss: 0.4358634 Vali Loss: 0.7725437 Test Loss: 0.4283787\n","Validation loss decreased (0.774401 --> 0.772544).  Saving model ...\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 1.665905475616455\n","Epoch: 8, Steps: 64 | Train Loss: 0.4345791 Vali Loss: 0.7704663 Test Loss: 0.4279162\n","Validation loss decreased (0.772544 --> 0.770466).  Saving model ...\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 1.6462714672088623\n","Epoch: 9, Steps: 64 | Train Loss: 0.4343358 Vali Loss: 0.7701163 Test Loss: 0.4277495\n","Validation loss decreased (0.770466 --> 0.770116).  Saving model ...\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 1.7236073017120361\n","Epoch: 10, Steps: 64 | Train Loss: 0.4339545 Vali Loss: 0.7679031 Test Loss: 0.4276408\n","Validation loss decreased (0.770116 --> 0.767903).  Saving model ...\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 1.8002736568450928\n","Epoch: 11, Steps: 64 | Train Loss: 0.4338405 Vali Loss: 0.7725194 Test Loss: 0.4276307\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 1.6487762928009033\n","Epoch: 12, Steps: 64 | Train Loss: 0.4338569 Vali Loss: 0.7625846 Test Loss: 0.4274939\n","Validation loss decreased (0.767903 --> 0.762585).  Saving model ...\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 1.6681957244873047\n","Epoch: 13, Steps: 64 | Train Loss: 0.4335969 Vali Loss: 0.7723597 Test Loss: 0.4275071\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 1.7243192195892334\n","Epoch: 14, Steps: 64 | Train Loss: 0.4332980 Vali Loss: 0.7730165 Test Loss: 0.4275516\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 1.800990104675293\n","Epoch: 15, Steps: 64 | Train Loss: 0.4335456 Vali Loss: 0.7699968 Test Loss: 0.4274113\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 1.6694715023040771\n","Epoch: 16, Steps: 64 | Train Loss: 0.4334796 Vali Loss: 0.7690060 Test Loss: 0.4275263\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 1.6428589820861816\n","Epoch: 17, Steps: 64 | Train Loss: 0.4333885 Vali Loss: 0.7714328 Test Loss: 0.4274641\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 1.6992530822753906\n","Epoch: 18, Steps: 64 | Train Loss: 0.4333468 Vali Loss: 0.7676719 Test Loss: 0.4274859\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 1.8081309795379639\n","Epoch: 19, Steps: 64 | Train Loss: 0.4331761 Vali Loss: 0.7745031 Test Loss: 0.4274478\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 1.802220106124878\n","Epoch: 20, Steps: 64 | Train Loss: 0.4338132 Vali Loss: 0.7716935 Test Loss: 0.4275024\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 1.6775023937225342\n","Epoch: 21, Steps: 64 | Train Loss: 0.4337759 Vali Loss: 0.7757373 Test Loss: 0.4274895\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 1.6643788814544678\n","Epoch: 22, Steps: 64 | Train Loss: 0.4337533 Vali Loss: 0.7713112 Test Loss: 0.4274781\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 1.7519121170043945\n","Epoch: 23, Steps: 64 | Train Loss: 0.4336263 Vali Loss: 0.7720426 Test Loss: 0.4274443\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 1.8755018711090088\n","Epoch: 24, Steps: 64 | Train Loss: 0.4335779 Vali Loss: 0.7736568 Test Loss: 0.4274399\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 1.6765005588531494\n","Epoch: 25, Steps: 64 | Train Loss: 0.4334212 Vali Loss: 0.7674748 Test Loss: 0.4274549\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 1.6776604652404785\n","Epoch: 26, Steps: 64 | Train Loss: 0.4336899 Vali Loss: 0.7708247 Test Loss: 0.4274303\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 1.7651102542877197\n","Epoch: 27, Steps: 64 | Train Loss: 0.4336119 Vali Loss: 0.7723203 Test Loss: 0.4275188\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 1.7752535343170166\n","Epoch: 28, Steps: 64 | Train Loss: 0.4332996 Vali Loss: 0.7678254 Test Loss: 0.4275347\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 1.7140686511993408\n","Epoch: 29, Steps: 64 | Train Loss: 0.4337267 Vali Loss: 0.7734098 Test Loss: 0.4275000\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 1.6917564868927002\n","Epoch: 30, Steps: 64 | Train Loss: 0.4331806 Vali Loss: 0.7728082 Test Loss: 0.4274619\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 1.7363440990447998\n","Epoch: 31, Steps: 64 | Train Loss: 0.4331128 Vali Loss: 0.7691496 Test Loss: 0.4275133\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 1.8490421772003174\n","Epoch: 32, Steps: 64 | Train Loss: 0.4335914 Vali Loss: 0.7701881 Test Loss: 0.4274970\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 1.7830214500427246\n","Epoch: 33, Steps: 64 | Train Loss: 0.4332063 Vali Loss: 0.7733628 Test Loss: 0.4274874\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 1.7124521732330322\n","Epoch: 34, Steps: 64 | Train Loss: 0.4339639 Vali Loss: 0.7694756 Test Loss: 0.4275338\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 1.8087782859802246\n","Epoch: 35, Steps: 64 | Train Loss: 0.4331847 Vali Loss: 0.7736553 Test Loss: 0.4274424\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 1.7365434169769287\n","Epoch: 36, Steps: 64 | Train Loss: 0.4333968 Vali Loss: 0.7711733 Test Loss: 0.4274162\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 1.826636791229248\n","Epoch: 37, Steps: 64 | Train Loss: 0.4334001 Vali Loss: 0.7727684 Test Loss: 0.4275104\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 1.6955249309539795\n","Epoch: 38, Steps: 64 | Train Loss: 0.4339023 Vali Loss: 0.7680808 Test Loss: 0.4274801\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 1.6494789123535156\n","Epoch: 39, Steps: 64 | Train Loss: 0.4335066 Vali Loss: 0.7717937 Test Loss: 0.4274876\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 1.7163283824920654\n","Epoch: 40, Steps: 64 | Train Loss: 0.4333133 Vali Loss: 0.7727219 Test Loss: 0.4274903\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 1.8257901668548584\n","Epoch: 41, Steps: 64 | Train Loss: 0.4340060 Vali Loss: 0.7713007 Test Loss: 0.4275028\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 1.6847376823425293\n","Epoch: 42, Steps: 64 | Train Loss: 0.4338701 Vali Loss: 0.7708579 Test Loss: 0.4274307\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 1.7102937698364258\n","Epoch: 43, Steps: 64 | Train Loss: 0.4331340 Vali Loss: 0.7730308 Test Loss: 0.4275245\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 1.6914467811584473\n","Epoch: 44, Steps: 64 | Train Loss: 0.4338967 Vali Loss: 0.7702073 Test Loss: 0.4274864\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 1.860914707183838\n","Epoch: 45, Steps: 64 | Train Loss: 0.4335327 Vali Loss: 0.7730982 Test Loss: 0.4274787\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 1.783665418624878\n","Epoch: 46, Steps: 64 | Train Loss: 0.4335327 Vali Loss: 0.7684831 Test Loss: 0.4275080\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 1.7427186965942383\n","Epoch: 47, Steps: 64 | Train Loss: 0.4333240 Vali Loss: 0.7721401 Test Loss: 0.4274700\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 1.6999213695526123\n","Epoch: 48, Steps: 64 | Train Loss: 0.4336911 Vali Loss: 0.7714093 Test Loss: 0.4274753\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 1.7967805862426758\n","Epoch: 49, Steps: 64 | Train Loss: 0.4332709 Vali Loss: 0.7723151 Test Loss: 0.4274839\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 1.7664082050323486\n","Epoch: 50, Steps: 64 | Train Loss: 0.4337011 Vali Loss: 0.7682405 Test Loss: 0.4275199\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 1.6613333225250244\n","Epoch: 51, Steps: 64 | Train Loss: 0.4338951 Vali Loss: 0.7690644 Test Loss: 0.4274307\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 1.7208726406097412\n","Epoch: 52, Steps: 64 | Train Loss: 0.4338503 Vali Loss: 0.7725064 Test Loss: 0.4274830\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 1.7841815948486328\n","Epoch: 53, Steps: 64 | Train Loss: 0.4335715 Vali Loss: 0.7678323 Test Loss: 0.4274869\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 1.9153144359588623\n","Epoch: 54, Steps: 64 | Train Loss: 0.4331790 Vali Loss: 0.7683228 Test Loss: 0.4275450\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 2.035754442214966\n","Epoch: 55, Steps: 64 | Train Loss: 0.4338131 Vali Loss: 0.7741051 Test Loss: 0.4274508\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 1.73972487449646\n","Epoch: 56, Steps: 64 | Train Loss: 0.4335604 Vali Loss: 0.7695713 Test Loss: 0.4275473\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 1.7091174125671387\n","Epoch: 57, Steps: 64 | Train Loss: 0.4335868 Vali Loss: 0.7689002 Test Loss: 0.4274749\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 1.8299095630645752\n","Epoch: 58, Steps: 64 | Train Loss: 0.4337097 Vali Loss: 0.7711461 Test Loss: 0.4274167\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 1.737983226776123\n","Epoch: 59, Steps: 64 | Train Loss: 0.4335725 Vali Loss: 0.7722667 Test Loss: 0.4275607\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 1.7538390159606934\n","Epoch: 60, Steps: 64 | Train Loss: 0.4335927 Vali Loss: 0.7693235 Test Loss: 0.4274783\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 1.722811222076416\n","Epoch: 61, Steps: 64 | Train Loss: 0.4338506 Vali Loss: 0.7736061 Test Loss: 0.4274368\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 1.7978975772857666\n","Epoch: 62, Steps: 64 | Train Loss: 0.4334591 Vali Loss: 0.7712919 Test Loss: 0.4274042\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 1.6611196994781494\n","Epoch: 63, Steps: 64 | Train Loss: 0.4334781 Vali Loss: 0.7730947 Test Loss: 0.4274659\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 1.7122931480407715\n","Epoch: 64, Steps: 64 | Train Loss: 0.4338082 Vali Loss: 0.7701188 Test Loss: 0.4274704\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 1.7684447765350342\n","Epoch: 65, Steps: 64 | Train Loss: 0.4338698 Vali Loss: 0.7679471 Test Loss: 0.4274786\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 1.8001859188079834\n","Epoch: 66, Steps: 64 | Train Loss: 0.4335894 Vali Loss: 0.7706289 Test Loss: 0.4275286\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 1.760148286819458\n","Epoch: 67, Steps: 64 | Train Loss: 0.4328272 Vali Loss: 0.7693551 Test Loss: 0.4274954\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 1.6653203964233398\n","Epoch: 68, Steps: 64 | Train Loss: 0.4333374 Vali Loss: 0.7730458 Test Loss: 0.4274781\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 1.6609442234039307\n","Epoch: 69, Steps: 64 | Train Loss: 0.4334466 Vali Loss: 0.7739550 Test Loss: 0.4275720\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 1.7570018768310547\n","Epoch: 70, Steps: 64 | Train Loss: 0.4332059 Vali Loss: 0.7728155 Test Loss: 0.4275190\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 1.7889423370361328\n","Epoch: 71, Steps: 64 | Train Loss: 0.4336232 Vali Loss: 0.7740195 Test Loss: 0.4274391\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 1.7935781478881836\n","Epoch: 72, Steps: 64 | Train Loss: 0.4334432 Vali Loss: 0.7722694 Test Loss: 0.4274593\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 1.7401349544525146\n","Epoch: 73, Steps: 64 | Train Loss: 0.4334562 Vali Loss: 0.7729231 Test Loss: 0.4274823\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 1.7268033027648926\n","Epoch: 74, Steps: 64 | Train Loss: 0.4333117 Vali Loss: 0.7734722 Test Loss: 0.4274746\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 1.9059643745422363\n","Epoch: 75, Steps: 64 | Train Loss: 0.4337272 Vali Loss: 0.7698746 Test Loss: 0.4274921\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 1.7813937664031982\n","Epoch: 76, Steps: 64 | Train Loss: 0.4332550 Vali Loss: 0.7718394 Test Loss: 0.4275156\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 1.7175445556640625\n","Epoch: 77, Steps: 64 | Train Loss: 0.4335832 Vali Loss: 0.7706323 Test Loss: 0.4274654\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 1.7704050540924072\n","Epoch: 78, Steps: 64 | Train Loss: 0.4337149 Vali Loss: 0.7691496 Test Loss: 0.4273553\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 1.856844186782837\n","Epoch: 79, Steps: 64 | Train Loss: 0.4338706 Vali Loss: 0.7713347 Test Loss: 0.4274499\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 1.744060754776001\n","Epoch: 80, Steps: 64 | Train Loss: 0.4337373 Vali Loss: 0.7709137 Test Loss: 0.4274920\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 1.714000940322876\n","Epoch: 81, Steps: 64 | Train Loss: 0.4334901 Vali Loss: 0.7715096 Test Loss: 0.4274817\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 1.7280454635620117\n","Epoch: 82, Steps: 64 | Train Loss: 0.4335454 Vali Loss: 0.7719472 Test Loss: 0.4275030\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 1.9010887145996094\n","Epoch: 83, Steps: 64 | Train Loss: 0.4333302 Vali Loss: 0.7695838 Test Loss: 0.4275196\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 1.789839744567871\n","Epoch: 84, Steps: 64 | Train Loss: 0.4333763 Vali Loss: 0.7748567 Test Loss: 0.4275443\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 1.6899263858795166\n","Epoch: 85, Steps: 64 | Train Loss: 0.4332577 Vali Loss: 0.7695796 Test Loss: 0.4274819\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 1.7072978019714355\n","Epoch: 86, Steps: 64 | Train Loss: 0.4333995 Vali Loss: 0.7712401 Test Loss: 0.4274877\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 1.8518412113189697\n","Epoch: 87, Steps: 64 | Train Loss: 0.4333360 Vali Loss: 0.7669348 Test Loss: 0.4274513\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 1.833665132522583\n","Epoch: 88, Steps: 64 | Train Loss: 0.4333943 Vali Loss: 0.7731569 Test Loss: 0.4274687\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 1.7203376293182373\n","Epoch: 89, Steps: 64 | Train Loss: 0.4334767 Vali Loss: 0.7701470 Test Loss: 0.4274808\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 1.7356464862823486\n","Epoch: 90, Steps: 64 | Train Loss: 0.4335164 Vali Loss: 0.7713711 Test Loss: 0.4275130\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 1.7590312957763672\n","Epoch: 91, Steps: 64 | Train Loss: 0.4338923 Vali Loss: 0.7700835 Test Loss: 0.4273961\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 1.8633508682250977\n","Epoch: 92, Steps: 64 | Train Loss: 0.4330203 Vali Loss: 0.7699101 Test Loss: 0.4274565\n","EarlyStopping counter: 80 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 1.687617540359497\n","Epoch: 93, Steps: 64 | Train Loss: 0.4334077 Vali Loss: 0.7719439 Test Loss: 0.4274908\n","EarlyStopping counter: 81 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 1.688159704208374\n","Epoch: 94, Steps: 64 | Train Loss: 0.4333823 Vali Loss: 0.7747266 Test Loss: 0.4275042\n","EarlyStopping counter: 82 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 1.6934356689453125\n","Epoch: 95, Steps: 64 | Train Loss: 0.4338845 Vali Loss: 0.7689112 Test Loss: 0.4274503\n","EarlyStopping counter: 83 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 1.881072998046875\n","Epoch: 96, Steps: 64 | Train Loss: 0.4331019 Vali Loss: 0.7695252 Test Loss: 0.4274580\n","EarlyStopping counter: 84 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 1.7180347442626953\n","Epoch: 97, Steps: 64 | Train Loss: 0.4335297 Vali Loss: 0.7702987 Test Loss: 0.4274718\n","EarlyStopping counter: 85 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 1.6623814105987549\n","Epoch: 98, Steps: 64 | Train Loss: 0.4334450 Vali Loss: 0.7704381 Test Loss: 0.4274763\n","EarlyStopping counter: 86 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 1.7894339561462402\n","Epoch: 99, Steps: 64 | Train Loss: 0.4337290 Vali Loss: 0.7703566 Test Loss: 0.4274656\n","EarlyStopping counter: 87 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 1.858112096786499\n","Epoch: 100, Steps: 64 | Train Loss: 0.4335194 Vali Loss: 0.7695910 Test Loss: 0.4274878\n","EarlyStopping counter: 88 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl96_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2785\n","mse:0.42749401926994324, mae:0.43664199113845825, rse:0.619983971118927\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl96_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  192\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  0\n","Exp_Main init!\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 8113\n","val 2689\n","test 2689\n","Epoch: 1 cost time: 1.7494068145751953\n","Epoch: 1, Steps: 63 | Train Loss: 0.7549401 Vali Loss: 1.5632818 Test Loss: 0.7854514\n","Validation loss decreased (inf --> 1.563282).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 1.7336630821228027\n","Epoch: 2, Steps: 63 | Train Loss: 0.6083873 Vali Loss: 1.0964661 Test Loss: 0.5115626\n","Validation loss decreased (1.563282 --> 1.096466).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 1.7738995552062988\n","Epoch: 3, Steps: 63 | Train Loss: 0.5156879 Vali Loss: 1.0314471 Test Loss: 0.4782634\n","Validation loss decreased (1.096466 --> 1.031447).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 1.8441696166992188\n","Epoch: 4, Steps: 63 | Train Loss: 0.4947718 Vali Loss: 1.0116481 Test Loss: 0.4689921\n","Validation loss decreased (1.031447 --> 1.011648).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 1.7445309162139893\n","Epoch: 5, Steps: 63 | Train Loss: 0.4870312 Vali Loss: 1.0031099 Test Loss: 0.4649547\n","Validation loss decreased (1.011648 --> 1.003110).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 1.7537603378295898\n","Epoch: 6, Steps: 63 | Train Loss: 0.4827539 Vali Loss: 0.9988587 Test Loss: 0.4630477\n","Validation loss decreased (1.003110 --> 0.998859).  Saving model ...\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 1.7756049633026123\n","Epoch: 7, Steps: 63 | Train Loss: 0.4810479 Vali Loss: 0.9967405 Test Loss: 0.4621657\n","Validation loss decreased (0.998859 --> 0.996741).  Saving model ...\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 1.833289384841919\n","Epoch: 8, Steps: 63 | Train Loss: 0.4803690 Vali Loss: 0.9958704 Test Loss: 0.4615915\n","Validation loss decreased (0.996741 --> 0.995870).  Saving model ...\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 1.693559169769287\n","Epoch: 9, Steps: 63 | Train Loss: 0.4794922 Vali Loss: 0.9958916 Test Loss: 0.4614006\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 1.7177362442016602\n","Epoch: 10, Steps: 63 | Train Loss: 0.4797063 Vali Loss: 0.9952469 Test Loss: 0.4612701\n","Validation loss decreased (0.995870 --> 0.995247).  Saving model ...\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 1.7178735733032227\n","Epoch: 11, Steps: 63 | Train Loss: 0.4791868 Vali Loss: 0.9954744 Test Loss: 0.4612120\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 1.8464739322662354\n","Epoch: 12, Steps: 63 | Train Loss: 0.4793298 Vali Loss: 0.9949816 Test Loss: 0.4611725\n","Validation loss decreased (0.995247 --> 0.994982).  Saving model ...\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 1.6965508460998535\n","Epoch: 13, Steps: 63 | Train Loss: 0.4793742 Vali Loss: 0.9953825 Test Loss: 0.4611738\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 1.6993377208709717\n","Epoch: 14, Steps: 63 | Train Loss: 0.4792415 Vali Loss: 0.9953694 Test Loss: 0.4611773\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 1.7066049575805664\n","Epoch: 15, Steps: 63 | Train Loss: 0.4794861 Vali Loss: 0.9949105 Test Loss: 0.4611683\n","Validation loss decreased (0.994982 --> 0.994910).  Saving model ...\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 1.8621017932891846\n","Epoch: 16, Steps: 63 | Train Loss: 0.4790557 Vali Loss: 0.9952737 Test Loss: 0.4611144\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 1.6746628284454346\n","Epoch: 17, Steps: 63 | Train Loss: 0.4792122 Vali Loss: 0.9952435 Test Loss: 0.4611707\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 1.679084062576294\n","Epoch: 18, Steps: 63 | Train Loss: 0.4794571 Vali Loss: 0.9952049 Test Loss: 0.4612131\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 1.7146551609039307\n","Epoch: 19, Steps: 63 | Train Loss: 0.4790981 Vali Loss: 0.9947427 Test Loss: 0.4611933\n","Validation loss decreased (0.994910 --> 0.994743).  Saving model ...\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 1.8791112899780273\n","Epoch: 20, Steps: 63 | Train Loss: 0.4792548 Vali Loss: 0.9954259 Test Loss: 0.4611201\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 1.7198021411895752\n","Epoch: 21, Steps: 63 | Train Loss: 0.4793011 Vali Loss: 0.9949136 Test Loss: 0.4611590\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 1.6874759197235107\n","Epoch: 22, Steps: 63 | Train Loss: 0.4790927 Vali Loss: 0.9949265 Test Loss: 0.4611017\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 1.6995875835418701\n","Epoch: 23, Steps: 63 | Train Loss: 0.4790427 Vali Loss: 0.9952122 Test Loss: 0.4611693\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 1.8414313793182373\n","Epoch: 24, Steps: 63 | Train Loss: 0.4797258 Vali Loss: 0.9953540 Test Loss: 0.4611626\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 1.854386329650879\n","Epoch: 25, Steps: 63 | Train Loss: 0.4790040 Vali Loss: 0.9954649 Test Loss: 0.4611726\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 1.678565263748169\n","Epoch: 26, Steps: 63 | Train Loss: 0.4792709 Vali Loss: 0.9947715 Test Loss: 0.4611619\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 1.7648413181304932\n","Epoch: 27, Steps: 63 | Train Loss: 0.4794319 Vali Loss: 0.9950978 Test Loss: 0.4611438\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 1.7213711738586426\n","Epoch: 28, Steps: 63 | Train Loss: 0.4790300 Vali Loss: 0.9954142 Test Loss: 0.4612181\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 1.8627636432647705\n","Epoch: 29, Steps: 63 | Train Loss: 0.4789563 Vali Loss: 0.9953701 Test Loss: 0.4611849\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 1.7131006717681885\n","Epoch: 30, Steps: 63 | Train Loss: 0.4790719 Vali Loss: 0.9949769 Test Loss: 0.4611662\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 1.788848638534546\n","Epoch: 31, Steps: 63 | Train Loss: 0.4792664 Vali Loss: 0.9951716 Test Loss: 0.4611186\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 1.7908365726470947\n","Epoch: 32, Steps: 63 | Train Loss: 0.4789238 Vali Loss: 0.9952151 Test Loss: 0.4611744\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 1.9102857112884521\n","Epoch: 33, Steps: 63 | Train Loss: 0.4792599 Vali Loss: 0.9948629 Test Loss: 0.4611499\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 1.7196168899536133\n","Epoch: 34, Steps: 63 | Train Loss: 0.4792817 Vali Loss: 0.9953508 Test Loss: 0.4611751\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 1.7337775230407715\n","Epoch: 35, Steps: 63 | Train Loss: 0.4795335 Vali Loss: 0.9949582 Test Loss: 0.4611524\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 1.8232827186584473\n","Epoch: 36, Steps: 63 | Train Loss: 0.4792754 Vali Loss: 0.9954221 Test Loss: 0.4611879\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 1.8771986961364746\n","Epoch: 37, Steps: 63 | Train Loss: 0.4790654 Vali Loss: 0.9951694 Test Loss: 0.4611957\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 1.7811431884765625\n","Epoch: 38, Steps: 63 | Train Loss: 0.4793355 Vali Loss: 0.9954450 Test Loss: 0.4610980\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 1.7489619255065918\n","Epoch: 39, Steps: 63 | Train Loss: 0.4787823 Vali Loss: 0.9953242 Test Loss: 0.4611540\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 1.8011388778686523\n","Epoch: 40, Steps: 63 | Train Loss: 0.4789650 Vali Loss: 0.9948894 Test Loss: 0.4611657\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 1.8663966655731201\n","Epoch: 41, Steps: 63 | Train Loss: 0.4788806 Vali Loss: 0.9952376 Test Loss: 0.4611152\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 1.75571870803833\n","Epoch: 42, Steps: 63 | Train Loss: 0.4796891 Vali Loss: 0.9949357 Test Loss: 0.4611393\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 1.7097346782684326\n","Epoch: 43, Steps: 63 | Train Loss: 0.4792196 Vali Loss: 0.9954339 Test Loss: 0.4611555\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 1.7324655055999756\n","Epoch: 44, Steps: 63 | Train Loss: 0.4793497 Vali Loss: 0.9952474 Test Loss: 0.4611193\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 1.835571050643921\n","Epoch: 45, Steps: 63 | Train Loss: 0.4794552 Vali Loss: 0.9953738 Test Loss: 0.4612161\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 1.7304072380065918\n","Epoch: 46, Steps: 63 | Train Loss: 0.4793325 Vali Loss: 0.9952793 Test Loss: 0.4611561\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 1.7542965412139893\n","Epoch: 47, Steps: 63 | Train Loss: 0.4787795 Vali Loss: 0.9949443 Test Loss: 0.4611844\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 1.7794811725616455\n","Epoch: 48, Steps: 63 | Train Loss: 0.4794782 Vali Loss: 0.9952605 Test Loss: 0.4611813\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 1.8211352825164795\n","Epoch: 49, Steps: 63 | Train Loss: 0.4796966 Vali Loss: 0.9947562 Test Loss: 0.4611812\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 1.794182538986206\n","Epoch: 50, Steps: 63 | Train Loss: 0.4798665 Vali Loss: 0.9951432 Test Loss: 0.4611422\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 1.7325398921966553\n","Epoch: 51, Steps: 63 | Train Loss: 0.4793076 Vali Loss: 0.9951075 Test Loss: 0.4611124\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 1.7946581840515137\n","Epoch: 52, Steps: 63 | Train Loss: 0.4794234 Vali Loss: 0.9955424 Test Loss: 0.4611965\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 1.902160882949829\n","Epoch: 53, Steps: 63 | Train Loss: 0.4792189 Vali Loss: 0.9950840 Test Loss: 0.4611575\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 1.7242212295532227\n","Epoch: 54, Steps: 63 | Train Loss: 0.4787254 Vali Loss: 0.9948619 Test Loss: 0.4611986\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 1.747795820236206\n","Epoch: 55, Steps: 63 | Train Loss: 0.4792559 Vali Loss: 0.9953309 Test Loss: 0.4612147\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 1.7680096626281738\n","Epoch: 56, Steps: 63 | Train Loss: 0.4793517 Vali Loss: 0.9949743 Test Loss: 0.4611621\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 1.8754537105560303\n","Epoch: 57, Steps: 63 | Train Loss: 0.4796349 Vali Loss: 0.9947612 Test Loss: 0.4611567\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 1.6997101306915283\n","Epoch: 58, Steps: 63 | Train Loss: 0.4788130 Vali Loss: 0.9950530 Test Loss: 0.4611835\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 1.7210204601287842\n","Epoch: 59, Steps: 63 | Train Loss: 0.4789853 Vali Loss: 0.9955030 Test Loss: 0.4611696\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 1.7193748950958252\n","Epoch: 60, Steps: 63 | Train Loss: 0.4792832 Vali Loss: 0.9949315 Test Loss: 0.4611570\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 1.8375184535980225\n","Epoch: 61, Steps: 63 | Train Loss: 0.4785109 Vali Loss: 0.9947633 Test Loss: 0.4611521\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 1.75193452835083\n","Epoch: 62, Steps: 63 | Train Loss: 0.4796497 Vali Loss: 0.9952868 Test Loss: 0.4611804\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 1.7507646083831787\n","Epoch: 63, Steps: 63 | Train Loss: 0.4796164 Vali Loss: 0.9954147 Test Loss: 0.4611490\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 1.710157871246338\n","Epoch: 64, Steps: 63 | Train Loss: 0.4790343 Vali Loss: 0.9955263 Test Loss: 0.4611356\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 1.9015684127807617\n","Epoch: 65, Steps: 63 | Train Loss: 0.4789621 Vali Loss: 0.9953393 Test Loss: 0.4611375\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 1.7514145374298096\n","Epoch: 66, Steps: 63 | Train Loss: 0.4791297 Vali Loss: 0.9950936 Test Loss: 0.4612370\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 1.7439234256744385\n","Epoch: 67, Steps: 63 | Train Loss: 0.4793978 Vali Loss: 0.9950526 Test Loss: 0.4611912\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 1.7598106861114502\n","Epoch: 68, Steps: 63 | Train Loss: 0.4789407 Vali Loss: 0.9953721 Test Loss: 0.4611498\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 1.8702564239501953\n","Epoch: 69, Steps: 63 | Train Loss: 0.4795058 Vali Loss: 0.9953648 Test Loss: 0.4611660\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 1.8000798225402832\n","Epoch: 70, Steps: 63 | Train Loss: 0.4792439 Vali Loss: 0.9951831 Test Loss: 0.4611387\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 2.1627001762390137\n","Epoch: 71, Steps: 63 | Train Loss: 0.4794423 Vali Loss: 0.9954131 Test Loss: 0.4611590\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 1.8204340934753418\n","Epoch: 72, Steps: 63 | Train Loss: 0.4792348 Vali Loss: 0.9953116 Test Loss: 0.4611707\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 1.9394769668579102\n","Epoch: 73, Steps: 63 | Train Loss: 0.4792627 Vali Loss: 0.9951796 Test Loss: 0.4612250\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 1.8335659503936768\n","Epoch: 74, Steps: 63 | Train Loss: 0.4794943 Vali Loss: 0.9952916 Test Loss: 0.4611199\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 1.7952141761779785\n","Epoch: 75, Steps: 63 | Train Loss: 0.4790741 Vali Loss: 0.9954202 Test Loss: 0.4611023\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 1.7909679412841797\n","Epoch: 76, Steps: 63 | Train Loss: 0.4792128 Vali Loss: 0.9949521 Test Loss: 0.4611382\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 1.983161211013794\n","Epoch: 77, Steps: 63 | Train Loss: 0.4794330 Vali Loss: 0.9952397 Test Loss: 0.4611830\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 1.8133676052093506\n","Epoch: 78, Steps: 63 | Train Loss: 0.4791391 Vali Loss: 0.9953575 Test Loss: 0.4611520\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 1.8084943294525146\n","Epoch: 79, Steps: 63 | Train Loss: 0.4794237 Vali Loss: 0.9954112 Test Loss: 0.4612205\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 1.7944271564483643\n","Epoch: 80, Steps: 63 | Train Loss: 0.4790230 Vali Loss: 0.9948396 Test Loss: 0.4611458\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 1.9145665168762207\n","Epoch: 81, Steps: 63 | Train Loss: 0.4791282 Vali Loss: 0.9951724 Test Loss: 0.4611372\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 1.7514557838439941\n","Epoch: 82, Steps: 63 | Train Loss: 0.4790352 Vali Loss: 0.9948727 Test Loss: 0.4611928\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 1.7999811172485352\n","Epoch: 83, Steps: 63 | Train Loss: 0.4794737 Vali Loss: 0.9949310 Test Loss: 0.4612203\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 1.7632524967193604\n","Epoch: 84, Steps: 63 | Train Loss: 0.4793665 Vali Loss: 0.9948621 Test Loss: 0.4611136\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 1.9148013591766357\n","Epoch: 85, Steps: 63 | Train Loss: 0.4791342 Vali Loss: 0.9953296 Test Loss: 0.4611462\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 1.7555036544799805\n","Epoch: 86, Steps: 63 | Train Loss: 0.4789225 Vali Loss: 0.9949863 Test Loss: 0.4611534\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 1.70027756690979\n","Epoch: 87, Steps: 63 | Train Loss: 0.4793011 Vali Loss: 0.9951922 Test Loss: 0.4611201\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 1.782439947128296\n","Epoch: 88, Steps: 63 | Train Loss: 0.4791749 Vali Loss: 0.9954049 Test Loss: 0.4611560\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 1.8643755912780762\n","Epoch: 89, Steps: 63 | Train Loss: 0.4795604 Vali Loss: 0.9954674 Test Loss: 0.4611931\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 1.7458009719848633\n","Epoch: 90, Steps: 63 | Train Loss: 0.4791697 Vali Loss: 0.9952384 Test Loss: 0.4610636\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 1.7690980434417725\n","Epoch: 91, Steps: 63 | Train Loss: 0.4793043 Vali Loss: 0.9949383 Test Loss: 0.4611940\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 1.736487627029419\n","Epoch: 92, Steps: 63 | Train Loss: 0.4789568 Vali Loss: 0.9954020 Test Loss: 0.4611455\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 1.8986501693725586\n","Epoch: 93, Steps: 63 | Train Loss: 0.4790048 Vali Loss: 0.9953939 Test Loss: 0.4611122\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 1.7665753364562988\n","Epoch: 94, Steps: 63 | Train Loss: 0.4793064 Vali Loss: 0.9954075 Test Loss: 0.4611755\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 1.771191120147705\n","Epoch: 95, Steps: 63 | Train Loss: 0.4792643 Vali Loss: 0.9951066 Test Loss: 0.4611653\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 1.7275073528289795\n","Epoch: 96, Steps: 63 | Train Loss: 0.4796718 Vali Loss: 0.9953097 Test Loss: 0.4611519\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 1.8740606307983398\n","Epoch: 97, Steps: 63 | Train Loss: 0.4797988 Vali Loss: 0.9951061 Test Loss: 0.4611621\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 1.7831857204437256\n","Epoch: 98, Steps: 63 | Train Loss: 0.4794316 Vali Loss: 0.9953473 Test Loss: 0.4611511\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 1.736577033996582\n","Epoch: 99, Steps: 63 | Train Loss: 0.4792804 Vali Loss: 0.9949323 Test Loss: 0.4611638\n","EarlyStopping counter: 80 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 1.7643778324127197\n","Epoch: 100, Steps: 63 | Train Loss: 0.4788390 Vali Loss: 0.9950617 Test Loss: 0.4611751\n","EarlyStopping counter: 81 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2689\n","mse:0.46119317412376404, mae:0.4560082256793976, rse:0.6449010968208313\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  336\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  0\n","Exp_Main init!\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 7969\n","val 2545\n","test 2545\n","Epoch: 1 cost time: 1.790984869003296\n","Epoch: 1, Steps: 62 | Train Loss: 0.8033972 Vali Loss: 1.7082218 Test Loss: 0.7641666\n","Validation loss decreased (inf --> 1.708222).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 1.7465074062347412\n","Epoch: 2, Steps: 62 | Train Loss: 0.6630183 Vali Loss: 1.3030787 Test Loss: 0.5161726\n","Validation loss decreased (1.708222 --> 1.303079).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 1.788163185119629\n","Epoch: 3, Steps: 62 | Train Loss: 0.5775634 Vali Loss: 1.2523789 Test Loss: 0.4810620\n","Validation loss decreased (1.303079 --> 1.252379).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 1.8434805870056152\n","Epoch: 4, Steps: 62 | Train Loss: 0.5552729 Vali Loss: 1.2342739 Test Loss: 0.4713572\n","Validation loss decreased (1.252379 --> 1.234274).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 1.8000226020812988\n","Epoch: 5, Steps: 62 | Train Loss: 0.5461338 Vali Loss: 1.2324787 Test Loss: 0.4671475\n","Validation loss decreased (1.234274 --> 1.232479).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 1.7397935390472412\n","Epoch: 6, Steps: 62 | Train Loss: 0.5419822 Vali Loss: 1.2352642 Test Loss: 0.4650582\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 1.7286713123321533\n","Epoch: 7, Steps: 62 | Train Loss: 0.5403608 Vali Loss: 1.2264328 Test Loss: 0.4639790\n","Validation loss decreased (1.232479 --> 1.226433).  Saving model ...\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 1.9854645729064941\n","Epoch: 8, Steps: 62 | Train Loss: 0.5394820 Vali Loss: 1.2187599 Test Loss: 0.4635168\n","Validation loss decreased (1.226433 --> 1.218760).  Saving model ...\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 1.749377965927124\n","Epoch: 9, Steps: 62 | Train Loss: 0.5389465 Vali Loss: 1.2280418 Test Loss: 0.4632846\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 1.7449135780334473\n","Epoch: 10, Steps: 62 | Train Loss: 0.5386489 Vali Loss: 1.2226982 Test Loss: 0.4631776\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 1.841581106185913\n","Epoch: 11, Steps: 62 | Train Loss: 0.5386651 Vali Loss: 1.2219971 Test Loss: 0.4630824\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 1.8541810512542725\n","Epoch: 12, Steps: 62 | Train Loss: 0.5387997 Vali Loss: 1.2208580 Test Loss: 0.4630376\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 1.74326491355896\n","Epoch: 13, Steps: 62 | Train Loss: 0.5383889 Vali Loss: 1.2265077 Test Loss: 0.4630221\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 1.7353482246398926\n","Epoch: 14, Steps: 62 | Train Loss: 0.5385843 Vali Loss: 1.2206374 Test Loss: 0.4630243\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 1.740671157836914\n","Epoch: 15, Steps: 62 | Train Loss: 0.5388491 Vali Loss: 1.2211772 Test Loss: 0.4630160\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 1.905240774154663\n","Epoch: 16, Steps: 62 | Train Loss: 0.5389252 Vali Loss: 1.2214909 Test Loss: 0.4630511\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 1.6934425830841064\n","Epoch: 17, Steps: 62 | Train Loss: 0.5385490 Vali Loss: 1.2214520 Test Loss: 0.4631205\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 1.7783513069152832\n","Epoch: 18, Steps: 62 | Train Loss: 0.5385824 Vali Loss: 1.2208221 Test Loss: 0.4630548\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 1.783200979232788\n","Epoch: 19, Steps: 62 | Train Loss: 0.5386424 Vali Loss: 1.2211754 Test Loss: 0.4629969\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 1.908470869064331\n","Epoch: 20, Steps: 62 | Train Loss: 0.5382148 Vali Loss: 1.2196406 Test Loss: 0.4630129\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 1.7446093559265137\n","Epoch: 21, Steps: 62 | Train Loss: 0.5384019 Vali Loss: 1.2241923 Test Loss: 0.4630148\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 1.7645699977874756\n","Epoch: 22, Steps: 62 | Train Loss: 0.5385236 Vali Loss: 1.2214605 Test Loss: 0.4630320\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 1.7287368774414062\n","Epoch: 23, Steps: 62 | Train Loss: 0.5385936 Vali Loss: 1.2238121 Test Loss: 0.4629568\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 1.8753201961517334\n","Epoch: 24, Steps: 62 | Train Loss: 0.5381102 Vali Loss: 1.2212329 Test Loss: 0.4630848\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 1.8014004230499268\n","Epoch: 25, Steps: 62 | Train Loss: 0.5385062 Vali Loss: 1.2233678 Test Loss: 0.4630975\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 1.8136863708496094\n","Epoch: 26, Steps: 62 | Train Loss: 0.5385928 Vali Loss: 1.2236781 Test Loss: 0.4630588\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 1.8560256958007812\n","Epoch: 27, Steps: 62 | Train Loss: 0.5383962 Vali Loss: 1.2225561 Test Loss: 0.4630337\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 1.9188711643218994\n","Epoch: 28, Steps: 62 | Train Loss: 0.5385681 Vali Loss: 1.2233824 Test Loss: 0.4630657\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 1.7522950172424316\n","Epoch: 29, Steps: 62 | Train Loss: 0.5383196 Vali Loss: 1.2214041 Test Loss: 0.4630478\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 1.8228766918182373\n","Epoch: 30, Steps: 62 | Train Loss: 0.5386687 Vali Loss: 1.2258254 Test Loss: 0.4629657\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 1.7938520908355713\n","Epoch: 31, Steps: 62 | Train Loss: 0.5385948 Vali Loss: 1.2180207 Test Loss: 0.4630443\n","Validation loss decreased (1.218760 --> 1.218021).  Saving model ...\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 1.889317512512207\n","Epoch: 32, Steps: 62 | Train Loss: 0.5383421 Vali Loss: 1.2262330 Test Loss: 0.4630533\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 1.7878243923187256\n","Epoch: 33, Steps: 62 | Train Loss: 0.5379895 Vali Loss: 1.2216018 Test Loss: 0.4629961\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 1.7623231410980225\n","Epoch: 34, Steps: 62 | Train Loss: 0.5384495 Vali Loss: 1.2199003 Test Loss: 0.4629860\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 1.901836633682251\n","Epoch: 35, Steps: 62 | Train Loss: 0.5384599 Vali Loss: 1.2206328 Test Loss: 0.4630473\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 1.8397305011749268\n","Epoch: 36, Steps: 62 | Train Loss: 0.5385073 Vali Loss: 1.2248783 Test Loss: 0.4629930\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 1.7719049453735352\n","Epoch: 37, Steps: 62 | Train Loss: 0.5382666 Vali Loss: 1.2230232 Test Loss: 0.4630347\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 1.7989583015441895\n","Epoch: 38, Steps: 62 | Train Loss: 0.5383510 Vali Loss: 1.2231872 Test Loss: 0.4629579\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 1.931056022644043\n","Epoch: 39, Steps: 62 | Train Loss: 0.5377987 Vali Loss: 1.2216470 Test Loss: 0.4629701\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 1.835137128829956\n","Epoch: 40, Steps: 62 | Train Loss: 0.5382063 Vali Loss: 1.2259015 Test Loss: 0.4629927\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 1.8367156982421875\n","Epoch: 41, Steps: 62 | Train Loss: 0.5387403 Vali Loss: 1.2182819 Test Loss: 0.4630159\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 1.8097097873687744\n","Epoch: 42, Steps: 62 | Train Loss: 0.5385864 Vali Loss: 1.2279564 Test Loss: 0.4629631\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 1.9276983737945557\n","Epoch: 43, Steps: 62 | Train Loss: 0.5386266 Vali Loss: 1.2209740 Test Loss: 0.4630093\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 1.8110809326171875\n","Epoch: 44, Steps: 62 | Train Loss: 0.5385354 Vali Loss: 1.2216144 Test Loss: 0.4630378\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 1.867417573928833\n","Epoch: 45, Steps: 62 | Train Loss: 0.5386635 Vali Loss: 1.2265134 Test Loss: 0.4630030\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 1.7725749015808105\n","Epoch: 46, Steps: 62 | Train Loss: 0.5386880 Vali Loss: 1.2151027 Test Loss: 0.4630258\n","Validation loss decreased (1.218021 --> 1.215103).  Saving model ...\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 1.9820952415466309\n","Epoch: 47, Steps: 62 | Train Loss: 0.5384338 Vali Loss: 1.2240076 Test Loss: 0.4629382\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 1.8456897735595703\n","Epoch: 48, Steps: 62 | Train Loss: 0.5384924 Vali Loss: 1.2185823 Test Loss: 0.4629465\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 1.813772201538086\n","Epoch: 49, Steps: 62 | Train Loss: 0.5383224 Vali Loss: 1.2183433 Test Loss: 0.4630488\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 1.880021572113037\n","Epoch: 50, Steps: 62 | Train Loss: 0.5386613 Vali Loss: 1.2228709 Test Loss: 0.4630215\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 1.9384841918945312\n","Epoch: 51, Steps: 62 | Train Loss: 0.5383158 Vali Loss: 1.2226118 Test Loss: 0.4630958\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 1.8145382404327393\n","Epoch: 52, Steps: 62 | Train Loss: 0.5386614 Vali Loss: 1.2224569 Test Loss: 0.4629675\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 1.8238427639007568\n","Epoch: 53, Steps: 62 | Train Loss: 0.5383589 Vali Loss: 1.2213063 Test Loss: 0.4630742\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 1.9640202522277832\n","Epoch: 54, Steps: 62 | Train Loss: 0.5383289 Vali Loss: 1.2249409 Test Loss: 0.4629626\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 1.9878642559051514\n","Epoch: 55, Steps: 62 | Train Loss: 0.5385264 Vali Loss: 1.2208687 Test Loss: 0.4630902\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 1.9014065265655518\n","Epoch: 56, Steps: 62 | Train Loss: 0.5387576 Vali Loss: 1.2237874 Test Loss: 0.4630410\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 1.8726716041564941\n","Epoch: 57, Steps: 62 | Train Loss: 0.5385048 Vali Loss: 1.2190436 Test Loss: 0.4630228\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 1.9833436012268066\n","Epoch: 58, Steps: 62 | Train Loss: 0.5383920 Vali Loss: 1.2208500 Test Loss: 0.4630395\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 1.8258168697357178\n","Epoch: 59, Steps: 62 | Train Loss: 0.5383912 Vali Loss: 1.2230455 Test Loss: 0.4630511\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 1.8562395572662354\n","Epoch: 60, Steps: 62 | Train Loss: 0.5384072 Vali Loss: 1.2296816 Test Loss: 0.4630263\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 1.784256935119629\n","Epoch: 61, Steps: 62 | Train Loss: 0.5386990 Vali Loss: 1.2224959 Test Loss: 0.4629814\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 1.9189941883087158\n","Epoch: 62, Steps: 62 | Train Loss: 0.5383734 Vali Loss: 1.2234818 Test Loss: 0.4630384\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 1.8445408344268799\n","Epoch: 63, Steps: 62 | Train Loss: 0.5383877 Vali Loss: 1.2228378 Test Loss: 0.4630674\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 1.8931372165679932\n","Epoch: 64, Steps: 62 | Train Loss: 0.5384967 Vali Loss: 1.2204560 Test Loss: 0.4630816\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 1.7942180633544922\n","Epoch: 65, Steps: 62 | Train Loss: 0.5384942 Vali Loss: 1.2248087 Test Loss: 0.4629953\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 2.0016350746154785\n","Epoch: 66, Steps: 62 | Train Loss: 0.5381847 Vali Loss: 1.2243220 Test Loss: 0.4629964\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 1.8134491443634033\n","Epoch: 67, Steps: 62 | Train Loss: 0.5383361 Vali Loss: 1.2189122 Test Loss: 0.4630130\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 1.8368282318115234\n","Epoch: 68, Steps: 62 | Train Loss: 0.5386606 Vali Loss: 1.2211120 Test Loss: 0.4629957\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 1.886007308959961\n","Epoch: 69, Steps: 62 | Train Loss: 0.5387854 Vali Loss: 1.2238525 Test Loss: 0.4629440\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 1.9144487380981445\n","Epoch: 70, Steps: 62 | Train Loss: 0.5386493 Vali Loss: 1.2221229 Test Loss: 0.4630176\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 1.8370146751403809\n","Epoch: 71, Steps: 62 | Train Loss: 0.5381873 Vali Loss: 1.2246706 Test Loss: 0.4630189\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 1.9082863330841064\n","Epoch: 72, Steps: 62 | Train Loss: 0.5384736 Vali Loss: 1.2244142 Test Loss: 0.4629619\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 1.9612514972686768\n","Epoch: 73, Steps: 62 | Train Loss: 0.5386626 Vali Loss: 1.2186711 Test Loss: 0.4630466\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 1.941528081893921\n","Epoch: 74, Steps: 62 | Train Loss: 0.5385008 Vali Loss: 1.2224514 Test Loss: 0.4630587\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 1.8304414749145508\n","Epoch: 75, Steps: 62 | Train Loss: 0.5384927 Vali Loss: 1.2155602 Test Loss: 0.4630229\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 1.8128235340118408\n","Epoch: 76, Steps: 62 | Train Loss: 0.5384102 Vali Loss: 1.2226160 Test Loss: 0.4629980\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 1.9347121715545654\n","Epoch: 77, Steps: 62 | Train Loss: 0.5386032 Vali Loss: 1.2224749 Test Loss: 0.4629772\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 1.8662519454956055\n","Epoch: 78, Steps: 62 | Train Loss: 0.5381844 Vali Loss: 1.2191194 Test Loss: 0.4630085\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 1.887995719909668\n","Epoch: 79, Steps: 62 | Train Loss: 0.5387873 Vali Loss: 1.2256645 Test Loss: 0.4630080\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 1.8184330463409424\n","Epoch: 80, Steps: 62 | Train Loss: 0.5381298 Vali Loss: 1.2195239 Test Loss: 0.4630563\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 2.0244088172912598\n","Epoch: 81, Steps: 62 | Train Loss: 0.5385082 Vali Loss: 1.2227316 Test Loss: 0.4629740\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 1.854071855545044\n","Epoch: 82, Steps: 62 | Train Loss: 0.5384986 Vali Loss: 1.2254792 Test Loss: 0.4629616\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 1.8046517372131348\n","Epoch: 83, Steps: 62 | Train Loss: 0.5384589 Vali Loss: 1.2226286 Test Loss: 0.4630747\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 1.8749995231628418\n","Epoch: 84, Steps: 62 | Train Loss: 0.5386764 Vali Loss: 1.2275813 Test Loss: 0.4629776\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 1.96632719039917\n","Epoch: 85, Steps: 62 | Train Loss: 0.5380923 Vali Loss: 1.2217970 Test Loss: 0.4630052\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 1.7976388931274414\n","Epoch: 86, Steps: 62 | Train Loss: 0.5383519 Vali Loss: 1.2267069 Test Loss: 0.4630442\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 1.8382651805877686\n","Epoch: 87, Steps: 62 | Train Loss: 0.5385469 Vali Loss: 1.2221186 Test Loss: 0.4630199\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 2.0074784755706787\n","Epoch: 88, Steps: 62 | Train Loss: 0.5383531 Vali Loss: 1.2238878 Test Loss: 0.4630216\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 1.9362356662750244\n","Epoch: 89, Steps: 62 | Train Loss: 0.5382608 Vali Loss: 1.2218033 Test Loss: 0.4630742\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 1.8130805492401123\n","Epoch: 90, Steps: 62 | Train Loss: 0.5384568 Vali Loss: 1.2247785 Test Loss: 0.4630684\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 1.835101842880249\n","Epoch: 91, Steps: 62 | Train Loss: 0.5384784 Vali Loss: 1.2214711 Test Loss: 0.4629923\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 1.9566831588745117\n","Epoch: 92, Steps: 62 | Train Loss: 0.5386842 Vali Loss: 1.2237034 Test Loss: 0.4629792\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 1.8888719081878662\n","Epoch: 93, Steps: 62 | Train Loss: 0.5384474 Vali Loss: 1.2214986 Test Loss: 0.4630735\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 1.9336304664611816\n","Epoch: 94, Steps: 62 | Train Loss: 0.5385756 Vali Loss: 1.2222487 Test Loss: 0.4630393\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 1.9033241271972656\n","Epoch: 95, Steps: 62 | Train Loss: 0.5388294 Vali Loss: 1.2228462 Test Loss: 0.4630143\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 1.9830524921417236\n","Epoch: 96, Steps: 62 | Train Loss: 0.5382857 Vali Loss: 1.2208525 Test Loss: 0.4630241\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 1.7964532375335693\n","Epoch: 97, Steps: 62 | Train Loss: 0.5385516 Vali Loss: 1.2197952 Test Loss: 0.4629667\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 1.8620107173919678\n","Epoch: 98, Steps: 62 | Train Loss: 0.5386220 Vali Loss: 1.2174431 Test Loss: 0.4631002\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 1.8361945152282715\n","Epoch: 99, Steps: 62 | Train Loss: 0.5384767 Vali Loss: 1.2251000 Test Loss: 0.4630294\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 1.9632182121276855\n","Epoch: 100, Steps: 62 | Train Loss: 0.5384180 Vali Loss: 1.2216864 Test Loss: 0.4629401\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2545\n","mse:0.4630257487297058, mae:0.46205562353134155, rse:0.6504727602005005\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  720\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  0\n","Exp_Main init!\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 7585\n","val 2161\n","test 2161\n","Epoch: 1 cost time: 1.9342145919799805\n","Epoch: 1, Steps: 59 | Train Loss: 0.9035799 Vali Loss: 1.9745135 Test Loss: 0.7816728\n","Validation loss decreased (inf --> 1.974514).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 1.953139066696167\n","Epoch: 2, Steps: 59 | Train Loss: 0.7736927 Vali Loss: 1.5453290 Test Loss: 0.5067559\n","Validation loss decreased (1.974514 --> 1.545329).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 2.0938570499420166\n","Epoch: 3, Steps: 59 | Train Loss: 0.6842922 Vali Loss: 1.5054708 Test Loss: 0.4756532\n","Validation loss decreased (1.545329 --> 1.505471).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 1.9753541946411133\n","Epoch: 4, Steps: 59 | Train Loss: 0.6629545 Vali Loss: 1.4920584 Test Loss: 0.4676351\n","Validation loss decreased (1.505471 --> 1.492058).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 1.9444282054901123\n","Epoch: 5, Steps: 59 | Train Loss: 0.6555662 Vali Loss: 1.4785144 Test Loss: 0.4644367\n","Validation loss decreased (1.492058 --> 1.478514).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 2.1080050468444824\n","Epoch: 6, Steps: 59 | Train Loss: 0.6518299 Vali Loss: 1.4737718 Test Loss: 0.4631542\n","Validation loss decreased (1.478514 --> 1.473772).  Saving model ...\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 1.9985120296478271\n","Epoch: 7, Steps: 59 | Train Loss: 0.6503027 Vali Loss: 1.4787350 Test Loss: 0.4624687\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 1.9186336994171143\n","Epoch: 8, Steps: 59 | Train Loss: 0.6491551 Vali Loss: 1.4808365 Test Loss: 0.4621945\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 1.9156625270843506\n","Epoch: 9, Steps: 59 | Train Loss: 0.6488573 Vali Loss: 1.4766568 Test Loss: 0.4619741\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 2.0304040908813477\n","Epoch: 10, Steps: 59 | Train Loss: 0.6486674 Vali Loss: 1.4771745 Test Loss: 0.4617757\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 1.945004940032959\n","Epoch: 11, Steps: 59 | Train Loss: 0.6486455 Vali Loss: 1.4774837 Test Loss: 0.4617788\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 1.8969850540161133\n","Epoch: 12, Steps: 59 | Train Loss: 0.6483255 Vali Loss: 1.4804256 Test Loss: 0.4618208\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 1.9057669639587402\n","Epoch: 13, Steps: 59 | Train Loss: 0.6485355 Vali Loss: 1.4810991 Test Loss: 0.4618155\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 2.0493342876434326\n","Epoch: 14, Steps: 59 | Train Loss: 0.6481576 Vali Loss: 1.4788654 Test Loss: 0.4618524\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 1.9314451217651367\n","Epoch: 15, Steps: 59 | Train Loss: 0.6485691 Vali Loss: 1.4750510 Test Loss: 0.4617051\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 1.90409255027771\n","Epoch: 16, Steps: 59 | Train Loss: 0.6482533 Vali Loss: 1.4823217 Test Loss: 0.4617057\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 2.0791211128234863\n","Epoch: 17, Steps: 59 | Train Loss: 0.6482576 Vali Loss: 1.4731975 Test Loss: 0.4618351\n","Validation loss decreased (1.473772 --> 1.473197).  Saving model ...\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 1.9731035232543945\n","Epoch: 18, Steps: 59 | Train Loss: 0.6483648 Vali Loss: 1.4789469 Test Loss: 0.4617623\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 1.9546356201171875\n","Epoch: 19, Steps: 59 | Train Loss: 0.6483855 Vali Loss: 1.4785109 Test Loss: 0.4617125\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 1.9229133129119873\n","Epoch: 20, Steps: 59 | Train Loss: 0.6484754 Vali Loss: 1.4783986 Test Loss: 0.4616927\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 2.0651800632476807\n","Epoch: 21, Steps: 59 | Train Loss: 0.6478961 Vali Loss: 1.4825445 Test Loss: 0.4618196\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 1.9511959552764893\n","Epoch: 22, Steps: 59 | Train Loss: 0.6485484 Vali Loss: 1.4783363 Test Loss: 0.4617664\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 1.9223742485046387\n","Epoch: 23, Steps: 59 | Train Loss: 0.6484343 Vali Loss: 1.4798005 Test Loss: 0.4617712\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 2.092027187347412\n","Epoch: 24, Steps: 59 | Train Loss: 0.6483031 Vali Loss: 1.4814622 Test Loss: 0.4617068\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 2.003286838531494\n","Epoch: 25, Steps: 59 | Train Loss: 0.6483000 Vali Loss: 1.4773256 Test Loss: 0.4617034\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 1.9315276145935059\n","Epoch: 26, Steps: 59 | Train Loss: 0.6483595 Vali Loss: 1.4781225 Test Loss: 0.4617653\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 1.9436273574829102\n","Epoch: 27, Steps: 59 | Train Loss: 0.6483317 Vali Loss: 1.4724928 Test Loss: 0.4617539\n","Validation loss decreased (1.473197 --> 1.472493).  Saving model ...\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 2.1078038215637207\n","Epoch: 28, Steps: 59 | Train Loss: 0.6481981 Vali Loss: 1.4811897 Test Loss: 0.4617593\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 1.9288160800933838\n","Epoch: 29, Steps: 59 | Train Loss: 0.6484040 Vali Loss: 1.4777434 Test Loss: 0.4617001\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 1.9483387470245361\n","Epoch: 30, Steps: 59 | Train Loss: 0.6482186 Vali Loss: 1.4747984 Test Loss: 0.4616800\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 2.124495506286621\n","Epoch: 31, Steps: 59 | Train Loss: 0.6481041 Vali Loss: 1.4832050 Test Loss: 0.4617421\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 2.039598226547241\n","Epoch: 32, Steps: 59 | Train Loss: 0.6481987 Vali Loss: 1.4790434 Test Loss: 0.4616809\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 1.9687387943267822\n","Epoch: 33, Steps: 59 | Train Loss: 0.6486052 Vali Loss: 1.4808311 Test Loss: 0.4617414\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 2.0046610832214355\n","Epoch: 34, Steps: 59 | Train Loss: 0.6481411 Vali Loss: 1.4807602 Test Loss: 0.4617779\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 2.0909066200256348\n","Epoch: 35, Steps: 59 | Train Loss: 0.6480372 Vali Loss: 1.4770967 Test Loss: 0.4617658\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 1.9783756732940674\n","Epoch: 36, Steps: 59 | Train Loss: 0.6486477 Vali Loss: 1.4767438 Test Loss: 0.4617873\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 1.9458892345428467\n","Epoch: 37, Steps: 59 | Train Loss: 0.6479828 Vali Loss: 1.4804919 Test Loss: 0.4617573\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 2.0743911266326904\n","Epoch: 38, Steps: 59 | Train Loss: 0.6483690 Vali Loss: 1.4788134 Test Loss: 0.4617546\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 2.0512077808380127\n","Epoch: 39, Steps: 59 | Train Loss: 0.6483085 Vali Loss: 1.4739256 Test Loss: 0.4617811\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 1.9758491516113281\n","Epoch: 40, Steps: 59 | Train Loss: 0.6482501 Vali Loss: 1.4828618 Test Loss: 0.4618048\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 2.0226762294769287\n","Epoch: 41, Steps: 59 | Train Loss: 0.6485180 Vali Loss: 1.4794650 Test Loss: 0.4617283\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 2.1313421726226807\n","Epoch: 42, Steps: 59 | Train Loss: 0.6482482 Vali Loss: 1.4750311 Test Loss: 0.4617921\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 1.8868470191955566\n","Epoch: 43, Steps: 59 | Train Loss: 0.6483215 Vali Loss: 1.4785104 Test Loss: 0.4617526\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 1.964625358581543\n","Epoch: 44, Steps: 59 | Train Loss: 0.6483851 Vali Loss: 1.4788740 Test Loss: 0.4617474\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 2.007375955581665\n","Epoch: 45, Steps: 59 | Train Loss: 0.6481788 Vali Loss: 1.4735851 Test Loss: 0.4616914\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 2.0488667488098145\n","Epoch: 46, Steps: 59 | Train Loss: 0.6482408 Vali Loss: 1.4802938 Test Loss: 0.4617794\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 1.976670503616333\n","Epoch: 47, Steps: 59 | Train Loss: 0.6483853 Vali Loss: 1.4846936 Test Loss: 0.4617282\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 1.9897685050964355\n","Epoch: 48, Steps: 59 | Train Loss: 0.6484451 Vali Loss: 1.4827172 Test Loss: 0.4617667\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 2.0781681537628174\n","Epoch: 49, Steps: 59 | Train Loss: 0.6482788 Vali Loss: 1.4710493 Test Loss: 0.4617769\n","Validation loss decreased (1.472493 --> 1.471049).  Saving model ...\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 1.9157500267028809\n","Epoch: 50, Steps: 59 | Train Loss: 0.6486667 Vali Loss: 1.4811717 Test Loss: 0.4617879\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 1.9353036880493164\n","Epoch: 51, Steps: 59 | Train Loss: 0.6481451 Vali Loss: 1.4774909 Test Loss: 0.4616363\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 1.9560363292694092\n","Epoch: 52, Steps: 59 | Train Loss: 0.6485323 Vali Loss: 1.4765458 Test Loss: 0.4617504\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 2.1040103435516357\n","Epoch: 53, Steps: 59 | Train Loss: 0.6481629 Vali Loss: 1.4836740 Test Loss: 0.4617923\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 1.9377551078796387\n","Epoch: 54, Steps: 59 | Train Loss: 0.6483305 Vali Loss: 1.4716163 Test Loss: 0.4617308\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 1.8482334613800049\n","Epoch: 55, Steps: 59 | Train Loss: 0.6483688 Vali Loss: 1.4740212 Test Loss: 0.4617131\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 2.0842018127441406\n","Epoch: 56, Steps: 59 | Train Loss: 0.6482547 Vali Loss: 1.4776778 Test Loss: 0.4617055\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 1.9819977283477783\n","Epoch: 57, Steps: 59 | Train Loss: 0.6483074 Vali Loss: 1.4735817 Test Loss: 0.4617653\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 1.9192397594451904\n","Epoch: 58, Steps: 59 | Train Loss: 0.6486566 Vali Loss: 1.4799991 Test Loss: 0.4617358\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 1.940566062927246\n","Epoch: 59, Steps: 59 | Train Loss: 0.6484782 Vali Loss: 1.4786766 Test Loss: 0.4616826\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 1.9888474941253662\n","Epoch: 60, Steps: 59 | Train Loss: 0.6484104 Vali Loss: 1.4763124 Test Loss: 0.4617160\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 1.9229469299316406\n","Epoch: 61, Steps: 59 | Train Loss: 0.6484047 Vali Loss: 1.4746681 Test Loss: 0.4617574\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 1.9482991695404053\n","Epoch: 62, Steps: 59 | Train Loss: 0.6483520 Vali Loss: 1.4810617 Test Loss: 0.4617538\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 2.0915305614471436\n","Epoch: 63, Steps: 59 | Train Loss: 0.6484098 Vali Loss: 1.4780424 Test Loss: 0.4617747\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 1.9588260650634766\n","Epoch: 64, Steps: 59 | Train Loss: 0.6481576 Vali Loss: 1.4829185 Test Loss: 0.4617713\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 1.8863089084625244\n","Epoch: 65, Steps: 59 | Train Loss: 0.6478183 Vali Loss: 1.4794583 Test Loss: 0.4618002\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 1.9810693264007568\n","Epoch: 66, Steps: 59 | Train Loss: 0.6481867 Vali Loss: 1.4754746 Test Loss: 0.4617647\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 2.0697624683380127\n","Epoch: 67, Steps: 59 | Train Loss: 0.6481460 Vali Loss: 1.4789634 Test Loss: 0.4617270\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 1.9741251468658447\n","Epoch: 68, Steps: 59 | Train Loss: 0.6478546 Vali Loss: 1.4735843 Test Loss: 0.4617575\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 1.932295322418213\n","Epoch: 69, Steps: 59 | Train Loss: 0.6482710 Vali Loss: 1.4800537 Test Loss: 0.4616885\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 2.1048827171325684\n","Epoch: 70, Steps: 59 | Train Loss: 0.6483902 Vali Loss: 1.4791727 Test Loss: 0.4617671\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 1.9681451320648193\n","Epoch: 71, Steps: 59 | Train Loss: 0.6483288 Vali Loss: 1.4708394 Test Loss: 0.4617733\n","Validation loss decreased (1.471049 --> 1.470839).  Saving model ...\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 1.9180951118469238\n","Epoch: 72, Steps: 59 | Train Loss: 0.6478778 Vali Loss: 1.4746910 Test Loss: 0.4618496\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 2.040226459503174\n","Epoch: 73, Steps: 59 | Train Loss: 0.6480671 Vali Loss: 1.4739672 Test Loss: 0.4617546\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 2.068091630935669\n","Epoch: 74, Steps: 59 | Train Loss: 0.6483631 Vali Loss: 1.4792904 Test Loss: 0.4617462\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 1.9118947982788086\n","Epoch: 75, Steps: 59 | Train Loss: 0.6485450 Vali Loss: 1.4799836 Test Loss: 0.4617855\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 1.9323768615722656\n","Epoch: 76, Steps: 59 | Train Loss: 0.6484018 Vali Loss: 1.4761785 Test Loss: 0.4617217\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 2.1796493530273438\n","Epoch: 77, Steps: 59 | Train Loss: 0.6483961 Vali Loss: 1.4787455 Test Loss: 0.4617049\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 1.9567973613739014\n","Epoch: 78, Steps: 59 | Train Loss: 0.6485747 Vali Loss: 1.4840971 Test Loss: 0.4618279\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 1.9159631729125977\n","Epoch: 79, Steps: 59 | Train Loss: 0.6483936 Vali Loss: 1.4789077 Test Loss: 0.4616715\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 2.0181987285614014\n","Epoch: 80, Steps: 59 | Train Loss: 0.6485360 Vali Loss: 1.4796064 Test Loss: 0.4617402\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 2.0026767253875732\n","Epoch: 81, Steps: 59 | Train Loss: 0.6484116 Vali Loss: 1.4780871 Test Loss: 0.4616880\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 1.9787440299987793\n","Epoch: 82, Steps: 59 | Train Loss: 0.6483548 Vali Loss: 1.4813144 Test Loss: 0.4617942\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 1.9842510223388672\n","Epoch: 83, Steps: 59 | Train Loss: 0.6480960 Vali Loss: 1.4783177 Test Loss: 0.4617839\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 2.1662192344665527\n","Epoch: 84, Steps: 59 | Train Loss: 0.6482886 Vali Loss: 1.4810719 Test Loss: 0.4616572\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 1.9289848804473877\n","Epoch: 85, Steps: 59 | Train Loss: 0.6482725 Vali Loss: 1.4742212 Test Loss: 0.4617674\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 1.924208641052246\n","Epoch: 86, Steps: 59 | Train Loss: 0.6486486 Vali Loss: 1.4725266 Test Loss: 0.4617482\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 2.05410099029541\n","Epoch: 87, Steps: 59 | Train Loss: 0.6485478 Vali Loss: 1.4785119 Test Loss: 0.4617674\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 2.1083755493164062\n","Epoch: 88, Steps: 59 | Train Loss: 0.6484499 Vali Loss: 1.4816754 Test Loss: 0.4618388\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 2.009334087371826\n","Epoch: 89, Steps: 59 | Train Loss: 0.6480521 Vali Loss: 1.4833174 Test Loss: 0.4617137\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 1.9818313121795654\n","Epoch: 90, Steps: 59 | Train Loss: 0.6482334 Vali Loss: 1.4820950 Test Loss: 0.4616825\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 2.1053128242492676\n","Epoch: 91, Steps: 59 | Train Loss: 0.6485223 Vali Loss: 1.4800209 Test Loss: 0.4617029\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 1.9887425899505615\n","Epoch: 92, Steps: 59 | Train Loss: 0.6485164 Vali Loss: 1.4782844 Test Loss: 0.4615897\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 1.9748897552490234\n","Epoch: 93, Steps: 59 | Train Loss: 0.6485229 Vali Loss: 1.4792876 Test Loss: 0.4617576\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 2.090923309326172\n","Epoch: 94, Steps: 59 | Train Loss: 0.6482649 Vali Loss: 1.4781468 Test Loss: 0.4617459\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 2.0588901042938232\n","Epoch: 95, Steps: 59 | Train Loss: 0.6486890 Vali Loss: 1.4779627 Test Loss: 0.4617950\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 1.930816888809204\n","Epoch: 96, Steps: 59 | Train Loss: 0.6483073 Vali Loss: 1.4810125 Test Loss: 0.4617007\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 1.9376797676086426\n","Epoch: 97, Steps: 59 | Train Loss: 0.6476754 Vali Loss: 1.4759688 Test Loss: 0.4618599\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 2.106700897216797\n","Epoch: 98, Steps: 59 | Train Loss: 0.6485549 Vali Loss: 1.4780648 Test Loss: 0.4617794\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 1.975266695022583\n","Epoch: 99, Steps: 59 | Train Loss: 0.6485625 Vali Loss: 1.4793899 Test Loss: 0.4617226\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 1.9772489070892334\n","Epoch: 100, Steps: 59 | Train Loss: 0.6486743 Vali Loss: 1.4757984 Test Loss: 0.4616857\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2161\n","mse:0.46177369356155396, mae:0.4760817289352417, rse:0.6526790261268616\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n"]}],"source":["arg_pred_len_list = [96, 192, 336, 720]\n","\n","for arg_pred_len in arg_pred_len_list:\n","  # prediction len 설정\n","\n","  args.pred_len = arg_pred_len\n","  Exp = Exp_Main\n","  print(\"Current Prediction Length : \", str(arg_pred_len))\n","  print(\"\\n\\n\\n\")\n","\n","  if args.is_training:\n","      for ii in range(args.itr):\n","          # setting record of experiments\n","          setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n","              args.model_id,\n","              args.model,\n","              args.data,\n","              args.features,\n","              args.seq_len,\n","              args.label_len,\n","              args.pred_len,\n","              args.d_model,\n","              args.n_heads,\n","              args.e_layers,\n","              args.d_layers,\n","              args.d_ff,\n","              args.factor,\n","              args.embed,\n","              args.distil,\n","              args.des,ii)\n","\n","          exp = Exp(args)  # set experiments\n","\n","          print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","          exp.train(setting)\n","\n","          print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","          exp.test(setting)\n","\n","          if args.do_predict:\n","              print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","              exp.predict(setting, True)\n","\n","          torch.cuda.empty_cache()\n","\n","          print(\"\\n\\n\\n\\n\\n\")\n","\n","  # 실험에서 사용되지 않는 경우.\n","  else:\n","      ii = 0\n","      setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n","                                                                                                  args.model,\n","                                                                                                  args.data,\n","                                                                                                  args.features,\n","                                                                                                  args.seq_len,\n","                                                                                                  args.label_len,\n","                                                                                                  args.pred_len,\n","                                                                                                  args.d_model,\n","                                                                                                  args.n_heads,\n","                                                                                                  args.e_layers,\n","                                                                                                  args.d_layers,\n","                                                                                                  args.d_ff,\n","                                                                                                  args.factor,\n","                                                                                                  args.embed,\n","                                                                                                  args.distil,\n","                                                                                                  args.des, ii)\n","\n","      exp = Exp(args)  # set experiments\n","      print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","      exp.test(setting, test=1)\n","      torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{},"source":["### ILI 데이터셋 실험"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":565,"status":"ok","timestamp":1701018458376,"user":{"displayName":"공자","userId":"09701607017816361852"},"user_tz":-540},"id":"1a4-IiiKewKL","outputId":"d407014b-8b35-4c92-f862-e952e90b9bdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","<__main__.Args object at 0x7f5ea8e3df60>\n"]}],"source":["arg_seq_len=104\n","\n","model_name='PatchTST'\n","\n","root_path_name='./dataset/'\n","data_path_name='national_illness.csv'\n","model_id_name='national_illness'\n","data_name='custom'\n","\n","random_seed=2021\n","\n","class Args:\n","    random_seed = 2021\n","\n","    is_training = 1\n","    model_id = model_id_name\n","    model = model_name\n","\n","    data = data_name\n","    root_path = root_path_name\n","    data_path = data_path_name\n","    features = 'M'\n","    target = 'OT'\n","    freq = 'h'\n","    checkpoints = './checkpoints/'\n","\n","    seq_len = arg_seq_len\n","    fc_dropout= 0.3\n","    head_dropout = 0.0\n","    patch_len = 24\n","    stride = 2\n","    decomposition = 0\n","    enc_in = 7\n","    d_model = 16\n","    n_heads = 4\n","    e_layers = 3\n","    d_ff = 128\n","    dropout = 0.3\n","    itr = 1 # 학습 횟수\n","    train_epochs = 100\n","    batch_size = 16\n","    learning_rate = 0.0025\n","    des = 'Exp'\n","    use_gpu = True\n","    gpu = 0\n","    use_multi_gpu = False\n","    devices = '0'\n","    label_len = 48\n","    d_layers = 1\n","    factor = 1\n","    distil = True\n","    embed = 'timeF'\n","    individual = 0\n","    padding_patch = 'end'\n","    revin = 1\n","    affine = 0\n","    subtract_last = 0\n","    kernel_size = 25\n","    embed_type = 0\n","    dec_in = 7\n","    c_out = 7\n","    moving_avg = 25\n","    activation = 'gelu'\n","    output_attention = False\n","    do_predict = True\n","    patience = 100\n","    num_workers = 10 # DataLoader에 사용할 subprocess 개수\n","    loss = 'MSE'\n","    lradj = 'type1'\n","    pct_start = 0.3\n","    use_amp = False\n","    test_flop = False\n","\n","args = Args();\n","\n","# random seed\n","fix_seed = args.random_seed\n","random.seed(fix_seed)\n","torch.manual_seed(fix_seed)\n","np.random.seed(fix_seed)\n","\n","args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.dvices = args.devices.replace(' ', '')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1189053,"status":"ok","timestamp":1701019712505,"user":{"displayName":"공자","userId":"09701607017816361852"},"user_tz":-540},"id":"QqyBn83xfZuM","outputId":"eb4b9aca-3a63-433e-b753-ac535296b3b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current Prediction Length :  24\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  0\n","Exp_Main init!\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl24_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 549\n","val 74\n","test 170\n","Epoch: 1 cost time: 1.1200480461120605\n","Epoch: 1, Steps: 34 | Train Loss: 0.9077794 Vali Loss: 0.3459986 Test Loss: 2.7053838\n","Validation loss decreased (inf --> 0.345999).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 1.2041077613830566\n","Epoch: 2, Steps: 34 | Train Loss: 0.7567074 Vali Loss: 0.3271586 Test Loss: 2.2059572\n","Validation loss decreased (0.345999 --> 0.327159).  Saving model ...\n","Updating learning rate to 0.00125\n","Epoch: 3 cost time: 1.1315903663635254\n","Epoch: 3, Steps: 34 | Train Loss: 0.5327487 Vali Loss: 0.2819144 Test Loss: 1.7478812\n","Validation loss decreased (0.327159 --> 0.281914).  Saving model ...\n","Updating learning rate to 0.000625\n","Epoch: 4 cost time: 1.1278772354125977\n","Epoch: 4, Steps: 34 | Train Loss: 0.4582917 Vali Loss: 0.2792809 Test Loss: 1.8330834\n","Validation loss decreased (0.281914 --> 0.279281).  Saving model ...\n","Updating learning rate to 0.0003125\n","Epoch: 5 cost time: 1.128873348236084\n","Epoch: 5, Steps: 34 | Train Loss: 0.4347283 Vali Loss: 0.2972835 Test Loss: 1.8282551\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.00015625\n","Epoch: 6 cost time: 1.0956964492797852\n","Epoch: 6, Steps: 34 | Train Loss: 0.4318099 Vali Loss: 0.2890662 Test Loss: 1.7945158\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 7.8125e-05\n","Epoch: 7 cost time: 1.2040414810180664\n","Epoch: 7, Steps: 34 | Train Loss: 0.4287860 Vali Loss: 0.2632283 Test Loss: 1.7881076\n","Validation loss decreased (0.279281 --> 0.263228).  Saving model ...\n","Updating learning rate to 3.90625e-05\n","Epoch: 8 cost time: 1.1499981880187988\n","Epoch: 8, Steps: 34 | Train Loss: 0.4148549 Vali Loss: 0.2749872 Test Loss: 1.7697378\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.953125e-05\n","Epoch: 9 cost time: 1.1043455600738525\n","Epoch: 9, Steps: 34 | Train Loss: 0.4101295 Vali Loss: 0.2548890 Test Loss: 1.7696711\n","Validation loss decreased (0.263228 --> 0.254889).  Saving model ...\n","Updating learning rate to 9.765625e-06\n","Epoch: 10 cost time: 1.1365306377410889\n","Epoch: 10, Steps: 34 | Train Loss: 0.4179393 Vali Loss: 0.2616201 Test Loss: 1.7721723\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.8828125e-06\n","Epoch: 11 cost time: 1.1126368045806885\n","Epoch: 11, Steps: 34 | Train Loss: 0.4094789 Vali Loss: 0.2759988 Test Loss: 1.7827257\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.44140625e-06\n","Epoch: 12 cost time: 1.2256004810333252\n","Epoch: 12, Steps: 34 | Train Loss: 0.4214276 Vali Loss: 0.2760529 Test Loss: 1.7653221\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.220703125e-06\n","Epoch: 13 cost time: 1.190739393234253\n","Epoch: 13, Steps: 34 | Train Loss: 0.4158197 Vali Loss: 0.2799103 Test Loss: 1.7742081\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 6.103515625e-07\n","Epoch: 14 cost time: 1.0791864395141602\n","Epoch: 14, Steps: 34 | Train Loss: 0.4186948 Vali Loss: 0.2631568 Test Loss: 1.7697771\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 3.0517578125e-07\n","Epoch: 15 cost time: 1.1699578762054443\n","Epoch: 15, Steps: 34 | Train Loss: 0.4202535 Vali Loss: 0.2477603 Test Loss: 1.7725109\n","Validation loss decreased (0.254889 --> 0.247760).  Saving model ...\n","Updating learning rate to 1.52587890625e-07\n","Epoch: 16 cost time: 1.1206207275390625\n","Epoch: 16, Steps: 34 | Train Loss: 0.4160323 Vali Loss: 0.2671975 Test Loss: 1.7687519\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.62939453125e-08\n","Epoch: 17 cost time: 1.152268409729004\n","Epoch: 17, Steps: 34 | Train Loss: 0.4104624 Vali Loss: 0.2702768 Test Loss: 1.7738292\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.814697265625e-08\n","Epoch: 18 cost time: 1.2075834274291992\n","Epoch: 18, Steps: 34 | Train Loss: 0.4199736 Vali Loss: 0.2712404 Test Loss: 1.7668178\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.9073486328125e-08\n","Epoch: 19 cost time: 1.132763147354126\n","Epoch: 19, Steps: 34 | Train Loss: 0.4192123 Vali Loss: 0.2769059 Test Loss: 1.7698961\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 9.5367431640625e-09\n","Epoch: 20 cost time: 1.1141674518585205\n","Epoch: 20, Steps: 34 | Train Loss: 0.4176785 Vali Loss: 0.2854533 Test Loss: 1.7608610\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 4.76837158203125e-09\n","Epoch: 21 cost time: 1.1580138206481934\n","Epoch: 21, Steps: 34 | Train Loss: 0.4187311 Vali Loss: 0.2742484 Test Loss: 1.7678473\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 2.384185791015625e-09\n","Epoch: 22 cost time: 1.106821060180664\n","Epoch: 22, Steps: 34 | Train Loss: 0.4185360 Vali Loss: 0.2812598 Test Loss: 1.7879616\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 1.1920928955078125e-09\n","Epoch: 23 cost time: 1.1587340831756592\n","Epoch: 23, Steps: 34 | Train Loss: 0.4183308 Vali Loss: 0.2821555 Test Loss: 1.7760870\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 5.960464477539063e-10\n","Epoch: 24 cost time: 1.125201940536499\n","Epoch: 24, Steps: 34 | Train Loss: 0.4179240 Vali Loss: 0.2619759 Test Loss: 1.7725338\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 2.9802322387695313e-10\n","Epoch: 25 cost time: 1.1176588535308838\n","Epoch: 25, Steps: 34 | Train Loss: 0.4119145 Vali Loss: 0.2809035 Test Loss: 1.7619355\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 1.4901161193847657e-10\n","Epoch: 26 cost time: 1.12367582321167\n","Epoch: 26, Steps: 34 | Train Loss: 0.4170869 Vali Loss: 0.2500967 Test Loss: 1.7802036\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 7.450580596923828e-11\n","Epoch: 27 cost time: 1.1323142051696777\n","Epoch: 27, Steps: 34 | Train Loss: 0.4186942 Vali Loss: 0.2619231 Test Loss: 1.7670791\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 3.725290298461914e-11\n","Epoch: 28 cost time: 1.1481339931488037\n","Epoch: 28, Steps: 34 | Train Loss: 0.4205817 Vali Loss: 0.2928762 Test Loss: 1.7681999\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.862645149230957e-11\n","Epoch: 29 cost time: 1.1953425407409668\n","Epoch: 29, Steps: 34 | Train Loss: 0.4197179 Vali Loss: 0.2782843 Test Loss: 1.7778677\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 9.313225746154785e-12\n","Epoch: 30 cost time: 1.1036906242370605\n","Epoch: 30, Steps: 34 | Train Loss: 0.4144435 Vali Loss: 0.2704024 Test Loss: 1.7686989\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 4.656612873077393e-12\n","Epoch: 31 cost time: 1.1167595386505127\n","Epoch: 31, Steps: 34 | Train Loss: 0.4193612 Vali Loss: 0.2643463 Test Loss: 1.7716644\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 2.3283064365386963e-12\n","Epoch: 32 cost time: 1.118452548980713\n","Epoch: 32, Steps: 34 | Train Loss: 0.4098099 Vali Loss: 0.2515756 Test Loss: 1.7563350\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 1.1641532182693482e-12\n","Epoch: 33 cost time: 1.1452479362487793\n","Epoch: 33, Steps: 34 | Train Loss: 0.4189739 Vali Loss: 0.2588596 Test Loss: 1.7648304\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 5.820766091346741e-13\n","Epoch: 34 cost time: 1.1900060176849365\n","Epoch: 34, Steps: 34 | Train Loss: 0.4195673 Vali Loss: 0.2719043 Test Loss: 1.7705748\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 2.9103830456733704e-13\n","Epoch: 35 cost time: 1.1020429134368896\n","Epoch: 35, Steps: 34 | Train Loss: 0.4104810 Vali Loss: 0.2632844 Test Loss: 1.7741601\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 1.4551915228366852e-13\n","Epoch: 36 cost time: 1.139751672744751\n","Epoch: 36, Steps: 34 | Train Loss: 0.4180385 Vali Loss: 0.2714849 Test Loss: 1.7710085\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 7.275957614183426e-14\n","Epoch: 37 cost time: 1.1367177963256836\n","Epoch: 37, Steps: 34 | Train Loss: 0.4116326 Vali Loss: 0.2811040 Test Loss: 1.7734085\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 3.637978807091713e-14\n","Epoch: 38 cost time: 1.1237282752990723\n","Epoch: 38, Steps: 34 | Train Loss: 0.4159267 Vali Loss: 0.2651641 Test Loss: 1.7722991\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 1.8189894035458565e-14\n","Epoch: 39 cost time: 1.1483778953552246\n","Epoch: 39, Steps: 34 | Train Loss: 0.4146232 Vali Loss: 0.2741661 Test Loss: 1.7829195\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 9.094947017729283e-15\n","Epoch: 40 cost time: 1.1504454612731934\n","Epoch: 40, Steps: 34 | Train Loss: 0.4193210 Vali Loss: 0.2957947 Test Loss: 1.7660986\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 4.547473508864641e-15\n","Epoch: 41 cost time: 1.130136489868164\n","Epoch: 41, Steps: 34 | Train Loss: 0.4160815 Vali Loss: 0.2644728 Test Loss: 1.7699093\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 2.2737367544323206e-15\n","Epoch: 42 cost time: 1.10660982131958\n","Epoch: 42, Steps: 34 | Train Loss: 0.4225851 Vali Loss: 0.2779468 Test Loss: 1.7682884\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 1.1368683772161603e-15\n","Epoch: 43 cost time: 1.121295690536499\n","Epoch: 43, Steps: 34 | Train Loss: 0.4204981 Vali Loss: 0.2740168 Test Loss: 1.7811505\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 5.684341886080802e-16\n","Epoch: 44 cost time: 1.2009456157684326\n","Epoch: 44, Steps: 34 | Train Loss: 0.4174678 Vali Loss: 0.2796422 Test Loss: 1.7731336\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 2.842170943040401e-16\n","Epoch: 45 cost time: 1.207228422164917\n","Epoch: 45, Steps: 34 | Train Loss: 0.4146552 Vali Loss: 0.2821195 Test Loss: 1.7592125\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 1.4210854715202004e-16\n","Epoch: 46 cost time: 1.120530605316162\n","Epoch: 46, Steps: 34 | Train Loss: 0.4116954 Vali Loss: 0.2787618 Test Loss: 1.7637622\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 7.105427357601002e-17\n","Epoch: 47 cost time: 1.147711992263794\n","Epoch: 47, Steps: 34 | Train Loss: 0.4170559 Vali Loss: 0.2812037 Test Loss: 1.7804892\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 3.552713678800501e-17\n","Epoch: 48 cost time: 1.134918212890625\n","Epoch: 48, Steps: 34 | Train Loss: 0.4235260 Vali Loss: 0.2744755 Test Loss: 1.7813852\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 1.7763568394002505e-17\n","Epoch: 49 cost time: 1.2257637977600098\n","Epoch: 49, Steps: 34 | Train Loss: 0.4165298 Vali Loss: 0.2859055 Test Loss: 1.7568798\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 8.881784197001253e-18\n","Epoch: 50 cost time: 1.1858716011047363\n","Epoch: 50, Steps: 34 | Train Loss: 0.4073011 Vali Loss: 0.2720928 Test Loss: 1.7743847\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 4.440892098500626e-18\n","Epoch: 51 cost time: 1.1553311347961426\n","Epoch: 51, Steps: 34 | Train Loss: 0.4153414 Vali Loss: 0.2737816 Test Loss: 1.7665266\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 2.220446049250313e-18\n","Epoch: 52 cost time: 1.1194214820861816\n","Epoch: 52, Steps: 34 | Train Loss: 0.4092662 Vali Loss: 0.2819037 Test Loss: 1.7810402\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 1.1102230246251566e-18\n","Epoch: 53 cost time: 1.162196397781372\n","Epoch: 53, Steps: 34 | Train Loss: 0.4106032 Vali Loss: 0.2796871 Test Loss: 1.7792699\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 5.551115123125783e-19\n","Epoch: 54 cost time: 1.1615393161773682\n","Epoch: 54, Steps: 34 | Train Loss: 0.4190828 Vali Loss: 0.2682680 Test Loss: 1.7678505\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 2.7755575615628914e-19\n","Epoch: 55 cost time: 1.2286639213562012\n","Epoch: 55, Steps: 34 | Train Loss: 0.4178466 Vali Loss: 0.2880770 Test Loss: 1.7898779\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 1.3877787807814457e-19\n","Epoch: 56 cost time: 1.1587238311767578\n","Epoch: 56, Steps: 34 | Train Loss: 0.4172948 Vali Loss: 0.2811595 Test Loss: 1.7530949\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 6.938893903907229e-20\n","Epoch: 57 cost time: 1.1176509857177734\n","Epoch: 57, Steps: 34 | Train Loss: 0.4168437 Vali Loss: 0.2726640 Test Loss: 1.7851988\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 3.469446951953614e-20\n","Epoch: 58 cost time: 1.134033203125\n","Epoch: 58, Steps: 34 | Train Loss: 0.4162243 Vali Loss: 0.2927425 Test Loss: 1.7719027\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 1.734723475976807e-20\n","Epoch: 59 cost time: 1.1323773860931396\n","Epoch: 59, Steps: 34 | Train Loss: 0.4179076 Vali Loss: 0.2677178 Test Loss: 1.7673191\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 8.673617379884036e-21\n","Epoch: 60 cost time: 1.1828608512878418\n","Epoch: 60, Steps: 34 | Train Loss: 0.4183477 Vali Loss: 0.2766556 Test Loss: 1.7850904\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 4.336808689942018e-21\n","Epoch: 61 cost time: 1.2047152519226074\n","Epoch: 61, Steps: 34 | Train Loss: 0.4130160 Vali Loss: 0.2566609 Test Loss: 1.7625220\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 2.168404344971009e-21\n","Epoch: 62 cost time: 1.1461820602416992\n","Epoch: 62, Steps: 34 | Train Loss: 0.4151237 Vali Loss: 0.2860529 Test Loss: 1.7701508\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 1.0842021724855045e-21\n","Epoch: 63 cost time: 1.1442365646362305\n","Epoch: 63, Steps: 34 | Train Loss: 0.4091793 Vali Loss: 0.2873747 Test Loss: 1.7886842\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 5.421010862427522e-22\n","Epoch: 64 cost time: 1.1071410179138184\n","Epoch: 64, Steps: 34 | Train Loss: 0.4174153 Vali Loss: 0.2875662 Test Loss: 1.7876221\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 2.710505431213761e-22\n","Epoch: 65 cost time: 1.2391157150268555\n","Epoch: 65, Steps: 34 | Train Loss: 0.4147483 Vali Loss: 0.2783882 Test Loss: 1.7750956\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 1.3552527156068806e-22\n","Epoch: 66 cost time: 1.20204758644104\n","Epoch: 66, Steps: 34 | Train Loss: 0.4207105 Vali Loss: 0.2789467 Test Loss: 1.7665033\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 6.776263578034403e-23\n","Epoch: 67 cost time: 1.1078829765319824\n","Epoch: 67, Steps: 34 | Train Loss: 0.4185976 Vali Loss: 0.2685583 Test Loss: 1.7675560\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 3.3881317890172014e-23\n","Epoch: 68 cost time: 1.1192967891693115\n","Epoch: 68, Steps: 34 | Train Loss: 0.4186582 Vali Loss: 0.2814195 Test Loss: 1.7666891\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 1.6940658945086007e-23\n","Epoch: 69 cost time: 1.1250779628753662\n","Epoch: 69, Steps: 34 | Train Loss: 0.4195557 Vali Loss: 0.2570412 Test Loss: 1.7675642\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 8.470329472543004e-24\n","Epoch: 70 cost time: 1.1804299354553223\n","Epoch: 70, Steps: 34 | Train Loss: 0.4074060 Vali Loss: 0.2843679 Test Loss: 1.7639043\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 4.235164736271502e-24\n","Epoch: 71 cost time: 1.1896119117736816\n","Epoch: 71, Steps: 34 | Train Loss: 0.4170484 Vali Loss: 0.2627937 Test Loss: 1.7707866\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 2.117582368135751e-24\n","Epoch: 72 cost time: 1.1249558925628662\n","Epoch: 72, Steps: 34 | Train Loss: 0.4171210 Vali Loss: 0.2657086 Test Loss: 1.7611892\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 1.0587911840678754e-24\n","Epoch: 73 cost time: 1.1224849224090576\n","Epoch: 73, Steps: 34 | Train Loss: 0.4127940 Vali Loss: 0.2575466 Test Loss: 1.7679733\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 5.293955920339377e-25\n","Epoch: 74 cost time: 1.1516938209533691\n","Epoch: 74, Steps: 34 | Train Loss: 0.4117515 Vali Loss: 0.2759972 Test Loss: 1.7783539\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 2.6469779601696886e-25\n","Epoch: 75 cost time: 1.147951364517212\n","Epoch: 75, Steps: 34 | Train Loss: 0.4186920 Vali Loss: 0.2869261 Test Loss: 1.7706566\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 1.3234889800848443e-25\n","Epoch: 76 cost time: 1.2065060138702393\n","Epoch: 76, Steps: 34 | Train Loss: 0.4128374 Vali Loss: 0.2677522 Test Loss: 1.7745049\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 6.617444900424222e-26\n","Epoch: 77 cost time: 1.1460344791412354\n","Epoch: 77, Steps: 34 | Train Loss: 0.4201312 Vali Loss: 0.2734369 Test Loss: 1.7787983\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 3.308722450212111e-26\n","Epoch: 78 cost time: 1.121661901473999\n","Epoch: 78, Steps: 34 | Train Loss: 0.4146308 Vali Loss: 0.2751160 Test Loss: 1.7830147\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 1.6543612251060554e-26\n","Epoch: 79 cost time: 1.0985743999481201\n","Epoch: 79, Steps: 34 | Train Loss: 0.4200328 Vali Loss: 0.2698216 Test Loss: 1.7630684\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 8.271806125530277e-27\n","Epoch: 80 cost time: 1.1206965446472168\n","Epoch: 80, Steps: 34 | Train Loss: 0.4144869 Vali Loss: 0.2608651 Test Loss: 1.7815853\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 4.1359030627651385e-27\n","Epoch: 81 cost time: 1.2037947177886963\n","Epoch: 81, Steps: 34 | Train Loss: 0.4194710 Vali Loss: 0.2661430 Test Loss: 1.7764219\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 2.0679515313825692e-27\n","Epoch: 82 cost time: 1.2153799533843994\n","Epoch: 82, Steps: 34 | Train Loss: 0.4089946 Vali Loss: 0.2598615 Test Loss: 1.7596738\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 1.0339757656912846e-27\n","Epoch: 83 cost time: 1.1267173290252686\n","Epoch: 83, Steps: 34 | Train Loss: 0.4184428 Vali Loss: 0.2709659 Test Loss: 1.7644867\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 5.169878828456423e-28\n","Epoch: 84 cost time: 1.1660618782043457\n","Epoch: 84, Steps: 34 | Train Loss: 0.4123857 Vali Loss: 0.2745609 Test Loss: 1.7671713\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 2.5849394142282115e-28\n","Epoch: 85 cost time: 1.1765570640563965\n","Epoch: 85, Steps: 34 | Train Loss: 0.4158801 Vali Loss: 0.2765702 Test Loss: 1.7658964\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 1.2924697071141058e-28\n","Epoch: 86 cost time: 1.1702876091003418\n","Epoch: 86, Steps: 34 | Train Loss: 0.4198578 Vali Loss: 0.2760349 Test Loss: 1.7650058\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 6.462348535570529e-29\n","Epoch: 87 cost time: 1.2119834423065186\n","Epoch: 87, Steps: 34 | Train Loss: 0.4171412 Vali Loss: 0.2868549 Test Loss: 1.7426932\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 3.2311742677852644e-29\n","Epoch: 88 cost time: 1.1320245265960693\n","Epoch: 88, Steps: 34 | Train Loss: 0.4193321 Vali Loss: 0.2816569 Test Loss: 1.7741715\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 1.6155871338926322e-29\n","Epoch: 89 cost time: 1.1308505535125732\n","Epoch: 89, Steps: 34 | Train Loss: 0.4179288 Vali Loss: 0.2700374 Test Loss: 1.7635329\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 8.077935669463161e-30\n","Epoch: 90 cost time: 1.1574108600616455\n","Epoch: 90, Steps: 34 | Train Loss: 0.4171924 Vali Loss: 0.2582240 Test Loss: 1.7688233\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 4.0389678347315805e-30\n","Epoch: 91 cost time: 1.1661908626556396\n","Epoch: 91, Steps: 34 | Train Loss: 0.4175129 Vali Loss: 0.2812691 Test Loss: 1.7817396\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 2.0194839173657903e-30\n","Epoch: 92 cost time: 1.2456269264221191\n","Epoch: 92, Steps: 34 | Train Loss: 0.4184952 Vali Loss: 0.2797837 Test Loss: 1.7825686\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 1.0097419586828951e-30\n","Epoch: 93 cost time: 1.1201462745666504\n","Epoch: 93, Steps: 34 | Train Loss: 0.4184037 Vali Loss: 0.2655996 Test Loss: 1.7766578\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 5.048709793414476e-31\n","Epoch: 94 cost time: 1.1365132331848145\n","Epoch: 94, Steps: 34 | Train Loss: 0.4131631 Vali Loss: 0.2848024 Test Loss: 1.7730734\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 2.524354896707238e-31\n","Epoch: 95 cost time: 1.1363921165466309\n","Epoch: 95, Steps: 34 | Train Loss: 0.4192091 Vali Loss: 0.2703005 Test Loss: 1.7757518\n","EarlyStopping counter: 80 out of 100\n","Updating learning rate to 1.262177448353619e-31\n","Epoch: 96 cost time: 1.1457860469818115\n","Epoch: 96, Steps: 34 | Train Loss: 0.4187155 Vali Loss: 0.2569422 Test Loss: 1.7686064\n","EarlyStopping counter: 81 out of 100\n","Updating learning rate to 6.310887241768095e-32\n","Epoch: 97 cost time: 1.249356746673584\n","Epoch: 97, Steps: 34 | Train Loss: 0.4182556 Vali Loss: 0.2483657 Test Loss: 1.7648773\n","EarlyStopping counter: 82 out of 100\n","Updating learning rate to 3.1554436208840473e-32\n","Epoch: 98 cost time: 1.1889796257019043\n","Epoch: 98, Steps: 34 | Train Loss: 0.4152496 Vali Loss: 0.2439527 Test Loss: 1.7841251\n","Validation loss decreased (0.247760 --> 0.243953).  Saving model ...\n","Updating learning rate to 1.5777218104420236e-32\n","Epoch: 99 cost time: 1.156311273574829\n","Epoch: 99, Steps: 34 | Train Loss: 0.4079426 Vali Loss: 0.2533726 Test Loss: 1.7840765\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.888609052210118e-33\n","Epoch: 100 cost time: 1.1782808303833008\n","Epoch: 100, Steps: 34 | Train Loss: 0.4176430 Vali Loss: 0.2676055 Test Loss: 1.7548821\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.944304526105059e-33\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl24_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 170\n","mse:1.7841250896453857, mae:0.875597357749939, rse:0.6445915102958679\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl24_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  36\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  0\n","Exp_Main init!\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl36_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 537\n","val 62\n","test 158\n","Epoch: 1 cost time: 1.1751463413238525\n","Epoch: 1, Steps: 33 | Train Loss: 0.9323220 Vali Loss: 0.3237324 Test Loss: 2.6658745\n","Validation loss decreased (inf --> 0.323732).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 1.2178454399108887\n","Epoch: 2, Steps: 33 | Train Loss: 0.8232885 Vali Loss: 0.3587404 Test Loss: 2.5504990\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.00125\n","Epoch: 3 cost time: 1.1418869495391846\n","Epoch: 3, Steps: 33 | Train Loss: 0.5749713 Vali Loss: 0.3081205 Test Loss: 2.0031755\n","Validation loss decreased (0.323732 --> 0.308121).  Saving model ...\n","Updating learning rate to 0.000625\n","Epoch: 4 cost time: 1.1506016254425049\n","Epoch: 4, Steps: 33 | Train Loss: 0.5085555 Vali Loss: 0.2580134 Test Loss: 1.8024458\n","Validation loss decreased (0.308121 --> 0.258013).  Saving model ...\n","Updating learning rate to 0.0003125\n","Epoch: 5 cost time: 1.1438190937042236\n","Epoch: 5, Steps: 33 | Train Loss: 0.4782279 Vali Loss: 0.2439761 Test Loss: 1.9292502\n","Validation loss decreased (0.258013 --> 0.243976).  Saving model ...\n","Updating learning rate to 0.00015625\n","Epoch: 6 cost time: 1.1484975814819336\n","Epoch: 6, Steps: 33 | Train Loss: 0.4648334 Vali Loss: 0.2662011 Test Loss: 1.8542734\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.8125e-05\n","Epoch: 7 cost time: 1.2093210220336914\n","Epoch: 7, Steps: 33 | Train Loss: 0.4641209 Vali Loss: 0.2639651 Test Loss: 1.8970460\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.90625e-05\n","Epoch: 8 cost time: 1.175607681274414\n","Epoch: 8, Steps: 33 | Train Loss: 0.4587731 Vali Loss: 0.2323835 Test Loss: 1.8699913\n","Validation loss decreased (0.243976 --> 0.232384).  Saving model ...\n","Updating learning rate to 1.953125e-05\n","Epoch: 9 cost time: 1.151923656463623\n","Epoch: 9, Steps: 33 | Train Loss: 0.4575896 Vali Loss: 0.2312629 Test Loss: 1.8654929\n","Validation loss decreased (0.232384 --> 0.231263).  Saving model ...\n","Updating learning rate to 9.765625e-06\n","Epoch: 10 cost time: 1.182098150253296\n","Epoch: 10, Steps: 33 | Train Loss: 0.4580971 Vali Loss: 0.2304064 Test Loss: 1.8671398\n","Validation loss decreased (0.231263 --> 0.230406).  Saving model ...\n","Updating learning rate to 4.8828125e-06\n","Epoch: 11 cost time: 1.1556472778320312\n","Epoch: 11, Steps: 33 | Train Loss: 0.4500567 Vali Loss: 0.2554692 Test Loss: 1.8514699\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 2.44140625e-06\n","Epoch: 12 cost time: 1.2224011421203613\n","Epoch: 12, Steps: 33 | Train Loss: 0.4533201 Vali Loss: 0.2459515 Test Loss: 1.8551341\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.220703125e-06\n","Epoch: 13 cost time: 1.1530780792236328\n","Epoch: 13, Steps: 33 | Train Loss: 0.4491738 Vali Loss: 0.2392278 Test Loss: 1.8506821\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 6.103515625e-07\n","Epoch: 14 cost time: 1.1236093044281006\n","Epoch: 14, Steps: 33 | Train Loss: 0.4518324 Vali Loss: 0.2464622 Test Loss: 1.8529680\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 3.0517578125e-07\n","Epoch: 15 cost time: 1.1649143695831299\n","Epoch: 15, Steps: 33 | Train Loss: 0.4586174 Vali Loss: 0.2438274 Test Loss: 1.8622845\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.52587890625e-07\n","Epoch: 16 cost time: 1.14231538772583\n","Epoch: 16, Steps: 33 | Train Loss: 0.4524695 Vali Loss: 0.2248641 Test Loss: 1.8640734\n","Validation loss decreased (0.230406 --> 0.224864).  Saving model ...\n","Updating learning rate to 7.62939453125e-08\n","Epoch: 17 cost time: 1.209181547164917\n","Epoch: 17, Steps: 33 | Train Loss: 0.4561702 Vali Loss: 0.2384162 Test Loss: 1.8604891\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.814697265625e-08\n","Epoch: 18 cost time: 1.2101335525512695\n","Epoch: 18, Steps: 33 | Train Loss: 0.4569373 Vali Loss: 0.2510426 Test Loss: 1.8603426\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.9073486328125e-08\n","Epoch: 19 cost time: 1.1549701690673828\n","Epoch: 19, Steps: 33 | Train Loss: 0.4556226 Vali Loss: 0.2459267 Test Loss: 1.8603624\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 9.5367431640625e-09\n","Epoch: 20 cost time: 1.1251938343048096\n","Epoch: 20, Steps: 33 | Train Loss: 0.4546209 Vali Loss: 0.2543219 Test Loss: 1.8700689\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 4.76837158203125e-09\n","Epoch: 21 cost time: 1.151019811630249\n","Epoch: 21, Steps: 33 | Train Loss: 0.4577282 Vali Loss: 0.2566466 Test Loss: 1.8657725\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.384185791015625e-09\n","Epoch: 22 cost time: 1.2333950996398926\n","Epoch: 22, Steps: 33 | Train Loss: 0.4569625 Vali Loss: 0.2451836 Test Loss: 1.8624802\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.1920928955078125e-09\n","Epoch: 23 cost time: 1.2093024253845215\n","Epoch: 23, Steps: 33 | Train Loss: 0.4512257 Vali Loss: 0.2588550 Test Loss: 1.8596170\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 5.960464477539063e-10\n","Epoch: 24 cost time: 1.1343724727630615\n","Epoch: 24, Steps: 33 | Train Loss: 0.4505453 Vali Loss: 0.2594520 Test Loss: 1.8601165\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 2.9802322387695313e-10\n","Epoch: 25 cost time: 1.1537549495697021\n","Epoch: 25, Steps: 33 | Train Loss: 0.4589957 Vali Loss: 0.2414740 Test Loss: 1.8468668\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.4901161193847657e-10\n","Epoch: 26 cost time: 1.1088194847106934\n","Epoch: 26, Steps: 33 | Train Loss: 0.4520598 Vali Loss: 0.2380130 Test Loss: 1.8564649\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 7.450580596923828e-11\n","Epoch: 27 cost time: 1.2481169700622559\n","Epoch: 27, Steps: 33 | Train Loss: 0.4584543 Vali Loss: 0.2277438 Test Loss: 1.8533976\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 3.725290298461914e-11\n","Epoch: 28 cost time: 1.2461051940917969\n","Epoch: 28, Steps: 33 | Train Loss: 0.4554703 Vali Loss: 0.2466353 Test Loss: 1.8809474\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.862645149230957e-11\n","Epoch: 29 cost time: 1.154038906097412\n","Epoch: 29, Steps: 33 | Train Loss: 0.4461321 Vali Loss: 0.2433656 Test Loss: 1.8420080\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 9.313225746154785e-12\n","Epoch: 30 cost time: 1.1595091819763184\n","Epoch: 30, Steps: 33 | Train Loss: 0.4581205 Vali Loss: 0.2582349 Test Loss: 1.8524685\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 4.656612873077393e-12\n","Epoch: 31 cost time: 1.1372294425964355\n","Epoch: 31, Steps: 33 | Train Loss: 0.4544074 Vali Loss: 0.2346084 Test Loss: 1.8368688\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 2.3283064365386963e-12\n","Epoch: 32 cost time: 1.203810453414917\n","Epoch: 32, Steps: 33 | Train Loss: 0.4542245 Vali Loss: 0.2504117 Test Loss: 1.8417439\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.1641532182693482e-12\n","Epoch: 33 cost time: 1.2466464042663574\n","Epoch: 33, Steps: 33 | Train Loss: 0.4510021 Vali Loss: 0.2322176 Test Loss: 1.8650241\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 5.820766091346741e-13\n","Epoch: 34 cost time: 1.1800832748413086\n","Epoch: 34, Steps: 33 | Train Loss: 0.4525577 Vali Loss: 0.2534303 Test Loss: 1.8625243\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 2.9103830456733704e-13\n","Epoch: 35 cost time: 1.1621308326721191\n","Epoch: 35, Steps: 33 | Train Loss: 0.4566067 Vali Loss: 0.2504494 Test Loss: 1.8515716\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.4551915228366852e-13\n","Epoch: 36 cost time: 1.1506707668304443\n","Epoch: 36, Steps: 33 | Train Loss: 0.4588530 Vali Loss: 0.2384592 Test Loss: 1.8330199\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 7.275957614183426e-14\n","Epoch: 37 cost time: 1.1790082454681396\n","Epoch: 37, Steps: 33 | Train Loss: 0.4566162 Vali Loss: 0.2515555 Test Loss: 1.8547361\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 3.637978807091713e-14\n","Epoch: 38 cost time: 1.2648553848266602\n","Epoch: 38, Steps: 33 | Train Loss: 0.4504056 Vali Loss: 0.2406489 Test Loss: 1.8434103\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 1.8189894035458565e-14\n","Epoch: 39 cost time: 1.1442153453826904\n","Epoch: 39, Steps: 33 | Train Loss: 0.4559928 Vali Loss: 0.2461384 Test Loss: 1.8239057\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 9.094947017729283e-15\n","Epoch: 40 cost time: 1.159226894378662\n","Epoch: 40, Steps: 33 | Train Loss: 0.4576752 Vali Loss: 0.2473128 Test Loss: 1.8467422\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 4.547473508864641e-15\n","Epoch: 41 cost time: 1.1666436195373535\n","Epoch: 41, Steps: 33 | Train Loss: 0.4565872 Vali Loss: 0.2397377 Test Loss: 1.8557363\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 2.2737367544323206e-15\n","Epoch: 42 cost time: 1.1589295864105225\n","Epoch: 42, Steps: 33 | Train Loss: 0.4566751 Vali Loss: 0.2581773 Test Loss: 1.8581529\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 1.1368683772161603e-15\n","Epoch: 43 cost time: 1.2851927280426025\n","Epoch: 43, Steps: 33 | Train Loss: 0.4499600 Vali Loss: 0.2548110 Test Loss: 1.8580846\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 5.684341886080802e-16\n","Epoch: 44 cost time: 1.1283671855926514\n","Epoch: 44, Steps: 33 | Train Loss: 0.4539054 Vali Loss: 0.2339954 Test Loss: 1.8484756\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 2.842170943040401e-16\n","Epoch: 45 cost time: 1.149764060974121\n","Epoch: 45, Steps: 33 | Train Loss: 0.4592905 Vali Loss: 0.2578331 Test Loss: 1.8731512\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 1.4210854715202004e-16\n","Epoch: 46 cost time: 1.173949956893921\n","Epoch: 46, Steps: 33 | Train Loss: 0.4526623 Vali Loss: 0.2246764 Test Loss: 1.8548995\n","Validation loss decreased (0.224864 --> 0.224676).  Saving model ...\n","Updating learning rate to 7.105427357601002e-17\n","Epoch: 47 cost time: 1.1707212924957275\n","Epoch: 47, Steps: 33 | Train Loss: 0.4566791 Vali Loss: 0.2563261 Test Loss: 1.8522078\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.552713678800501e-17\n","Epoch: 48 cost time: 1.2682626247406006\n","Epoch: 48, Steps: 33 | Train Loss: 0.4592597 Vali Loss: 0.2365225 Test Loss: 1.8416663\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.7763568394002505e-17\n","Epoch: 49 cost time: 1.1807730197906494\n","Epoch: 49, Steps: 33 | Train Loss: 0.4573921 Vali Loss: 0.2605505 Test Loss: 1.8444676\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 8.881784197001253e-18\n","Epoch: 50 cost time: 1.182328701019287\n","Epoch: 50, Steps: 33 | Train Loss: 0.4570303 Vali Loss: 0.2462795 Test Loss: 1.8477985\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 4.440892098500626e-18\n","Epoch: 51 cost time: 1.1873457431793213\n","Epoch: 51, Steps: 33 | Train Loss: 0.4575484 Vali Loss: 0.2395877 Test Loss: 1.8525567\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.220446049250313e-18\n","Epoch: 52 cost time: 1.1875231266021729\n","Epoch: 52, Steps: 33 | Train Loss: 0.4555307 Vali Loss: 0.2427992 Test Loss: 1.8602282\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.1102230246251566e-18\n","Epoch: 53 cost time: 1.2460458278656006\n","Epoch: 53, Steps: 33 | Train Loss: 0.4445718 Vali Loss: 0.2434220 Test Loss: 1.8528192\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 5.551115123125783e-19\n","Epoch: 54 cost time: 1.2033376693725586\n","Epoch: 54, Steps: 33 | Train Loss: 0.4509872 Vali Loss: 0.2539670 Test Loss: 1.8527309\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 2.7755575615628914e-19\n","Epoch: 55 cost time: 1.1638739109039307\n","Epoch: 55, Steps: 33 | Train Loss: 0.4526344 Vali Loss: 0.2516921 Test Loss: 1.8622712\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.3877787807814457e-19\n","Epoch: 56 cost time: 1.225527048110962\n","Epoch: 56, Steps: 33 | Train Loss: 0.4527481 Vali Loss: 0.2279648 Test Loss: 1.8486543\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 6.938893903907229e-20\n","Epoch: 57 cost time: 1.1720945835113525\n","Epoch: 57, Steps: 33 | Train Loss: 0.4557975 Vali Loss: 0.2612033 Test Loss: 1.8585525\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 3.469446951953614e-20\n","Epoch: 58 cost time: 1.2529075145721436\n","Epoch: 58, Steps: 33 | Train Loss: 0.4461230 Vali Loss: 0.2341605 Test Loss: 1.8652886\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.734723475976807e-20\n","Epoch: 59 cost time: 1.1982042789459229\n","Epoch: 59, Steps: 33 | Train Loss: 0.4492371 Vali Loss: 0.2535099 Test Loss: 1.8419285\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 8.673617379884036e-21\n","Epoch: 60 cost time: 1.162635087966919\n","Epoch: 60, Steps: 33 | Train Loss: 0.4548899 Vali Loss: 0.2494548 Test Loss: 1.8596196\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 4.336808689942018e-21\n","Epoch: 61 cost time: 1.1602544784545898\n","Epoch: 61, Steps: 33 | Train Loss: 0.4542396 Vali Loss: 0.2482504 Test Loss: 1.8644900\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 2.168404344971009e-21\n","Epoch: 62 cost time: 1.190108299255371\n","Epoch: 62, Steps: 33 | Train Loss: 0.4494433 Vali Loss: 0.2464659 Test Loss: 1.8592020\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.0842021724855045e-21\n","Epoch: 63 cost time: 1.2356843948364258\n","Epoch: 63, Steps: 33 | Train Loss: 0.4575794 Vali Loss: 0.2497778 Test Loss: 1.8560257\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 5.421010862427522e-22\n","Epoch: 64 cost time: 1.256953239440918\n","Epoch: 64, Steps: 33 | Train Loss: 0.4453520 Vali Loss: 0.2504235 Test Loss: 1.8633096\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 2.710505431213761e-22\n","Epoch: 65 cost time: 1.1679754257202148\n","Epoch: 65, Steps: 33 | Train Loss: 0.4512457 Vali Loss: 0.2418943 Test Loss: 1.8644990\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.3552527156068806e-22\n","Epoch: 66 cost time: 1.1702067852020264\n","Epoch: 66, Steps: 33 | Train Loss: 0.4512601 Vali Loss: 0.2530686 Test Loss: 1.8419800\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 6.776263578034403e-23\n","Epoch: 67 cost time: 1.1522352695465088\n","Epoch: 67, Steps: 33 | Train Loss: 0.4532742 Vali Loss: 0.2397376 Test Loss: 1.8373551\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 3.3881317890172014e-23\n","Epoch: 68 cost time: 1.2753210067749023\n","Epoch: 68, Steps: 33 | Train Loss: 0.4575518 Vali Loss: 0.2591988 Test Loss: 1.8671002\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 1.6940658945086007e-23\n","Epoch: 69 cost time: 1.2785210609436035\n","Epoch: 69, Steps: 33 | Train Loss: 0.4540219 Vali Loss: 0.2293342 Test Loss: 1.8496145\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 8.470329472543004e-24\n","Epoch: 70 cost time: 1.1752736568450928\n","Epoch: 70, Steps: 33 | Train Loss: 0.4494679 Vali Loss: 0.2521225 Test Loss: 1.8686929\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 4.235164736271502e-24\n","Epoch: 71 cost time: 1.1723551750183105\n","Epoch: 71, Steps: 33 | Train Loss: 0.4583134 Vali Loss: 0.2541755 Test Loss: 1.8569692\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 2.117582368135751e-24\n","Epoch: 72 cost time: 1.1629111766815186\n","Epoch: 72, Steps: 33 | Train Loss: 0.4587898 Vali Loss: 0.2510096 Test Loss: 1.8679390\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 1.0587911840678754e-24\n","Epoch: 73 cost time: 1.2561366558074951\n","Epoch: 73, Steps: 33 | Train Loss: 0.4532059 Vali Loss: 0.2299789 Test Loss: 1.8532577\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 5.293955920339377e-25\n","Epoch: 74 cost time: 1.2708065509796143\n","Epoch: 74, Steps: 33 | Train Loss: 0.4547697 Vali Loss: 0.2506914 Test Loss: 1.8530638\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 2.6469779601696886e-25\n","Epoch: 75 cost time: 1.1821050643920898\n","Epoch: 75, Steps: 33 | Train Loss: 0.4606468 Vali Loss: 0.2382588 Test Loss: 1.8351811\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 1.3234889800848443e-25\n","Epoch: 76 cost time: 1.1474487781524658\n","Epoch: 76, Steps: 33 | Train Loss: 0.4556566 Vali Loss: 0.2414920 Test Loss: 1.8360070\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 6.617444900424222e-26\n","Epoch: 77 cost time: 1.143712043762207\n","Epoch: 77, Steps: 33 | Train Loss: 0.4570339 Vali Loss: 0.2293068 Test Loss: 1.8415037\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 3.308722450212111e-26\n","Epoch: 78 cost time: 1.2552056312561035\n","Epoch: 78, Steps: 33 | Train Loss: 0.4587101 Vali Loss: 0.2603845 Test Loss: 1.8726420\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 1.6543612251060554e-26\n","Epoch: 79 cost time: 1.274315595626831\n","Epoch: 79, Steps: 33 | Train Loss: 0.4498833 Vali Loss: 0.2413601 Test Loss: 1.8528941\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 8.271806125530277e-27\n","Epoch: 80 cost time: 1.177497386932373\n","Epoch: 80, Steps: 33 | Train Loss: 0.4603839 Vali Loss: 0.2377443 Test Loss: 1.8738041\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 4.1359030627651385e-27\n","Epoch: 81 cost time: 1.176978349685669\n","Epoch: 81, Steps: 33 | Train Loss: 0.4555571 Vali Loss: 0.2620109 Test Loss: 1.8355772\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 2.0679515313825692e-27\n","Epoch: 82 cost time: 1.1673774719238281\n","Epoch: 82, Steps: 33 | Train Loss: 0.4521842 Vali Loss: 0.2499251 Test Loss: 1.8607559\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 1.0339757656912846e-27\n","Epoch: 83 cost time: 1.2574520111083984\n","Epoch: 83, Steps: 33 | Train Loss: 0.4501519 Vali Loss: 0.2499259 Test Loss: 1.8450977\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 5.169878828456423e-28\n","Epoch: 84 cost time: 1.255985975265503\n","Epoch: 84, Steps: 33 | Train Loss: 0.4478403 Vali Loss: 0.2268563 Test Loss: 1.8594766\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 2.5849394142282115e-28\n","Epoch: 85 cost time: 1.2029166221618652\n","Epoch: 85, Steps: 33 | Train Loss: 0.4547373 Vali Loss: 0.2571603 Test Loss: 1.8624156\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 1.2924697071141058e-28\n","Epoch: 86 cost time: 1.1675481796264648\n","Epoch: 86, Steps: 33 | Train Loss: 0.4507889 Vali Loss: 0.2455883 Test Loss: 1.8479214\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 6.462348535570529e-29\n","Epoch: 87 cost time: 1.1530447006225586\n","Epoch: 87, Steps: 33 | Train Loss: 0.4524017 Vali Loss: 0.2605684 Test Loss: 1.8491538\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 3.2311742677852644e-29\n","Epoch: 88 cost time: 1.2017173767089844\n","Epoch: 88, Steps: 33 | Train Loss: 0.4585385 Vali Loss: 0.2296880 Test Loss: 1.8467426\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 1.6155871338926322e-29\n","Epoch: 89 cost time: 1.246121883392334\n","Epoch: 89, Steps: 33 | Train Loss: 0.4436587 Vali Loss: 0.2714295 Test Loss: 1.8581469\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 8.077935669463161e-30\n","Epoch: 90 cost time: 1.1794729232788086\n","Epoch: 90, Steps: 33 | Train Loss: 0.4406157 Vali Loss: 0.2518098 Test Loss: 1.8336762\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 4.0389678347315805e-30\n","Epoch: 91 cost time: 1.1731724739074707\n","Epoch: 91, Steps: 33 | Train Loss: 0.4562360 Vali Loss: 0.2583933 Test Loss: 1.8656341\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 2.0194839173657903e-30\n","Epoch: 92 cost time: 1.1867005825042725\n","Epoch: 92, Steps: 33 | Train Loss: 0.4561995 Vali Loss: 0.2535136 Test Loss: 1.8422347\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 1.0097419586828951e-30\n","Epoch: 93 cost time: 1.2400312423706055\n","Epoch: 93, Steps: 33 | Train Loss: 0.4505670 Vali Loss: 0.2495730 Test Loss: 1.8424217\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 5.048709793414476e-31\n","Epoch: 94 cost time: 1.2600631713867188\n","Epoch: 94, Steps: 33 | Train Loss: 0.4530301 Vali Loss: 0.2553212 Test Loss: 1.8687218\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 2.524354896707238e-31\n","Epoch: 95 cost time: 1.1792354583740234\n","Epoch: 95, Steps: 33 | Train Loss: 0.4556505 Vali Loss: 0.2597410 Test Loss: 1.8476758\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 1.262177448353619e-31\n","Epoch: 96 cost time: 1.194080114364624\n","Epoch: 96, Steps: 33 | Train Loss: 0.4588542 Vali Loss: 0.2606158 Test Loss: 1.8520353\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 6.310887241768095e-32\n","Epoch: 97 cost time: 1.186617136001587\n","Epoch: 97, Steps: 33 | Train Loss: 0.4519884 Vali Loss: 0.2530477 Test Loss: 1.8612151\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 3.1554436208840473e-32\n","Epoch: 98 cost time: 1.205589771270752\n","Epoch: 98, Steps: 33 | Train Loss: 0.4538525 Vali Loss: 0.2351053 Test Loss: 1.8428794\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 1.5777218104420236e-32\n","Epoch: 99 cost time: 1.2856333255767822\n","Epoch: 99, Steps: 33 | Train Loss: 0.4571429 Vali Loss: 0.2420675 Test Loss: 1.8531783\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 7.888609052210118e-33\n","Epoch: 100 cost time: 1.2026751041412354\n","Epoch: 100, Steps: 33 | Train Loss: 0.4615845 Vali Loss: 0.2573780 Test Loss: 1.8741877\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 3.944304526105059e-33\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl36_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 158\n","mse:1.854899525642395, mae:0.8866918683052063, rse:0.6532000303268433\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl36_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  48\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  0\n","Exp_Main init!\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl48_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 525\n","val 50\n","test 146\n","Epoch: 1 cost time: 1.18369460105896\n","Epoch: 1, Steps: 32 | Train Loss: 0.9562644 Vali Loss: 0.3356616 Test Loss: 2.8134301\n","Validation loss decreased (inf --> 0.335662).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 1.1539106369018555\n","Epoch: 2, Steps: 32 | Train Loss: 0.8413760 Vali Loss: 0.4412788 Test Loss: 2.2021296\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.00125\n","Epoch: 3 cost time: 1.2567620277404785\n","Epoch: 3, Steps: 32 | Train Loss: 0.5836751 Vali Loss: 0.2598682 Test Loss: 1.8542682\n","Validation loss decreased (0.335662 --> 0.259868).  Saving model ...\n","Updating learning rate to 0.000625\n","Epoch: 4 cost time: 1.1986780166625977\n","Epoch: 4, Steps: 32 | Train Loss: 0.5028086 Vali Loss: 0.2793507 Test Loss: 2.0448711\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0003125\n","Epoch: 5 cost time: 1.1418051719665527\n","Epoch: 5, Steps: 32 | Train Loss: 0.4809911 Vali Loss: 0.2688801 Test Loss: 2.0326014\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.00015625\n","Epoch: 6 cost time: 1.1672863960266113\n","Epoch: 6, Steps: 32 | Train Loss: 0.4635649 Vali Loss: 0.2513683 Test Loss: 2.0291529\n","Validation loss decreased (0.259868 --> 0.251368).  Saving model ...\n","Updating learning rate to 7.8125e-05\n","Epoch: 7 cost time: 1.1914856433868408\n","Epoch: 7, Steps: 32 | Train Loss: 0.4635454 Vali Loss: 0.2509170 Test Loss: 2.0156209\n","Validation loss decreased (0.251368 --> 0.250917).  Saving model ...\n","Updating learning rate to 3.90625e-05\n","Epoch: 8 cost time: 1.2992446422576904\n","Epoch: 8, Steps: 32 | Train Loss: 0.4537709 Vali Loss: 0.2530265 Test Loss: 1.9851407\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.953125e-05\n","Epoch: 9 cost time: 1.2136712074279785\n","Epoch: 9, Steps: 32 | Train Loss: 0.4582811 Vali Loss: 0.2437428 Test Loss: 1.9839910\n","Validation loss decreased (0.250917 --> 0.243743).  Saving model ...\n","Updating learning rate to 9.765625e-06\n","Epoch: 10 cost time: 1.1749670505523682\n","Epoch: 10, Steps: 32 | Train Loss: 0.4582539 Vali Loss: 0.2496090 Test Loss: 2.0089948\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.8828125e-06\n","Epoch: 11 cost time: 1.155379295349121\n","Epoch: 11, Steps: 32 | Train Loss: 0.4628023 Vali Loss: 0.2563076 Test Loss: 2.0116935\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.44140625e-06\n","Epoch: 12 cost time: 1.172858476638794\n","Epoch: 12, Steps: 32 | Train Loss: 0.4637419 Vali Loss: 0.2450774 Test Loss: 2.0064735\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.220703125e-06\n","Epoch: 13 cost time: 1.2551076412200928\n","Epoch: 13, Steps: 32 | Train Loss: 0.4561058 Vali Loss: 0.2441333 Test Loss: 1.9993854\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 6.103515625e-07\n","Epoch: 14 cost time: 1.2739036083221436\n","Epoch: 14, Steps: 32 | Train Loss: 0.4608675 Vali Loss: 0.2560462 Test Loss: 1.9991964\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 3.0517578125e-07\n","Epoch: 15 cost time: 1.1999356746673584\n","Epoch: 15, Steps: 32 | Train Loss: 0.4557588 Vali Loss: 0.2547062 Test Loss: 1.9828407\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.52587890625e-07\n","Epoch: 16 cost time: 1.1818368434906006\n","Epoch: 16, Steps: 32 | Train Loss: 0.4453225 Vali Loss: 0.2573708 Test Loss: 2.0142622\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 7.62939453125e-08\n","Epoch: 17 cost time: 1.192349910736084\n","Epoch: 17, Steps: 32 | Train Loss: 0.4621665 Vali Loss: 0.2489370 Test Loss: 1.9807388\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.814697265625e-08\n","Epoch: 18 cost time: 1.3209450244903564\n","Epoch: 18, Steps: 32 | Train Loss: 0.4612256 Vali Loss: 0.2505526 Test Loss: 2.0046489\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.9073486328125e-08\n","Epoch: 19 cost time: 1.2032873630523682\n","Epoch: 19, Steps: 32 | Train Loss: 0.4567923 Vali Loss: 0.2542485 Test Loss: 2.0117054\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 9.5367431640625e-09\n","Epoch: 20 cost time: 1.1493513584136963\n","Epoch: 20, Steps: 32 | Train Loss: 0.4568972 Vali Loss: 0.2505151 Test Loss: 1.9860787\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 4.76837158203125e-09\n","Epoch: 21 cost time: 1.1833395957946777\n","Epoch: 21, Steps: 32 | Train Loss: 0.4628214 Vali Loss: 0.2569264 Test Loss: 2.0122018\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.384185791015625e-09\n","Epoch: 22 cost time: 1.139901876449585\n","Epoch: 22, Steps: 32 | Train Loss: 0.4584702 Vali Loss: 0.2517512 Test Loss: 2.0200949\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.1920928955078125e-09\n","Epoch: 23 cost time: 1.259225606918335\n","Epoch: 23, Steps: 32 | Train Loss: 0.4565496 Vali Loss: 0.2495101 Test Loss: 1.9994894\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 5.960464477539063e-10\n","Epoch: 24 cost time: 1.1939353942871094\n","Epoch: 24, Steps: 32 | Train Loss: 0.4559435 Vali Loss: 0.2465204 Test Loss: 1.9895799\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 2.9802322387695313e-10\n","Epoch: 25 cost time: 1.1848583221435547\n","Epoch: 25, Steps: 32 | Train Loss: 0.4527984 Vali Loss: 0.2506479 Test Loss: 2.0103099\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.4901161193847657e-10\n","Epoch: 26 cost time: 1.1785202026367188\n","Epoch: 26, Steps: 32 | Train Loss: 0.4589574 Vali Loss: 0.2563246 Test Loss: 1.9952998\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 7.450580596923828e-11\n","Epoch: 27 cost time: 1.1765596866607666\n","Epoch: 27, Steps: 32 | Train Loss: 0.4613560 Vali Loss: 0.2446217 Test Loss: 1.9956033\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 3.725290298461914e-11\n","Epoch: 28 cost time: 1.2565281391143799\n","Epoch: 28, Steps: 32 | Train Loss: 0.4639546 Vali Loss: 0.2460886 Test Loss: 2.0093930\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.862645149230957e-11\n","Epoch: 29 cost time: 1.2218177318572998\n","Epoch: 29, Steps: 32 | Train Loss: 0.4628734 Vali Loss: 0.2481419 Test Loss: 1.9837965\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 9.313225746154785e-12\n","Epoch: 30 cost time: 1.1754977703094482\n","Epoch: 30, Steps: 32 | Train Loss: 0.4591109 Vali Loss: 0.2502786 Test Loss: 2.0084360\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 4.656612873077393e-12\n","Epoch: 31 cost time: 1.171377182006836\n","Epoch: 31, Steps: 32 | Train Loss: 0.4631787 Vali Loss: 0.2553902 Test Loss: 2.0195980\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 2.3283064365386963e-12\n","Epoch: 32 cost time: 1.1793849468231201\n","Epoch: 32, Steps: 32 | Train Loss: 0.4546085 Vali Loss: 0.2577672 Test Loss: 2.0106630\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 1.1641532182693482e-12\n","Epoch: 33 cost time: 1.2620501518249512\n","Epoch: 33, Steps: 32 | Train Loss: 0.4539062 Vali Loss: 0.2556848 Test Loss: 2.0092463\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 5.820766091346741e-13\n","Epoch: 34 cost time: 1.225344181060791\n","Epoch: 34, Steps: 32 | Train Loss: 0.4658950 Vali Loss: 0.2492614 Test Loss: 1.9828199\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 2.9103830456733704e-13\n","Epoch: 35 cost time: 1.1762630939483643\n","Epoch: 35, Steps: 32 | Train Loss: 0.4589922 Vali Loss: 0.2472074 Test Loss: 2.0376604\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 1.4551915228366852e-13\n","Epoch: 36 cost time: 1.1746625900268555\n","Epoch: 36, Steps: 32 | Train Loss: 0.4631374 Vali Loss: 0.2547152 Test Loss: 2.0109346\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 7.275957614183426e-14\n","Epoch: 37 cost time: 1.1661241054534912\n","Epoch: 37, Steps: 32 | Train Loss: 0.4649246 Vali Loss: 0.2498445 Test Loss: 2.0129764\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 3.637978807091713e-14\n","Epoch: 38 cost time: 1.2942299842834473\n","Epoch: 38, Steps: 32 | Train Loss: 0.4524404 Vali Loss: 0.2517181 Test Loss: 2.0233922\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 1.8189894035458565e-14\n","Epoch: 39 cost time: 1.2196605205535889\n","Epoch: 39, Steps: 32 | Train Loss: 0.4562817 Vali Loss: 0.2555178 Test Loss: 2.0011396\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 9.094947017729283e-15\n","Epoch: 40 cost time: 1.2155556678771973\n","Epoch: 40, Steps: 32 | Train Loss: 0.4626468 Vali Loss: 0.2560497 Test Loss: 2.0078895\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 4.547473508864641e-15\n","Epoch: 41 cost time: 1.184032678604126\n","Epoch: 41, Steps: 32 | Train Loss: 0.4577971 Vali Loss: 0.2520701 Test Loss: 2.0290267\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 2.2737367544323206e-15\n","Epoch: 42 cost time: 1.2160820960998535\n","Epoch: 42, Steps: 32 | Train Loss: 0.4591562 Vali Loss: 0.2500850 Test Loss: 2.0047791\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 1.1368683772161603e-15\n","Epoch: 43 cost time: 1.2866826057434082\n","Epoch: 43, Steps: 32 | Train Loss: 0.4632218 Vali Loss: 0.2503586 Test Loss: 2.0095315\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 5.684341886080802e-16\n","Epoch: 44 cost time: 1.2417469024658203\n","Epoch: 44, Steps: 32 | Train Loss: 0.4656455 Vali Loss: 0.2567649 Test Loss: 2.0064702\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 2.842170943040401e-16\n","Epoch: 45 cost time: 1.186734676361084\n","Epoch: 45, Steps: 32 | Train Loss: 0.4586323 Vali Loss: 0.2522457 Test Loss: 1.9896245\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 1.4210854715202004e-16\n","Epoch: 46 cost time: 1.1823108196258545\n","Epoch: 46, Steps: 32 | Train Loss: 0.4543929 Vali Loss: 0.2508733 Test Loss: 2.0117898\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 7.105427357601002e-17\n","Epoch: 47 cost time: 1.2093656063079834\n","Epoch: 47, Steps: 32 | Train Loss: 0.4469446 Vali Loss: 0.2489833 Test Loss: 1.9944723\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 3.552713678800501e-17\n","Epoch: 48 cost time: 1.264270544052124\n","Epoch: 48, Steps: 32 | Train Loss: 0.4508922 Vali Loss: 0.2557428 Test Loss: 1.9911188\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 1.7763568394002505e-17\n","Epoch: 49 cost time: 1.2156412601470947\n","Epoch: 49, Steps: 32 | Train Loss: 0.4554415 Vali Loss: 0.2509053 Test Loss: 2.0101237\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 8.881784197001253e-18\n","Epoch: 50 cost time: 1.2158403396606445\n","Epoch: 50, Steps: 32 | Train Loss: 0.4631098 Vali Loss: 0.2499291 Test Loss: 1.9933076\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 4.440892098500626e-18\n","Epoch: 51 cost time: 1.215837001800537\n","Epoch: 51, Steps: 32 | Train Loss: 0.4571298 Vali Loss: 0.2504835 Test Loss: 2.0055649\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 2.220446049250313e-18\n","Epoch: 52 cost time: 1.167379379272461\n","Epoch: 52, Steps: 32 | Train Loss: 0.4567973 Vali Loss: 0.2440778 Test Loss: 1.9901742\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 1.1102230246251566e-18\n","Epoch: 53 cost time: 1.2281944751739502\n","Epoch: 53, Steps: 32 | Train Loss: 0.4544821 Vali Loss: 0.2484348 Test Loss: 1.9775789\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 5.551115123125783e-19\n","Epoch: 54 cost time: 1.215343952178955\n","Epoch: 54, Steps: 32 | Train Loss: 0.4563519 Vali Loss: 0.2515340 Test Loss: 1.9999706\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 2.7755575615628914e-19\n","Epoch: 55 cost time: 1.1886725425720215\n","Epoch: 55, Steps: 32 | Train Loss: 0.4472239 Vali Loss: 0.2551991 Test Loss: 2.0057769\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 1.3877787807814457e-19\n","Epoch: 56 cost time: 1.2031705379486084\n","Epoch: 56, Steps: 32 | Train Loss: 0.4529503 Vali Loss: 0.2552783 Test Loss: 2.0022216\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 6.938893903907229e-20\n","Epoch: 57 cost time: 1.2055528163909912\n","Epoch: 57, Steps: 32 | Train Loss: 0.4558415 Vali Loss: 0.2506831 Test Loss: 2.0025053\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 3.469446951953614e-20\n","Epoch: 58 cost time: 1.2571203708648682\n","Epoch: 58, Steps: 32 | Train Loss: 0.4596460 Vali Loss: 0.2516656 Test Loss: 2.0258374\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 1.734723475976807e-20\n","Epoch: 59 cost time: 1.237417221069336\n","Epoch: 59, Steps: 32 | Train Loss: 0.4639359 Vali Loss: 0.2553150 Test Loss: 2.0042365\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 8.673617379884036e-21\n","Epoch: 60 cost time: 1.2270948886871338\n","Epoch: 60, Steps: 32 | Train Loss: 0.4563654 Vali Loss: 0.2530067 Test Loss: 2.0198271\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 4.336808689942018e-21\n","Epoch: 61 cost time: 1.1681849956512451\n","Epoch: 61, Steps: 32 | Train Loss: 0.4627695 Vali Loss: 0.2512976 Test Loss: 2.0025437\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 2.168404344971009e-21\n","Epoch: 62 cost time: 1.1727800369262695\n","Epoch: 62, Steps: 32 | Train Loss: 0.4629858 Vali Loss: 0.2558370 Test Loss: 2.0123620\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 1.0842021724855045e-21\n","Epoch: 63 cost time: 1.2743618488311768\n","Epoch: 63, Steps: 32 | Train Loss: 0.4629562 Vali Loss: 0.2526481 Test Loss: 2.0124254\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 5.421010862427522e-22\n","Epoch: 64 cost time: 1.2222011089324951\n","Epoch: 64, Steps: 32 | Train Loss: 0.4537417 Vali Loss: 0.2470382 Test Loss: 2.0144458\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 2.710505431213761e-22\n","Epoch: 65 cost time: 1.2273902893066406\n","Epoch: 65, Steps: 32 | Train Loss: 0.4522050 Vali Loss: 0.2564432 Test Loss: 2.0124066\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 1.3552527156068806e-22\n","Epoch: 66 cost time: 1.1915316581726074\n","Epoch: 66, Steps: 32 | Train Loss: 0.4537526 Vali Loss: 0.2507321 Test Loss: 2.0005460\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 6.776263578034403e-23\n","Epoch: 67 cost time: 1.1708178520202637\n","Epoch: 67, Steps: 32 | Train Loss: 0.4616301 Vali Loss: 0.2506150 Test Loss: 1.9907479\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 3.3881317890172014e-23\n","Epoch: 68 cost time: 1.2701799869537354\n","Epoch: 68, Steps: 32 | Train Loss: 0.4503515 Vali Loss: 0.2506108 Test Loss: 2.0113444\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 1.6940658945086007e-23\n","Epoch: 69 cost time: 1.2303171157836914\n","Epoch: 69, Steps: 32 | Train Loss: 0.4589194 Vali Loss: 0.2529034 Test Loss: 2.0284472\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 8.470329472543004e-24\n","Epoch: 70 cost time: 1.177086353302002\n","Epoch: 70, Steps: 32 | Train Loss: 0.4459039 Vali Loss: 0.2544421 Test Loss: 1.9829000\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 4.235164736271502e-24\n","Epoch: 71 cost time: 1.2113337516784668\n","Epoch: 71, Steps: 32 | Train Loss: 0.4623447 Vali Loss: 0.2501048 Test Loss: 2.0116255\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 2.117582368135751e-24\n","Epoch: 72 cost time: 1.2354919910430908\n","Epoch: 72, Steps: 32 | Train Loss: 0.4636631 Vali Loss: 0.2451964 Test Loss: 2.0069041\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 1.0587911840678754e-24\n","Epoch: 73 cost time: 1.29630446434021\n","Epoch: 73, Steps: 32 | Train Loss: 0.4546685 Vali Loss: 0.2559805 Test Loss: 1.9967446\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 5.293955920339377e-25\n","Epoch: 74 cost time: 1.212958812713623\n","Epoch: 74, Steps: 32 | Train Loss: 0.4658796 Vali Loss: 0.2501634 Test Loss: 1.9864374\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 2.6469779601696886e-25\n","Epoch: 75 cost time: 1.201547622680664\n","Epoch: 75, Steps: 32 | Train Loss: 0.4585727 Vali Loss: 0.2503038 Test Loss: 2.0012257\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 1.3234889800848443e-25\n","Epoch: 76 cost time: 1.210482120513916\n","Epoch: 76, Steps: 32 | Train Loss: 0.4507763 Vali Loss: 0.2508493 Test Loss: 1.9951528\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 6.617444900424222e-26\n","Epoch: 77 cost time: 1.2008998394012451\n","Epoch: 77, Steps: 32 | Train Loss: 0.4526023 Vali Loss: 0.2536529 Test Loss: 1.9755576\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 3.308722450212111e-26\n","Epoch: 78 cost time: 1.282332181930542\n","Epoch: 78, Steps: 32 | Train Loss: 0.4519854 Vali Loss: 0.2456935 Test Loss: 2.0138102\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 1.6543612251060554e-26\n","Epoch: 79 cost time: 1.2264816761016846\n","Epoch: 79, Steps: 32 | Train Loss: 0.4611623 Vali Loss: 0.2517264 Test Loss: 2.0122585\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 8.271806125530277e-27\n","Epoch: 80 cost time: 1.2016313076019287\n","Epoch: 80, Steps: 32 | Train Loss: 0.4491554 Vali Loss: 0.2487002 Test Loss: 1.9864095\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 4.1359030627651385e-27\n","Epoch: 81 cost time: 1.209906816482544\n","Epoch: 81, Steps: 32 | Train Loss: 0.4585063 Vali Loss: 0.2513476 Test Loss: 2.0015526\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 2.0679515313825692e-27\n","Epoch: 82 cost time: 1.2066898345947266\n","Epoch: 82, Steps: 32 | Train Loss: 0.4630042 Vali Loss: 0.2571241 Test Loss: 2.0136321\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 1.0339757656912846e-27\n","Epoch: 83 cost time: 1.2839291095733643\n","Epoch: 83, Steps: 32 | Train Loss: 0.4587011 Vali Loss: 0.2478933 Test Loss: 2.0163686\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 5.169878828456423e-28\n","Epoch: 84 cost time: 1.1841933727264404\n","Epoch: 84, Steps: 32 | Train Loss: 0.4585731 Vali Loss: 0.2503354 Test Loss: 2.0001807\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 2.5849394142282115e-28\n","Epoch: 85 cost time: 1.1906349658966064\n","Epoch: 85, Steps: 32 | Train Loss: 0.4552379 Vali Loss: 0.2476205 Test Loss: 2.0029767\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 1.2924697071141058e-28\n","Epoch: 86 cost time: 1.1742706298828125\n","Epoch: 86, Steps: 32 | Train Loss: 0.4638662 Vali Loss: 0.2512977 Test Loss: 2.0065594\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 6.462348535570529e-29\n","Epoch: 87 cost time: 1.199420690536499\n","Epoch: 87, Steps: 32 | Train Loss: 0.4659698 Vali Loss: 0.2457083 Test Loss: 2.0215230\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 3.2311742677852644e-29\n","Epoch: 88 cost time: 1.2481045722961426\n","Epoch: 88, Steps: 32 | Train Loss: 0.4600121 Vali Loss: 0.2536717 Test Loss: 2.0007582\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 1.6155871338926322e-29\n","Epoch: 89 cost time: 1.2167601585388184\n","Epoch: 89, Steps: 32 | Train Loss: 0.4598393 Vali Loss: 0.2469465 Test Loss: 2.0220757\n","EarlyStopping counter: 80 out of 100\n","Updating learning rate to 8.077935669463161e-30\n","Epoch: 90 cost time: 1.202458143234253\n","Epoch: 90, Steps: 32 | Train Loss: 0.4633267 Vali Loss: 0.2524904 Test Loss: 2.0296762\n","EarlyStopping counter: 81 out of 100\n","Updating learning rate to 4.0389678347315805e-30\n","Epoch: 91 cost time: 1.185460090637207\n","Epoch: 91, Steps: 32 | Train Loss: 0.4570114 Vali Loss: 0.2494172 Test Loss: 1.9893161\n","EarlyStopping counter: 82 out of 100\n","Updating learning rate to 2.0194839173657903e-30\n","Epoch: 92 cost time: 1.2256667613983154\n","Epoch: 92, Steps: 32 | Train Loss: 0.4563482 Vali Loss: 0.2549455 Test Loss: 1.9766364\n","EarlyStopping counter: 83 out of 100\n","Updating learning rate to 1.0097419586828951e-30\n","Epoch: 93 cost time: 1.261228322982788\n","Epoch: 93, Steps: 32 | Train Loss: 0.4636556 Vali Loss: 0.2474659 Test Loss: 2.0009155\n","EarlyStopping counter: 84 out of 100\n","Updating learning rate to 5.048709793414476e-31\n","Epoch: 94 cost time: 1.2059295177459717\n","Epoch: 94, Steps: 32 | Train Loss: 0.4527186 Vali Loss: 0.2520944 Test Loss: 2.0146093\n","EarlyStopping counter: 85 out of 100\n","Updating learning rate to 2.524354896707238e-31\n","Epoch: 95 cost time: 1.2185299396514893\n","Epoch: 95, Steps: 32 | Train Loss: 0.4662759 Vali Loss: 0.2558311 Test Loss: 2.0201180\n","EarlyStopping counter: 86 out of 100\n","Updating learning rate to 1.262177448353619e-31\n","Epoch: 96 cost time: 1.193251609802246\n","Epoch: 96, Steps: 32 | Train Loss: 0.4626195 Vali Loss: 0.2562938 Test Loss: 2.0027258\n","EarlyStopping counter: 87 out of 100\n","Updating learning rate to 6.310887241768095e-32\n","Epoch: 97 cost time: 1.258476972579956\n","Epoch: 97, Steps: 32 | Train Loss: 0.4517607 Vali Loss: 0.2558972 Test Loss: 2.0010595\n","EarlyStopping counter: 88 out of 100\n","Updating learning rate to 3.1554436208840473e-32\n","Epoch: 98 cost time: 1.324733018875122\n","Epoch: 98, Steps: 32 | Train Loss: 0.4556799 Vali Loss: 0.2554238 Test Loss: 1.9936922\n","EarlyStopping counter: 89 out of 100\n","Updating learning rate to 1.5777218104420236e-32\n","Epoch: 99 cost time: 1.2421674728393555\n","Epoch: 99, Steps: 32 | Train Loss: 0.4578736 Vali Loss: 0.2501354 Test Loss: 2.0056357\n","EarlyStopping counter: 90 out of 100\n","Updating learning rate to 7.888609052210118e-33\n","Epoch: 100 cost time: 1.2230136394500732\n","Epoch: 100, Steps: 32 | Train Loss: 0.4568980 Vali Loss: 0.2448756 Test Loss: 2.0008955\n","EarlyStopping counter: 91 out of 100\n","Updating learning rate to 3.944304526105059e-33\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl48_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 146\n","mse:1.983991026878357, mae:0.9385358095169067, rse:0.6737889051437378\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl48_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  60\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  0\n","Exp_Main init!\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl60_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 513\n","val 38\n","test 134\n","Epoch: 1 cost time: 1.2118451595306396\n","Epoch: 1, Steps: 32 | Train Loss: 0.9830709 Vali Loss: 0.3453752 Test Loss: 2.9080684\n","Validation loss decreased (inf --> 0.345375).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 1.2503256797790527\n","Epoch: 2, Steps: 32 | Train Loss: 0.8795899 Vali Loss: 0.5265888 Test Loss: 2.0820787\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.00125\n","Epoch: 3 cost time: 1.1837034225463867\n","Epoch: 3, Steps: 32 | Train Loss: 0.6010694 Vali Loss: 0.2293241 Test Loss: 1.9540819\n","Validation loss decreased (0.345375 --> 0.229324).  Saving model ...\n","Updating learning rate to 0.000625\n","Epoch: 4 cost time: 1.2202706336975098\n","Epoch: 4, Steps: 32 | Train Loss: 0.5265064 Vali Loss: 0.2817219 Test Loss: 2.0417356\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0003125\n","Epoch: 5 cost time: 1.1976253986358643\n","Epoch: 5, Steps: 32 | Train Loss: 0.5009129 Vali Loss: 0.2648679 Test Loss: 2.0668550\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.00015625\n","Epoch: 6 cost time: 1.2633657455444336\n","Epoch: 6, Steps: 32 | Train Loss: 0.4888549 Vali Loss: 0.2583106 Test Loss: 1.9940937\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 7.8125e-05\n","Epoch: 7 cost time: 1.2597949504852295\n","Epoch: 7, Steps: 32 | Train Loss: 0.4827013 Vali Loss: 0.2757177 Test Loss: 1.9815204\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 3.90625e-05\n","Epoch: 8 cost time: 1.2123591899871826\n","Epoch: 8, Steps: 32 | Train Loss: 0.4839770 Vali Loss: 0.2739682 Test Loss: 1.9943488\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.953125e-05\n","Epoch: 9 cost time: 1.2272653579711914\n","Epoch: 9, Steps: 32 | Train Loss: 0.4793300 Vali Loss: 0.2656565 Test Loss: 1.9819996\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 9.765625e-06\n","Epoch: 10 cost time: 1.1793303489685059\n","Epoch: 10, Steps: 32 | Train Loss: 0.4815412 Vali Loss: 0.2608610 Test Loss: 1.9815379\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 4.8828125e-06\n","Epoch: 11 cost time: 1.2410171031951904\n","Epoch: 11, Steps: 32 | Train Loss: 0.4800683 Vali Loss: 0.2625712 Test Loss: 1.9899197\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 2.44140625e-06\n","Epoch: 12 cost time: 1.2754666805267334\n","Epoch: 12, Steps: 32 | Train Loss: 0.4814706 Vali Loss: 0.2792436 Test Loss: 1.9727752\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.220703125e-06\n","Epoch: 13 cost time: 1.2148563861846924\n","Epoch: 13, Steps: 32 | Train Loss: 0.4776212 Vali Loss: 0.2731071 Test Loss: 1.9855593\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 6.103515625e-07\n","Epoch: 14 cost time: 1.189405918121338\n","Epoch: 14, Steps: 32 | Train Loss: 0.4805901 Vali Loss: 0.2611753 Test Loss: 1.9828699\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 3.0517578125e-07\n","Epoch: 15 cost time: 1.2208714485168457\n","Epoch: 15, Steps: 32 | Train Loss: 0.4781752 Vali Loss: 0.2625890 Test Loss: 1.9689323\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.52587890625e-07\n","Epoch: 16 cost time: 1.286773920059204\n","Epoch: 16, Steps: 32 | Train Loss: 0.4815710 Vali Loss: 0.2713075 Test Loss: 1.9875038\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 7.62939453125e-08\n","Epoch: 17 cost time: 1.2981514930725098\n","Epoch: 17, Steps: 32 | Train Loss: 0.4777879 Vali Loss: 0.2582959 Test Loss: 1.9841616\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 3.814697265625e-08\n","Epoch: 18 cost time: 1.2108557224273682\n","Epoch: 18, Steps: 32 | Train Loss: 0.4771860 Vali Loss: 0.2708691 Test Loss: 1.9704580\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 1.9073486328125e-08\n","Epoch: 19 cost time: 1.1709578037261963\n","Epoch: 19, Steps: 32 | Train Loss: 0.4793592 Vali Loss: 0.2725925 Test Loss: 1.9830556\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 9.5367431640625e-09\n","Epoch: 20 cost time: 1.1785304546356201\n","Epoch: 20, Steps: 32 | Train Loss: 0.4803924 Vali Loss: 0.2596150 Test Loss: 1.9782233\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 4.76837158203125e-09\n","Epoch: 21 cost time: 1.3043773174285889\n","Epoch: 21, Steps: 32 | Train Loss: 0.4783976 Vali Loss: 0.2736405 Test Loss: 1.9571368\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 2.384185791015625e-09\n","Epoch: 22 cost time: 1.2424721717834473\n","Epoch: 22, Steps: 32 | Train Loss: 0.4815213 Vali Loss: 0.2593304 Test Loss: 1.9888248\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.1920928955078125e-09\n","Epoch: 23 cost time: 1.2189877033233643\n","Epoch: 23, Steps: 32 | Train Loss: 0.4805758 Vali Loss: 0.2631723 Test Loss: 1.9687977\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 5.960464477539063e-10\n","Epoch: 24 cost time: 1.2373414039611816\n","Epoch: 24, Steps: 32 | Train Loss: 0.4828411 Vali Loss: 0.2678280 Test Loss: 1.9835646\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 2.9802322387695313e-10\n","Epoch: 25 cost time: 1.188429594039917\n","Epoch: 25, Steps: 32 | Train Loss: 0.4749202 Vali Loss: 0.2837980 Test Loss: 1.9859368\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 1.4901161193847657e-10\n","Epoch: 26 cost time: 1.284862756729126\n","Epoch: 26, Steps: 32 | Train Loss: 0.4794759 Vali Loss: 0.2626916 Test Loss: 1.9882596\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 7.450580596923828e-11\n","Epoch: 27 cost time: 1.2535943984985352\n","Epoch: 27, Steps: 32 | Train Loss: 0.4799368 Vali Loss: 0.2701233 Test Loss: 1.9861252\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 3.725290298461914e-11\n","Epoch: 28 cost time: 1.2030887603759766\n","Epoch: 28, Steps: 32 | Train Loss: 0.4793658 Vali Loss: 0.2602516 Test Loss: 1.9795583\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 1.862645149230957e-11\n","Epoch: 29 cost time: 1.201719045639038\n","Epoch: 29, Steps: 32 | Train Loss: 0.4764750 Vali Loss: 0.2778655 Test Loss: 1.9840617\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 9.313225746154785e-12\n","Epoch: 30 cost time: 1.2039430141448975\n","Epoch: 30, Steps: 32 | Train Loss: 0.4775168 Vali Loss: 0.2773558 Test Loss: 1.9692748\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 4.656612873077393e-12\n","Epoch: 31 cost time: 1.3049712181091309\n","Epoch: 31, Steps: 32 | Train Loss: 0.4796760 Vali Loss: 0.2733753 Test Loss: 1.9892759\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 2.3283064365386963e-12\n","Epoch: 32 cost time: 1.219783067703247\n","Epoch: 32, Steps: 32 | Train Loss: 0.4774336 Vali Loss: 0.2675921 Test Loss: 1.9933538\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 1.1641532182693482e-12\n","Epoch: 33 cost time: 1.2072992324829102\n","Epoch: 33, Steps: 32 | Train Loss: 0.4803876 Vali Loss: 0.2671160 Test Loss: 1.9763329\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 5.820766091346741e-13\n","Epoch: 34 cost time: 1.189525842666626\n","Epoch: 34, Steps: 32 | Train Loss: 0.4795418 Vali Loss: 0.2768487 Test Loss: 1.9980037\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 2.9103830456733704e-13\n","Epoch: 35 cost time: 1.2593507766723633\n","Epoch: 35, Steps: 32 | Train Loss: 0.4762926 Vali Loss: 0.2696539 Test Loss: 1.9928894\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 1.4551915228366852e-13\n","Epoch: 36 cost time: 1.267488956451416\n","Epoch: 36, Steps: 32 | Train Loss: 0.4769896 Vali Loss: 0.2617698 Test Loss: 1.9733956\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 7.275957614183426e-14\n","Epoch: 37 cost time: 1.1950109004974365\n","Epoch: 37, Steps: 32 | Train Loss: 0.4783004 Vali Loss: 0.2615591 Test Loss: 1.9742937\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 3.637978807091713e-14\n","Epoch: 38 cost time: 1.202960729598999\n","Epoch: 38, Steps: 32 | Train Loss: 0.4767235 Vali Loss: 0.2737357 Test Loss: 1.9740222\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 1.8189894035458565e-14\n","Epoch: 39 cost time: 1.2430753707885742\n","Epoch: 39, Steps: 32 | Train Loss: 0.4789199 Vali Loss: 0.2587933 Test Loss: 1.9859879\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 9.094947017729283e-15\n","Epoch: 40 cost time: 1.2608799934387207\n","Epoch: 40, Steps: 32 | Train Loss: 0.4773979 Vali Loss: 0.2598796 Test Loss: 1.9904269\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 4.547473508864641e-15\n","Epoch: 41 cost time: 1.2968499660491943\n","Epoch: 41, Steps: 32 | Train Loss: 0.4776200 Vali Loss: 0.2738852 Test Loss: 1.9735680\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 2.2737367544323206e-15\n","Epoch: 42 cost time: 1.2038028240203857\n","Epoch: 42, Steps: 32 | Train Loss: 0.4791283 Vali Loss: 0.2732129 Test Loss: 1.9876255\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 1.1368683772161603e-15\n","Epoch: 43 cost time: 1.2083501815795898\n","Epoch: 43, Steps: 32 | Train Loss: 0.4785417 Vali Loss: 0.2653832 Test Loss: 1.9994940\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 5.684341886080802e-16\n","Epoch: 44 cost time: 1.2118749618530273\n","Epoch: 44, Steps: 32 | Train Loss: 0.4738513 Vali Loss: 0.2620544 Test Loss: 1.9799796\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 2.842170943040401e-16\n","Epoch: 45 cost time: 1.277467966079712\n","Epoch: 45, Steps: 32 | Train Loss: 0.4759043 Vali Loss: 0.2744764 Test Loss: 1.9752328\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 1.4210854715202004e-16\n","Epoch: 46 cost time: 1.3246166706085205\n","Epoch: 46, Steps: 32 | Train Loss: 0.4783302 Vali Loss: 0.2727379 Test Loss: 1.9907928\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 7.105427357601002e-17\n","Epoch: 47 cost time: 1.2300488948822021\n","Epoch: 47, Steps: 32 | Train Loss: 0.4770262 Vali Loss: 0.2683961 Test Loss: 1.9751529\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 3.552713678800501e-17\n","Epoch: 48 cost time: 1.2183609008789062\n","Epoch: 48, Steps: 32 | Train Loss: 0.4795352 Vali Loss: 0.2714707 Test Loss: 1.9804375\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 1.7763568394002505e-17\n","Epoch: 49 cost time: 1.2328824996948242\n","Epoch: 49, Steps: 32 | Train Loss: 0.4788563 Vali Loss: 0.2600522 Test Loss: 1.9929041\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 8.881784197001253e-18\n","Epoch: 50 cost time: 1.3263375759124756\n","Epoch: 50, Steps: 32 | Train Loss: 0.4764626 Vali Loss: 0.2672092 Test Loss: 1.9643183\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 4.440892098500626e-18\n","Epoch: 51 cost time: 1.2557711601257324\n","Epoch: 51, Steps: 32 | Train Loss: 0.4771843 Vali Loss: 0.2692205 Test Loss: 1.9747943\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 2.220446049250313e-18\n","Epoch: 52 cost time: 1.230372667312622\n","Epoch: 52, Steps: 32 | Train Loss: 0.4780142 Vali Loss: 0.2719725 Test Loss: 1.9813750\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 1.1102230246251566e-18\n","Epoch: 53 cost time: 1.205461025238037\n","Epoch: 53, Steps: 32 | Train Loss: 0.4783457 Vali Loss: 0.2624936 Test Loss: 1.9885198\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 5.551115123125783e-19\n","Epoch: 54 cost time: 1.2085151672363281\n","Epoch: 54, Steps: 32 | Train Loss: 0.4804638 Vali Loss: 0.2603187 Test Loss: 1.9857030\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 2.7755575615628914e-19\n","Epoch: 55 cost time: 1.2966198921203613\n","Epoch: 55, Steps: 32 | Train Loss: 0.4794570 Vali Loss: 0.2724697 Test Loss: 1.9845672\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 1.3877787807814457e-19\n","Epoch: 56 cost time: 1.2658379077911377\n","Epoch: 56, Steps: 32 | Train Loss: 0.4774499 Vali Loss: 0.2720868 Test Loss: 1.9861591\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 6.938893903907229e-20\n","Epoch: 57 cost time: 1.2356853485107422\n","Epoch: 57, Steps: 32 | Train Loss: 0.4789220 Vali Loss: 0.2793410 Test Loss: 2.0104706\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 3.469446951953614e-20\n","Epoch: 58 cost time: 1.2224605083465576\n","Epoch: 58, Steps: 32 | Train Loss: 0.4779348 Vali Loss: 0.2716628 Test Loss: 1.9990783\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 1.734723475976807e-20\n","Epoch: 59 cost time: 1.287168025970459\n","Epoch: 59, Steps: 32 | Train Loss: 0.4768317 Vali Loss: 0.2656984 Test Loss: 1.9767519\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 8.673617379884036e-21\n","Epoch: 60 cost time: 1.3006417751312256\n","Epoch: 60, Steps: 32 | Train Loss: 0.4784432 Vali Loss: 0.2756540 Test Loss: 1.9993546\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 4.336808689942018e-21\n","Epoch: 61 cost time: 1.262176513671875\n","Epoch: 61, Steps: 32 | Train Loss: 0.4785451 Vali Loss: 0.2551666 Test Loss: 1.9772407\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 2.168404344971009e-21\n","Epoch: 62 cost time: 1.257946252822876\n","Epoch: 62, Steps: 32 | Train Loss: 0.4799100 Vali Loss: 0.2673573 Test Loss: 1.9795582\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 1.0842021724855045e-21\n","Epoch: 63 cost time: 1.1946823596954346\n","Epoch: 63, Steps: 32 | Train Loss: 0.4797246 Vali Loss: 0.2599569 Test Loss: 1.9951980\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 5.421010862427522e-22\n","Epoch: 64 cost time: 1.268794059753418\n","Epoch: 64, Steps: 32 | Train Loss: 0.4783976 Vali Loss: 0.2764109 Test Loss: 1.9827769\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 2.710505431213761e-22\n","Epoch: 65 cost time: 1.3213634490966797\n","Epoch: 65, Steps: 32 | Train Loss: 0.4788100 Vali Loss: 0.2569701 Test Loss: 1.9798787\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 1.3552527156068806e-22\n","Epoch: 66 cost time: 1.2373528480529785\n","Epoch: 66, Steps: 32 | Train Loss: 0.4785108 Vali Loss: 0.2626502 Test Loss: 1.9919879\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 6.776263578034403e-23\n","Epoch: 67 cost time: 1.227466344833374\n","Epoch: 67, Steps: 32 | Train Loss: 0.4825890 Vali Loss: 0.2675471 Test Loss: 1.9810485\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 3.3881317890172014e-23\n","Epoch: 68 cost time: 1.2304987907409668\n","Epoch: 68, Steps: 32 | Train Loss: 0.4763425 Vali Loss: 0.2737457 Test Loss: 1.9961500\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 1.6940658945086007e-23\n","Epoch: 69 cost time: 1.333122730255127\n","Epoch: 69, Steps: 32 | Train Loss: 0.4797875 Vali Loss: 0.2657480 Test Loss: 1.9836725\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 8.470329472543004e-24\n","Epoch: 70 cost time: 1.2766611576080322\n","Epoch: 70, Steps: 32 | Train Loss: 0.4806298 Vali Loss: 0.2737083 Test Loss: 1.9821030\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 4.235164736271502e-24\n","Epoch: 71 cost time: 1.2188613414764404\n","Epoch: 71, Steps: 32 | Train Loss: 0.4796138 Vali Loss: 0.2613760 Test Loss: 1.9868054\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 2.117582368135751e-24\n","Epoch: 72 cost time: 1.208984375\n","Epoch: 72, Steps: 32 | Train Loss: 0.4763625 Vali Loss: 0.2719837 Test Loss: 1.9933019\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 1.0587911840678754e-24\n","Epoch: 73 cost time: 1.201357364654541\n","Epoch: 73, Steps: 32 | Train Loss: 0.4762232 Vali Loss: 0.2689233 Test Loss: 1.9796197\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 5.293955920339377e-25\n","Epoch: 74 cost time: 1.3284175395965576\n","Epoch: 74, Steps: 32 | Train Loss: 0.4810971 Vali Loss: 0.2588445 Test Loss: 1.9798186\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 2.6469779601696886e-25\n","Epoch: 75 cost time: 1.241469144821167\n","Epoch: 75, Steps: 32 | Train Loss: 0.4782738 Vali Loss: 0.2789144 Test Loss: 1.9740531\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 1.3234889800848443e-25\n","Epoch: 76 cost time: 1.2391626834869385\n","Epoch: 76, Steps: 32 | Train Loss: 0.4759896 Vali Loss: 0.2532563 Test Loss: 1.9803584\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 6.617444900424222e-26\n","Epoch: 77 cost time: 1.2296810150146484\n","Epoch: 77, Steps: 32 | Train Loss: 0.4796655 Vali Loss: 0.2604070 Test Loss: 1.9939423\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 3.308722450212111e-26\n","Epoch: 78 cost time: 1.238006353378296\n","Epoch: 78, Steps: 32 | Train Loss: 0.4794677 Vali Loss: 0.2651590 Test Loss: 1.9775383\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 1.6543612251060554e-26\n","Epoch: 79 cost time: 1.362504005432129\n","Epoch: 79, Steps: 32 | Train Loss: 0.4783832 Vali Loss: 0.2633116 Test Loss: 1.9911282\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 8.271806125530277e-27\n","Epoch: 80 cost time: 1.2636444568634033\n","Epoch: 80, Steps: 32 | Train Loss: 0.4801346 Vali Loss: 0.2627089 Test Loss: 2.0065179\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 4.1359030627651385e-27\n","Epoch: 81 cost time: 1.241818904876709\n","Epoch: 81, Steps: 32 | Train Loss: 0.4778669 Vali Loss: 0.2638780 Test Loss: 1.9753373\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 2.0679515313825692e-27\n","Epoch: 82 cost time: 1.2374155521392822\n","Epoch: 82, Steps: 32 | Train Loss: 0.4776616 Vali Loss: 0.2604672 Test Loss: 1.9669886\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 1.0339757656912846e-27\n","Epoch: 83 cost time: 1.2455196380615234\n","Epoch: 83, Steps: 32 | Train Loss: 0.4774211 Vali Loss: 0.2581018 Test Loss: 1.9818902\n","EarlyStopping counter: 80 out of 100\n","Updating learning rate to 5.169878828456423e-28\n","Epoch: 84 cost time: 1.328707218170166\n","Epoch: 84, Steps: 32 | Train Loss: 0.4746865 Vali Loss: 0.2730676 Test Loss: 1.9820749\n","EarlyStopping counter: 81 out of 100\n","Updating learning rate to 2.5849394142282115e-28\n","Epoch: 85 cost time: 1.2551937103271484\n","Epoch: 85, Steps: 32 | Train Loss: 0.4789046 Vali Loss: 0.2662122 Test Loss: 1.9858587\n","EarlyStopping counter: 82 out of 100\n","Updating learning rate to 1.2924697071141058e-28\n","Epoch: 86 cost time: 1.2367520332336426\n","Epoch: 86, Steps: 32 | Train Loss: 0.4787803 Vali Loss: 0.2684798 Test Loss: 1.9813083\n","EarlyStopping counter: 83 out of 100\n","Updating learning rate to 6.462348535570529e-29\n","Epoch: 87 cost time: 1.2343876361846924\n","Epoch: 87, Steps: 32 | Train Loss: 0.4797160 Vali Loss: 0.2677870 Test Loss: 1.9674364\n","EarlyStopping counter: 84 out of 100\n","Updating learning rate to 3.2311742677852644e-29\n","Epoch: 88 cost time: 1.3168957233428955\n","Epoch: 88, Steps: 32 | Train Loss: 0.4791513 Vali Loss: 0.2514197 Test Loss: 1.9848125\n","EarlyStopping counter: 85 out of 100\n","Updating learning rate to 1.6155871338926322e-29\n","Epoch: 89 cost time: 1.3540539741516113\n","Epoch: 89, Steps: 32 | Train Loss: 0.4757164 Vali Loss: 0.2739424 Test Loss: 1.9855435\n","EarlyStopping counter: 86 out of 100\n","Updating learning rate to 8.077935669463161e-30\n","Epoch: 90 cost time: 1.2317900657653809\n","Epoch: 90, Steps: 32 | Train Loss: 0.4794851 Vali Loss: 0.2685484 Test Loss: 1.9806433\n","EarlyStopping counter: 87 out of 100\n","Updating learning rate to 4.0389678347315805e-30\n","Epoch: 91 cost time: 1.2245597839355469\n","Epoch: 91, Steps: 32 | Train Loss: 0.4815887 Vali Loss: 0.2630394 Test Loss: 1.9765077\n","EarlyStopping counter: 88 out of 100\n","Updating learning rate to 2.0194839173657903e-30\n","Epoch: 92 cost time: 1.2344615459442139\n","Epoch: 92, Steps: 32 | Train Loss: 0.4805874 Vali Loss: 0.2599809 Test Loss: 1.9845045\n","EarlyStopping counter: 89 out of 100\n","Updating learning rate to 1.0097419586828951e-30\n","Epoch: 93 cost time: 1.325354814529419\n","Epoch: 93, Steps: 32 | Train Loss: 0.4785040 Vali Loss: 0.2707587 Test Loss: 1.9808428\n","EarlyStopping counter: 90 out of 100\n","Updating learning rate to 5.048709793414476e-31\n","Epoch: 94 cost time: 1.2240169048309326\n","Epoch: 94, Steps: 32 | Train Loss: 0.4762949 Vali Loss: 0.2521667 Test Loss: 1.9918960\n","EarlyStopping counter: 91 out of 100\n","Updating learning rate to 2.524354896707238e-31\n","Epoch: 95 cost time: 1.2949731349945068\n","Epoch: 95, Steps: 32 | Train Loss: 0.4794973 Vali Loss: 0.2634139 Test Loss: 1.9903269\n","EarlyStopping counter: 92 out of 100\n","Updating learning rate to 1.262177448353619e-31\n","Epoch: 96 cost time: 1.2286977767944336\n","Epoch: 96, Steps: 32 | Train Loss: 0.4805179 Vali Loss: 0.2579309 Test Loss: 1.9903253\n","EarlyStopping counter: 93 out of 100\n","Updating learning rate to 6.310887241768095e-32\n","Epoch: 97 cost time: 1.267282247543335\n","Epoch: 97, Steps: 32 | Train Loss: 0.4813479 Vali Loss: 0.2697556 Test Loss: 1.9822415\n","EarlyStopping counter: 94 out of 100\n","Updating learning rate to 3.1554436208840473e-32\n","Epoch: 98 cost time: 1.366407871246338\n","Epoch: 98, Steps: 32 | Train Loss: 0.4776410 Vali Loss: 0.2669977 Test Loss: 1.9727329\n","EarlyStopping counter: 95 out of 100\n","Updating learning rate to 1.5777218104420236e-32\n","Epoch: 99 cost time: 1.2556943893432617\n","Epoch: 99, Steps: 32 | Train Loss: 0.4788695 Vali Loss: 0.2744994 Test Loss: 1.9910547\n","EarlyStopping counter: 96 out of 100\n","Updating learning rate to 7.888609052210118e-33\n","Epoch: 100 cost time: 1.245314598083496\n","Epoch: 100, Steps: 32 | Train Loss: 0.4806393 Vali Loss: 0.2655815 Test Loss: 1.9785914\n","EarlyStopping counter: 97 out of 100\n","Updating learning rate to 3.944304526105059e-33\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl60_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 134\n","mse:1.9540817737579346, mae:0.9468467235565186, rse:0.6679689884185791\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl60_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n"]}],"source":["arg_pred_len_list = [24, 36, 48, 60]\n","\n","for arg_pred_len in arg_pred_len_list:\n","  # prediction len 설정\n","\n","  args.pred_len = arg_pred_len\n","  Exp = Exp_Main\n","  print(\"Current Prediction Length : \", str(arg_pred_len))\n","  print(\"\\n\\n\\n\")\n","\n","  if args.is_training:\n","      for ii in range(args.itr):\n","          # setting record of experiments\n","          setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n","              args.model_id,\n","              args.model,\n","              args.data,\n","              args.features,\n","              args.seq_len,\n","              args.label_len,\n","              args.pred_len,\n","              args.d_model,\n","              args.n_heads,\n","              args.e_layers,\n","              args.d_layers,\n","              args.d_ff,\n","              args.factor,\n","              args.embed,\n","              args.distil,\n","              args.des,ii)\n","\n","          exp = Exp(args)  # set experiments\n","\n","          print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","          exp.train(setting)\n","\n","          print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","          exp.test(setting)\n","\n","          if args.do_predict:\n","              print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","              exp.predict(setting, True)\n","\n","          torch.cuda.empty_cache()\n","\n","          print(\"\\n\\n\\n\\n\\n\")\n","\n","  # 실험에서 사용되지 않는 경우.\n","  else:\n","      ii = 0\n","      setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n","                                                                                                  args.model,\n","                                                                                                  args.data,\n","                                                                                                  args.features,\n","                                                                                                  args.seq_len,\n","                                                                                                  args.label_len,\n","                                                                                                  args.pred_len,\n","                                                                                                  args.d_model,\n","                                                                                                  args.n_heads,\n","                                                                                                  args.e_layers,\n","                                                                                                  args.d_layers,\n","                                                                                                  args.d_ff,\n","                                                                                                  args.factor,\n","                                                                                                  args.embed,\n","                                                                                                  args.distil,\n","                                                                                                  args.des, ii)\n","\n","      exp = Exp(args)  # set experiments\n","      print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","      exp.test(setting, test=1)\n","      torch.cuda.empty_cache()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
