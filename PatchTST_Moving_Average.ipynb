{"cells":[{"cell_type":"markdown","metadata":{},"source":["### 전체 실험 결과 표"]},{"cell_type":"markdown","metadata":{},"source":["![image](./Experiment_image.png)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12702,"status":"ok","timestamp":1701020720983,"user":{"displayName":"공자","userId":"09701607017816361852"},"user_tz":-540},"id":"6NYRX3cQb-_T"},"outputs":[],"source":["import argparse\n","import os\n","import torch\n","from exp.exp_main import Exp_Main\n","import random\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"8HtGQ4jncI7P"},"source":["### ETTh1 데이터셋 실험"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1701020720983,"user":{"displayName":"공자","userId":"09701607017816361852"},"user_tz":-540},"id":"5XqpOCPhuWEi","outputId":"842ac6de-1da2-433a-9b7b-115bbeb681f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","<__main__.Args object at 0x7dc8b5db8430>\n"]}],"source":["arg_seq_len=336\n","arg_pred_len = 96\n","\n","model_name='PatchTST'\n","\n","root_path_name='./dataset/'\n","data_path_name='ETTh1.csv'\n","model_id_name='ETTh1'\n","data_name='ETTh1'\n","\n","random_seed=2021\n","\n","class Args:\n","    random_seed = 2021\n","\n","    is_training = 1\n","    model_id = model_id_name\n","    model = model_name\n","\n","    data = data_name\n","    root_path = root_path_name\n","    data_path = data_path_name\n","    features = 'M'\n","    target = 'OT'\n","    freq = 'h'\n","    checkpoints = './checkpoints/'\n","\n","    seq_len = arg_seq_len\n","    fc_dropout= 0.3\n","    head_dropout = 0.0\n","    patch_len = 16\n","    stride = 8\n","    decomposition = 1\n","    enc_in = 7\n","    d_model = 16\n","    n_heads = 4\n","    e_layers = 3\n","    d_ff = 128\n","    dropout = 0.3\n","    itr = 1 # 학습 횟수\n","    train_epochs = 100\n","    batch_size = 128\n","    learning_rate = 0.0001\n","    des = 'Exp'\n","    use_gpu = True\n","    gpu = 0\n","    use_multi_gpu = False\n","    devices = '0'\n","    label_len = 48\n","    d_layers = 1\n","    factor = 1\n","    distil = True\n","    embed = 'timeF'\n","    individual = 0\n","    pred_len = arg_pred_len\n","    padding_patch = 'end'\n","    revin = 1\n","    affine = 0\n","    subtract_last = 0\n","    kernel_size = 25\n","    embed_type = 0\n","    dec_in = 7\n","    c_out = 7\n","    moving_avg = 25\n","    activation = 'gelu'\n","    output_attention = False\n","    do_predict = True\n","    patience = 100\n","    num_workers = 10 # DataLoader에 사용할 subprocess 개수\n","    loss = 'MSE'\n","    lradj = 'type1'\n","    pct_start = 0.3\n","    use_amp = False\n","    test_flop = False\n","\n","args = Args();\n","\n","# random seed\n","fix_seed = args.random_seed\n","random.seed(fix_seed)\n","torch.manual_seed(fix_seed)\n","np.random.seed(fix_seed)\n","\n","args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.dvices = args.devices.replace(' ', '')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1700772,"status":"ok","timestamp":1701022421752,"user":{"displayName":"공자","userId":"09701607017816361852"},"user_tz":-540},"id":"OFd61ZJuuH0W","outputId":"25e7a1bc-7d9f-4c65-c65a-1d35c229e016"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current Prediction Length :  96\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  1\n","Exp_Main init!\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl96_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 8209\n","val 2785\n","test 2785\n","Epoch: 1 cost time: 6.523028612136841\n","Epoch: 1, Steps: 64 | Train Loss: 0.7145033 Vali Loss: 1.4131823 Test Loss: 0.7717640\n","Validation loss decreased (inf --> 1.413182).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 2.35530424118042\n","Epoch: 2, Steps: 64 | Train Loss: 0.5438734 Vali Loss: 0.8120297 Test Loss: 0.4647987\n","Validation loss decreased (1.413182 --> 0.812030).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 2.2132627964019775\n","Epoch: 3, Steps: 64 | Train Loss: 0.4506308 Vali Loss: 0.7506640 Test Loss: 0.4270206\n","Validation loss decreased (0.812030 --> 0.750664).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 2.2227370738983154\n","Epoch: 4, Steps: 64 | Train Loss: 0.4311832 Vali Loss: 0.7405894 Test Loss: 0.4188237\n","Validation loss decreased (0.750664 --> 0.740589).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 2.21052622795105\n","Epoch: 5, Steps: 64 | Train Loss: 0.4238199 Vali Loss: 0.7348801 Test Loss: 0.4152115\n","Validation loss decreased (0.740589 --> 0.734880).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 2.284104824066162\n","Epoch: 6, Steps: 64 | Train Loss: 0.4204915 Vali Loss: 0.7301657 Test Loss: 0.4135308\n","Validation loss decreased (0.734880 --> 0.730166).  Saving model ...\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 2.260908842086792\n","Epoch: 7, Steps: 64 | Train Loss: 0.4189833 Vali Loss: 0.7298798 Test Loss: 0.4127313\n","Validation loss decreased (0.730166 --> 0.729880).  Saving model ...\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 2.2927682399749756\n","Epoch: 8, Steps: 64 | Train Loss: 0.4177187 Vali Loss: 0.7314205 Test Loss: 0.4123033\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 2.402848482131958\n","Epoch: 9, Steps: 64 | Train Loss: 0.4177016 Vali Loss: 0.7296860 Test Loss: 0.4120571\n","Validation loss decreased (0.729880 --> 0.729686).  Saving model ...\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 2.2805066108703613\n","Epoch: 10, Steps: 64 | Train Loss: 0.4172215 Vali Loss: 0.7285657 Test Loss: 0.4119857\n","Validation loss decreased (0.729686 --> 0.728566).  Saving model ...\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 2.211217164993286\n","Epoch: 11, Steps: 64 | Train Loss: 0.4172758 Vali Loss: 0.7281345 Test Loss: 0.4119324\n","Validation loss decreased (0.728566 --> 0.728134).  Saving model ...\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 2.1926774978637695\n","Epoch: 12, Steps: 64 | Train Loss: 0.4173560 Vali Loss: 0.7309322 Test Loss: 0.4119393\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 2.3061771392822266\n","Epoch: 13, Steps: 64 | Train Loss: 0.4171279 Vali Loss: 0.7306924 Test Loss: 0.4118620\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 2.334911823272705\n","Epoch: 14, Steps: 64 | Train Loss: 0.4171251 Vali Loss: 0.7275174 Test Loss: 0.4118474\n","Validation loss decreased (0.728134 --> 0.727517).  Saving model ...\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 2.2403929233551025\n","Epoch: 15, Steps: 64 | Train Loss: 0.4167101 Vali Loss: 0.7286226 Test Loss: 0.4118834\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 2.202732563018799\n","Epoch: 16, Steps: 64 | Train Loss: 0.4172199 Vali Loss: 0.7299148 Test Loss: 0.4118174\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 2.316159248352051\n","Epoch: 17, Steps: 64 | Train Loss: 0.4170743 Vali Loss: 0.7248726 Test Loss: 0.4119271\n","Validation loss decreased (0.727517 --> 0.724873).  Saving model ...\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 2.244236946105957\n","Epoch: 18, Steps: 64 | Train Loss: 0.4172201 Vali Loss: 0.7266593 Test Loss: 0.4118565\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 2.2034804821014404\n","Epoch: 19, Steps: 64 | Train Loss: 0.4170705 Vali Loss: 0.7283676 Test Loss: 0.4119124\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 2.2969493865966797\n","Epoch: 20, Steps: 64 | Train Loss: 0.4171172 Vali Loss: 0.7266195 Test Loss: 0.4119073\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 2.39813494682312\n","Epoch: 21, Steps: 64 | Train Loss: 0.4172335 Vali Loss: 0.7298557 Test Loss: 0.4118351\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 2.2490785121917725\n","Epoch: 22, Steps: 64 | Train Loss: 0.4169693 Vali Loss: 0.7306322 Test Loss: 0.4118480\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 2.202859401702881\n","Epoch: 23, Steps: 64 | Train Loss: 0.4169570 Vali Loss: 0.7295684 Test Loss: 0.4118567\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 2.1949853897094727\n","Epoch: 24, Steps: 64 | Train Loss: 0.4173910 Vali Loss: 0.7333854 Test Loss: 0.4118478\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 2.4412012100219727\n","Epoch: 25, Steps: 64 | Train Loss: 0.4172541 Vali Loss: 0.7294829 Test Loss: 0.4119081\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 2.2713449001312256\n","Epoch: 26, Steps: 64 | Train Loss: 0.4170090 Vali Loss: 0.7282555 Test Loss: 0.4118889\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 2.2422845363616943\n","Epoch: 27, Steps: 64 | Train Loss: 0.4170661 Vali Loss: 0.7242169 Test Loss: 0.4119226\n","Validation loss decreased (0.724873 --> 0.724217).  Saving model ...\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 2.3707494735717773\n","Epoch: 28, Steps: 64 | Train Loss: 0.4169948 Vali Loss: 0.7265505 Test Loss: 0.4119060\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 2.2232227325439453\n","Epoch: 29, Steps: 64 | Train Loss: 0.4167276 Vali Loss: 0.7272099 Test Loss: 0.4119318\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 2.246703863143921\n","Epoch: 30, Steps: 64 | Train Loss: 0.4167488 Vali Loss: 0.7311691 Test Loss: 0.4118294\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 2.216097116470337\n","Epoch: 31, Steps: 64 | Train Loss: 0.4168055 Vali Loss: 0.7283626 Test Loss: 0.4118181\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 2.440889358520508\n","Epoch: 32, Steps: 64 | Train Loss: 0.4169068 Vali Loss: 0.7303521 Test Loss: 0.4118844\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 2.308121681213379\n","Epoch: 33, Steps: 64 | Train Loss: 0.4169526 Vali Loss: 0.7274314 Test Loss: 0.4118823\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 2.3261895179748535\n","Epoch: 34, Steps: 64 | Train Loss: 0.4169742 Vali Loss: 0.7237167 Test Loss: 0.4118300\n","Validation loss decreased (0.724217 --> 0.723717).  Saving model ...\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 2.2409045696258545\n","Epoch: 35, Steps: 64 | Train Loss: 0.4170566 Vali Loss: 0.7275217 Test Loss: 0.4119096\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 2.3893046379089355\n","Epoch: 36, Steps: 64 | Train Loss: 0.4172506 Vali Loss: 0.7284694 Test Loss: 0.4118131\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 2.2436511516571045\n","Epoch: 37, Steps: 64 | Train Loss: 0.4169324 Vali Loss: 0.7266832 Test Loss: 0.4118374\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 2.261253595352173\n","Epoch: 38, Steps: 64 | Train Loss: 0.4172968 Vali Loss: 0.7280923 Test Loss: 0.4119476\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 2.357321262359619\n","Epoch: 39, Steps: 64 | Train Loss: 0.4171960 Vali Loss: 0.7294256 Test Loss: 0.4118964\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 2.3627002239227295\n","Epoch: 40, Steps: 64 | Train Loss: 0.4169553 Vali Loss: 0.7288381 Test Loss: 0.4118059\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 2.233813762664795\n","Epoch: 41, Steps: 64 | Train Loss: 0.4165876 Vali Loss: 0.7263118 Test Loss: 0.4118847\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 2.2319042682647705\n","Epoch: 42, Steps: 64 | Train Loss: 0.4172132 Vali Loss: 0.7247298 Test Loss: 0.4118316\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 2.2662439346313477\n","Epoch: 43, Steps: 64 | Train Loss: 0.4173219 Vali Loss: 0.7287412 Test Loss: 0.4119047\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 2.3582892417907715\n","Epoch: 44, Steps: 64 | Train Loss: 0.4170359 Vali Loss: 0.7284145 Test Loss: 0.4118511\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 2.3413262367248535\n","Epoch: 45, Steps: 64 | Train Loss: 0.4171942 Vali Loss: 0.7264454 Test Loss: 0.4118201\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 2.296980381011963\n","Epoch: 46, Steps: 64 | Train Loss: 0.4172008 Vali Loss: 0.7266814 Test Loss: 0.4118676\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 2.2889461517333984\n","Epoch: 47, Steps: 64 | Train Loss: 0.4169171 Vali Loss: 0.7270439 Test Loss: 0.4118481\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 2.2265660762786865\n","Epoch: 48, Steps: 64 | Train Loss: 0.4172064 Vali Loss: 0.7297536 Test Loss: 0.4118718\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 2.262956380844116\n","Epoch: 49, Steps: 64 | Train Loss: 0.4172738 Vali Loss: 0.7284547 Test Loss: 0.4118744\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 2.2752931118011475\n","Epoch: 50, Steps: 64 | Train Loss: 0.4169010 Vali Loss: 0.7250248 Test Loss: 0.4118464\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 2.4412801265716553\n","Epoch: 51, Steps: 64 | Train Loss: 0.4169597 Vali Loss: 0.7282163 Test Loss: 0.4118988\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 2.2712085247039795\n","Epoch: 52, Steps: 64 | Train Loss: 0.4166640 Vali Loss: 0.7276969 Test Loss: 0.4118789\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 2.2259137630462646\n","Epoch: 53, Steps: 64 | Train Loss: 0.4168659 Vali Loss: 0.7273864 Test Loss: 0.4118908\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 2.265557289123535\n","Epoch: 54, Steps: 64 | Train Loss: 0.4171095 Vali Loss: 0.7246879 Test Loss: 0.4118723\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 2.316516876220703\n","Epoch: 55, Steps: 64 | Train Loss: 0.4170288 Vali Loss: 0.7258046 Test Loss: 0.4119130\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 2.280336856842041\n","Epoch: 56, Steps: 64 | Train Loss: 0.4171323 Vali Loss: 0.7309963 Test Loss: 0.4118710\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 2.2048704624176025\n","Epoch: 57, Steps: 64 | Train Loss: 0.4169415 Vali Loss: 0.7285944 Test Loss: 0.4119405\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 2.391169548034668\n","Epoch: 58, Steps: 64 | Train Loss: 0.4170921 Vali Loss: 0.7276214 Test Loss: 0.4118301\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 2.2495181560516357\n","Epoch: 59, Steps: 64 | Train Loss: 0.4169153 Vali Loss: 0.7275043 Test Loss: 0.4117739\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 2.1775219440460205\n","Epoch: 60, Steps: 64 | Train Loss: 0.4170840 Vali Loss: 0.7307479 Test Loss: 0.4118634\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 2.1773130893707275\n","Epoch: 61, Steps: 64 | Train Loss: 0.4167361 Vali Loss: 0.7250909 Test Loss: 0.4118297\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 2.379445791244507\n","Epoch: 62, Steps: 64 | Train Loss: 0.4170726 Vali Loss: 0.7281111 Test Loss: 0.4118844\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 2.3064050674438477\n","Epoch: 63, Steps: 64 | Train Loss: 0.4172701 Vali Loss: 0.7259907 Test Loss: 0.4118104\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 2.291792631149292\n","Epoch: 64, Steps: 64 | Train Loss: 0.4170646 Vali Loss: 0.7278644 Test Loss: 0.4118561\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 2.3246569633483887\n","Epoch: 65, Steps: 64 | Train Loss: 0.4171077 Vali Loss: 0.7305220 Test Loss: 0.4118267\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 2.345780849456787\n","Epoch: 66, Steps: 64 | Train Loss: 0.4171468 Vali Loss: 0.7272658 Test Loss: 0.4119023\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 2.2169675827026367\n","Epoch: 67, Steps: 64 | Train Loss: 0.4173162 Vali Loss: 0.7281016 Test Loss: 0.4119646\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 2.2289726734161377\n","Epoch: 68, Steps: 64 | Train Loss: 0.4167132 Vali Loss: 0.7276207 Test Loss: 0.4118225\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 2.359562397003174\n","Epoch: 69, Steps: 64 | Train Loss: 0.4172214 Vali Loss: 0.7292176 Test Loss: 0.4119014\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 2.4720208644866943\n","Epoch: 70, Steps: 64 | Train Loss: 0.4172164 Vali Loss: 0.7272165 Test Loss: 0.4119114\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 2.284783124923706\n","Epoch: 71, Steps: 64 | Train Loss: 0.4174557 Vali Loss: 0.7256562 Test Loss: 0.4118860\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 2.2646241188049316\n","Epoch: 72, Steps: 64 | Train Loss: 0.4170574 Vali Loss: 0.7265404 Test Loss: 0.4118833\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 2.356964349746704\n","Epoch: 73, Steps: 64 | Train Loss: 0.4173312 Vali Loss: 0.7223936 Test Loss: 0.4119805\n","Validation loss decreased (0.723717 --> 0.722394).  Saving model ...\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 2.335684299468994\n","Epoch: 74, Steps: 64 | Train Loss: 0.4169017 Vali Loss: 0.7275597 Test Loss: 0.4118100\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 2.2400150299072266\n","Epoch: 75, Steps: 64 | Train Loss: 0.4173238 Vali Loss: 0.7281517 Test Loss: 0.4118793\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 2.304138660430908\n","Epoch: 76, Steps: 64 | Train Loss: 0.4170887 Vali Loss: 0.7248511 Test Loss: 0.4118873\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 2.405613899230957\n","Epoch: 77, Steps: 64 | Train Loss: 0.4170487 Vali Loss: 0.7279863 Test Loss: 0.4118651\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 2.2434804439544678\n","Epoch: 78, Steps: 64 | Train Loss: 0.4173577 Vali Loss: 0.7275852 Test Loss: 0.4119003\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 2.2203457355499268\n","Epoch: 79, Steps: 64 | Train Loss: 0.4172837 Vali Loss: 0.7273580 Test Loss: 0.4118726\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 2.396272659301758\n","Epoch: 80, Steps: 64 | Train Loss: 0.4167746 Vali Loss: 0.7298194 Test Loss: 0.4118913\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 2.448423385620117\n","Epoch: 81, Steps: 64 | Train Loss: 0.4173316 Vali Loss: 0.7266208 Test Loss: 0.4118709\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 2.316833972930908\n","Epoch: 82, Steps: 64 | Train Loss: 0.4168965 Vali Loss: 0.7248219 Test Loss: 0.4118655\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 2.324176073074341\n","Epoch: 83, Steps: 64 | Train Loss: 0.4173946 Vali Loss: 0.7221965 Test Loss: 0.4119051\n","Validation loss decreased (0.722394 --> 0.722196).  Saving model ...\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 2.342069387435913\n","Epoch: 84, Steps: 64 | Train Loss: 0.4172448 Vali Loss: 0.7229692 Test Loss: 0.4118405\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 2.2565560340881348\n","Epoch: 85, Steps: 64 | Train Loss: 0.4169136 Vali Loss: 0.7289734 Test Loss: 0.4118731\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 2.219440221786499\n","Epoch: 86, Steps: 64 | Train Loss: 0.4172742 Vali Loss: 0.7271535 Test Loss: 0.4119041\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 2.2908706665039062\n","Epoch: 87, Steps: 64 | Train Loss: 0.4173038 Vali Loss: 0.7243772 Test Loss: 0.4118736\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 2.4193837642669678\n","Epoch: 88, Steps: 64 | Train Loss: 0.4171959 Vali Loss: 0.7272729 Test Loss: 0.4118006\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 2.283886671066284\n","Epoch: 89, Steps: 64 | Train Loss: 0.4170508 Vali Loss: 0.7269868 Test Loss: 0.4118750\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 2.2756919860839844\n","Epoch: 90, Steps: 64 | Train Loss: 0.4173459 Vali Loss: 0.7281980 Test Loss: 0.4117813\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 2.268899917602539\n","Epoch: 91, Steps: 64 | Train Loss: 0.4170599 Vali Loss: 0.7285106 Test Loss: 0.4118639\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 2.322575569152832\n","Epoch: 92, Steps: 64 | Train Loss: 0.4173460 Vali Loss: 0.7253985 Test Loss: 0.4119136\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 2.3517868518829346\n","Epoch: 93, Steps: 64 | Train Loss: 0.4167408 Vali Loss: 0.7266452 Test Loss: 0.4118692\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 2.3039968013763428\n","Epoch: 94, Steps: 64 | Train Loss: 0.4171036 Vali Loss: 0.7294239 Test Loss: 0.4119102\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 2.3248798847198486\n","Epoch: 95, Steps: 64 | Train Loss: 0.4170067 Vali Loss: 0.7267938 Test Loss: 0.4118046\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 2.2794742584228516\n","Epoch: 96, Steps: 64 | Train Loss: 0.4164592 Vali Loss: 0.7276121 Test Loss: 0.4119355\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 2.2483325004577637\n","Epoch: 97, Steps: 64 | Train Loss: 0.4174844 Vali Loss: 0.7284789 Test Loss: 0.4118815\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 2.235532760620117\n","Epoch: 98, Steps: 64 | Train Loss: 0.4171201 Vali Loss: 0.7231206 Test Loss: 0.4118572\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 2.3679234981536865\n","Epoch: 99, Steps: 64 | Train Loss: 0.4170100 Vali Loss: 0.7290795 Test Loss: 0.4118589\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 2.194669485092163\n","Epoch: 100, Steps: 64 | Train Loss: 0.4170390 Vali Loss: 0.7314560 Test Loss: 0.4118849\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl96_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2785\n","mse:0.41190508008003235, mae:0.42838478088378906, rse:0.6085748672485352\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl96_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  192\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  1\n","Exp_Main init!\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 8113\n","val 2689\n","test 2689\n","Epoch: 1 cost time: 2.3429017066955566\n","Epoch: 1, Steps: 63 | Train Loss: 0.7533789 Vali Loss: 1.5677567 Test Loss: 0.7779406\n","Validation loss decreased (inf --> 1.567757).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 2.2744038105010986\n","Epoch: 2, Steps: 63 | Train Loss: 0.5925620 Vali Loss: 1.0626334 Test Loss: 0.5041926\n","Validation loss decreased (1.567757 --> 1.062633).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 2.2689599990844727\n","Epoch: 3, Steps: 63 | Train Loss: 0.5061500 Vali Loss: 0.9929224 Test Loss: 0.4660093\n","Validation loss decreased (1.062633 --> 0.992922).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 2.364170789718628\n","Epoch: 4, Steps: 63 | Train Loss: 0.4861607 Vali Loss: 0.9791026 Test Loss: 0.4574605\n","Validation loss decreased (0.992922 --> 0.979103).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 2.381103277206421\n","Epoch: 5, Steps: 63 | Train Loss: 0.4788171 Vali Loss: 0.9738297 Test Loss: 0.4539346\n","Validation loss decreased (0.979103 --> 0.973830).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 2.3212177753448486\n","Epoch: 6, Steps: 63 | Train Loss: 0.4750375 Vali Loss: 0.9713091 Test Loss: 0.4521898\n","Validation loss decreased (0.973830 --> 0.971309).  Saving model ...\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 2.27618145942688\n","Epoch: 7, Steps: 63 | Train Loss: 0.4732865 Vali Loss: 0.9697869 Test Loss: 0.4513423\n","Validation loss decreased (0.971309 --> 0.969787).  Saving model ...\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 2.3543248176574707\n","Epoch: 8, Steps: 63 | Train Loss: 0.4728745 Vali Loss: 0.9692720 Test Loss: 0.4509072\n","Validation loss decreased (0.969787 --> 0.969272).  Saving model ...\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 2.3238131999969482\n","Epoch: 9, Steps: 63 | Train Loss: 0.4726938 Vali Loss: 0.9691072 Test Loss: 0.4506747\n","Validation loss decreased (0.969272 --> 0.969107).  Saving model ...\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 2.302774429321289\n","Epoch: 10, Steps: 63 | Train Loss: 0.4722833 Vali Loss: 0.9683834 Test Loss: 0.4505904\n","Validation loss decreased (0.969107 --> 0.968383).  Saving model ...\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 2.300501585006714\n","Epoch: 11, Steps: 63 | Train Loss: 0.4716879 Vali Loss: 0.9682050 Test Loss: 0.4505132\n","Validation loss decreased (0.968383 --> 0.968205).  Saving model ...\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 2.453070640563965\n","Epoch: 12, Steps: 63 | Train Loss: 0.4720408 Vali Loss: 0.9681436 Test Loss: 0.4505117\n","Validation loss decreased (0.968205 --> 0.968144).  Saving model ...\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 2.230703592300415\n","Epoch: 13, Steps: 63 | Train Loss: 0.4719119 Vali Loss: 0.9686361 Test Loss: 0.4504656\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 2.2387845516204834\n","Epoch: 14, Steps: 63 | Train Loss: 0.4717205 Vali Loss: 0.9684213 Test Loss: 0.4504659\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 2.4023663997650146\n","Epoch: 15, Steps: 63 | Train Loss: 0.4721708 Vali Loss: 0.9682246 Test Loss: 0.4504752\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 2.3718297481536865\n","Epoch: 16, Steps: 63 | Train Loss: 0.4721615 Vali Loss: 0.9684386 Test Loss: 0.4504564\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 2.298999786376953\n","Epoch: 17, Steps: 63 | Train Loss: 0.4719843 Vali Loss: 0.9686181 Test Loss: 0.4504574\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 2.225907802581787\n","Epoch: 18, Steps: 63 | Train Loss: 0.4721251 Vali Loss: 0.9684727 Test Loss: 0.4504693\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 2.4170098304748535\n","Epoch: 19, Steps: 63 | Train Loss: 0.4720728 Vali Loss: 0.9681014 Test Loss: 0.4504623\n","Validation loss decreased (0.968144 --> 0.968101).  Saving model ...\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 2.2128069400787354\n","Epoch: 20, Steps: 63 | Train Loss: 0.4723740 Vali Loss: 0.9683425 Test Loss: 0.4504599\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 2.297316312789917\n","Epoch: 21, Steps: 63 | Train Loss: 0.4717370 Vali Loss: 0.9685563 Test Loss: 0.4504308\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 2.4501399993896484\n","Epoch: 22, Steps: 63 | Train Loss: 0.4721868 Vali Loss: 0.9685411 Test Loss: 0.4504496\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 2.307013750076294\n","Epoch: 23, Steps: 63 | Train Loss: 0.4720812 Vali Loss: 0.9685287 Test Loss: 0.4504896\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 2.2728333473205566\n","Epoch: 24, Steps: 63 | Train Loss: 0.4719695 Vali Loss: 0.9684941 Test Loss: 0.4504265\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 2.24265456199646\n","Epoch: 25, Steps: 63 | Train Loss: 0.4720631 Vali Loss: 0.9683698 Test Loss: 0.4505008\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 2.414926767349243\n","Epoch: 26, Steps: 63 | Train Loss: 0.4718446 Vali Loss: 0.9686678 Test Loss: 0.4504570\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 2.307847023010254\n","Epoch: 27, Steps: 63 | Train Loss: 0.4721348 Vali Loss: 0.9684435 Test Loss: 0.4504625\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 2.319538116455078\n","Epoch: 28, Steps: 63 | Train Loss: 0.4719331 Vali Loss: 0.9682311 Test Loss: 0.4504165\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 2.375178337097168\n","Epoch: 29, Steps: 63 | Train Loss: 0.4722504 Vali Loss: 0.9687387 Test Loss: 0.4504864\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 2.382791042327881\n","Epoch: 30, Steps: 63 | Train Loss: 0.4717809 Vali Loss: 0.9685271 Test Loss: 0.4505028\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 2.2527236938476562\n","Epoch: 31, Steps: 63 | Train Loss: 0.4721506 Vali Loss: 0.9686161 Test Loss: 0.4504553\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 2.36141300201416\n","Epoch: 32, Steps: 63 | Train Loss: 0.4719904 Vali Loss: 0.9686111 Test Loss: 0.4504933\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 2.3252880573272705\n","Epoch: 33, Steps: 63 | Train Loss: 0.4724898 Vali Loss: 0.9677851 Test Loss: 0.4504640\n","Validation loss decreased (0.968101 --> 0.967785).  Saving model ...\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 2.3547379970550537\n","Epoch: 34, Steps: 63 | Train Loss: 0.4717100 Vali Loss: 0.9686723 Test Loss: 0.4504673\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 2.282557725906372\n","Epoch: 35, Steps: 63 | Train Loss: 0.4722464 Vali Loss: 0.9685794 Test Loss: 0.4504538\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 2.2318851947784424\n","Epoch: 36, Steps: 63 | Train Loss: 0.4720781 Vali Loss: 0.9684015 Test Loss: 0.4504580\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 2.357028007507324\n","Epoch: 37, Steps: 63 | Train Loss: 0.4717141 Vali Loss: 0.9687572 Test Loss: 0.4504537\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 2.311602830886841\n","Epoch: 38, Steps: 63 | Train Loss: 0.4721119 Vali Loss: 0.9685948 Test Loss: 0.4504188\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 2.348280906677246\n","Epoch: 39, Steps: 63 | Train Loss: 0.4720865 Vali Loss: 0.9686301 Test Loss: 0.4504656\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 2.470633029937744\n","Epoch: 40, Steps: 63 | Train Loss: 0.4724376 Vali Loss: 0.9685756 Test Loss: 0.4504723\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 2.2871646881103516\n","Epoch: 41, Steps: 63 | Train Loss: 0.4716819 Vali Loss: 0.9685759 Test Loss: 0.4504699\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 2.293850898742676\n","Epoch: 42, Steps: 63 | Train Loss: 0.4723610 Vali Loss: 0.9681612 Test Loss: 0.4504163\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 2.2949862480163574\n","Epoch: 43, Steps: 63 | Train Loss: 0.4718046 Vali Loss: 0.9685127 Test Loss: 0.4504371\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 2.422471284866333\n","Epoch: 44, Steps: 63 | Train Loss: 0.4721503 Vali Loss: 0.9686608 Test Loss: 0.4504529\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 2.4040699005126953\n","Epoch: 45, Steps: 63 | Train Loss: 0.4722682 Vali Loss: 0.9687399 Test Loss: 0.4504836\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 2.3741424083709717\n","Epoch: 46, Steps: 63 | Train Loss: 0.4723082 Vali Loss: 0.9681819 Test Loss: 0.4504847\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 2.364485502243042\n","Epoch: 47, Steps: 63 | Train Loss: 0.4718703 Vali Loss: 0.9686663 Test Loss: 0.4504777\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 2.265373468399048\n","Epoch: 48, Steps: 63 | Train Loss: 0.4721688 Vali Loss: 0.9686404 Test Loss: 0.4504583\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 2.3009891510009766\n","Epoch: 49, Steps: 63 | Train Loss: 0.4721615 Vali Loss: 0.9686643 Test Loss: 0.4504940\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 2.345512628555298\n","Epoch: 50, Steps: 63 | Train Loss: 0.4719378 Vali Loss: 0.9687858 Test Loss: 0.4504860\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 2.358996629714966\n","Epoch: 51, Steps: 63 | Train Loss: 0.4717190 Vali Loss: 0.9687028 Test Loss: 0.4504829\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 2.375506639480591\n","Epoch: 52, Steps: 63 | Train Loss: 0.4722479 Vali Loss: 0.9687333 Test Loss: 0.4504941\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 2.191716194152832\n","Epoch: 53, Steps: 63 | Train Loss: 0.4724291 Vali Loss: 0.9685799 Test Loss: 0.4504852\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 2.375908851623535\n","Epoch: 54, Steps: 63 | Train Loss: 0.4718360 Vali Loss: 0.9680107 Test Loss: 0.4504437\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 2.280226945877075\n","Epoch: 55, Steps: 63 | Train Loss: 0.4721124 Vali Loss: 0.9685845 Test Loss: 0.4505133\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 2.3308088779449463\n","Epoch: 56, Steps: 63 | Train Loss: 0.4721443 Vali Loss: 0.9684922 Test Loss: 0.4504547\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 2.361344337463379\n","Epoch: 57, Steps: 63 | Train Loss: 0.4720886 Vali Loss: 0.9686052 Test Loss: 0.4504739\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 2.453191041946411\n","Epoch: 58, Steps: 63 | Train Loss: 0.4720449 Vali Loss: 0.9686857 Test Loss: 0.4504964\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 2.3052518367767334\n","Epoch: 59, Steps: 63 | Train Loss: 0.4720306 Vali Loss: 0.9686973 Test Loss: 0.4504774\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 2.212815523147583\n","Epoch: 60, Steps: 63 | Train Loss: 0.4718892 Vali Loss: 0.9686128 Test Loss: 0.4504583\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 2.472676992416382\n","Epoch: 61, Steps: 63 | Train Loss: 0.4719896 Vali Loss: 0.9687260 Test Loss: 0.4504532\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 2.325913190841675\n","Epoch: 62, Steps: 63 | Train Loss: 0.4720156 Vali Loss: 0.9686236 Test Loss: 0.4504396\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 2.331981897354126\n","Epoch: 63, Steps: 63 | Train Loss: 0.4722130 Vali Loss: 0.9686378 Test Loss: 0.4504737\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 2.3982090950012207\n","Epoch: 64, Steps: 63 | Train Loss: 0.4722060 Vali Loss: 0.9686281 Test Loss: 0.4504683\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 2.3655107021331787\n","Epoch: 65, Steps: 63 | Train Loss: 0.4719095 Vali Loss: 0.9685535 Test Loss: 0.4504516\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 2.287712574005127\n","Epoch: 66, Steps: 63 | Train Loss: 0.4722386 Vali Loss: 0.9680960 Test Loss: 0.4504660\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 2.365230083465576\n","Epoch: 67, Steps: 63 | Train Loss: 0.4722466 Vali Loss: 0.9686046 Test Loss: 0.4504881\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 2.3839404582977295\n","Epoch: 68, Steps: 63 | Train Loss: 0.4723121 Vali Loss: 0.9684193 Test Loss: 0.4504577\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 2.371769428253174\n","Epoch: 69, Steps: 63 | Train Loss: 0.4717668 Vali Loss: 0.9683424 Test Loss: 0.4504830\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 2.2666707038879395\n","Epoch: 70, Steps: 63 | Train Loss: 0.4720614 Vali Loss: 0.9686011 Test Loss: 0.4504756\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 2.3377983570098877\n","Epoch: 71, Steps: 63 | Train Loss: 0.4722273 Vali Loss: 0.9684053 Test Loss: 0.4504883\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 2.3445932865142822\n","Epoch: 72, Steps: 63 | Train Loss: 0.4719473 Vali Loss: 0.9683591 Test Loss: 0.4504976\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 2.335759162902832\n","Epoch: 73, Steps: 63 | Train Loss: 0.4719953 Vali Loss: 0.9685282 Test Loss: 0.4504829\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 2.3977434635162354\n","Epoch: 74, Steps: 63 | Train Loss: 0.4716944 Vali Loss: 0.9686869 Test Loss: 0.4505230\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 2.4557151794433594\n","Epoch: 75, Steps: 63 | Train Loss: 0.4715745 Vali Loss: 0.9683996 Test Loss: 0.4505493\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 2.283655881881714\n","Epoch: 76, Steps: 63 | Train Loss: 0.4717909 Vali Loss: 0.9679392 Test Loss: 0.4504716\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 2.3120787143707275\n","Epoch: 77, Steps: 63 | Train Loss: 0.4721856 Vali Loss: 0.9683927 Test Loss: 0.4504778\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 2.301476001739502\n","Epoch: 78, Steps: 63 | Train Loss: 0.4724599 Vali Loss: 0.9679997 Test Loss: 0.4504719\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 2.5446290969848633\n","Epoch: 79, Steps: 63 | Train Loss: 0.4719851 Vali Loss: 0.9686156 Test Loss: 0.4504742\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 2.398815870285034\n","Epoch: 80, Steps: 63 | Train Loss: 0.4720210 Vali Loss: 0.9682640 Test Loss: 0.4504826\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 2.3600285053253174\n","Epoch: 81, Steps: 63 | Train Loss: 0.4722977 Vali Loss: 0.9687033 Test Loss: 0.4504766\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 2.389069080352783\n","Epoch: 82, Steps: 63 | Train Loss: 0.4719201 Vali Loss: 0.9683644 Test Loss: 0.4504745\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 2.3721654415130615\n","Epoch: 83, Steps: 63 | Train Loss: 0.4722360 Vali Loss: 0.9682869 Test Loss: 0.4504666\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 2.287047863006592\n","Epoch: 84, Steps: 63 | Train Loss: 0.4719552 Vali Loss: 0.9683402 Test Loss: 0.4504960\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 2.423715829849243\n","Epoch: 85, Steps: 63 | Train Loss: 0.4721999 Vali Loss: 0.9687091 Test Loss: 0.4504850\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 2.4772419929504395\n","Epoch: 86, Steps: 63 | Train Loss: 0.4716439 Vali Loss: 0.9684669 Test Loss: 0.4504712\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 2.293071985244751\n","Epoch: 87, Steps: 63 | Train Loss: 0.4717020 Vali Loss: 0.9685488 Test Loss: 0.4504378\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 2.2665622234344482\n","Epoch: 88, Steps: 63 | Train Loss: 0.4717507 Vali Loss: 0.9686285 Test Loss: 0.4504523\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 2.3859331607818604\n","Epoch: 89, Steps: 63 | Train Loss: 0.4722212 Vali Loss: 0.9682226 Test Loss: 0.4504953\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 2.317243814468384\n","Epoch: 90, Steps: 63 | Train Loss: 0.4719274 Vali Loss: 0.9679980 Test Loss: 0.4504857\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 2.360348701477051\n","Epoch: 91, Steps: 63 | Train Loss: 0.4716288 Vali Loss: 0.9683356 Test Loss: 0.4504565\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 2.3226799964904785\n","Epoch: 92, Steps: 63 | Train Loss: 0.4720340 Vali Loss: 0.9683200 Test Loss: 0.4504851\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 2.4589626789093018\n","Epoch: 93, Steps: 63 | Train Loss: 0.4720827 Vali Loss: 0.9683852 Test Loss: 0.4504531\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 2.2457499504089355\n","Epoch: 94, Steps: 63 | Train Loss: 0.4721564 Vali Loss: 0.9681535 Test Loss: 0.4504634\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 2.2572901248931885\n","Epoch: 95, Steps: 63 | Train Loss: 0.4722974 Vali Loss: 0.9686784 Test Loss: 0.4504921\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 2.495274066925049\n","Epoch: 96, Steps: 63 | Train Loss: 0.4720364 Vali Loss: 0.9685634 Test Loss: 0.4504752\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 2.3819949626922607\n","Epoch: 97, Steps: 63 | Train Loss: 0.4722440 Vali Loss: 0.9685504 Test Loss: 0.4504629\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 2.314807176589966\n","Epoch: 98, Steps: 63 | Train Loss: 0.4723892 Vali Loss: 0.9685863 Test Loss: 0.4504599\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 2.319765567779541\n","Epoch: 99, Steps: 63 | Train Loss: 0.4714251 Vali Loss: 0.9681680 Test Loss: 0.4504901\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 2.356567144393921\n","Epoch: 100, Steps: 63 | Train Loss: 0.4724761 Vali Loss: 0.9683253 Test Loss: 0.4504918\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2689\n","mse:0.4504642188549042, mae:0.4502984583377838, rse:0.6373556852340698\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  336\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  1\n","Exp_Main init!\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 7969\n","val 2545\n","test 2545\n","Epoch: 1 cost time: 2.4375109672546387\n","Epoch: 1, Steps: 62 | Train Loss: 0.7968274 Vali Loss: 1.7044082 Test Loss: 0.7618362\n","Validation loss decreased (inf --> 1.704408).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 2.4737019538879395\n","Epoch: 2, Steps: 62 | Train Loss: 0.6467816 Vali Loss: 1.2738314 Test Loss: 0.4976673\n","Validation loss decreased (1.704408 --> 1.273831).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 2.283942222595215\n","Epoch: 3, Steps: 62 | Train Loss: 0.5564821 Vali Loss: 1.2126400 Test Loss: 0.4608098\n","Validation loss decreased (1.273831 --> 1.212640).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 2.3339414596557617\n","Epoch: 4, Steps: 62 | Train Loss: 0.5384512 Vali Loss: 1.2022146 Test Loss: 0.4542483\n","Validation loss decreased (1.212640 --> 1.202215).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 2.498899221420288\n","Epoch: 5, Steps: 62 | Train Loss: 0.5320299 Vali Loss: 1.1914943 Test Loss: 0.4515544\n","Validation loss decreased (1.202215 --> 1.191494).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 2.3125205039978027\n","Epoch: 6, Steps: 62 | Train Loss: 0.5283044 Vali Loss: 1.1943151 Test Loss: 0.4503677\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 2.420894145965576\n","Epoch: 7, Steps: 62 | Train Loss: 0.5269869 Vali Loss: 1.1958104 Test Loss: 0.4496920\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 2.4835805892944336\n","Epoch: 8, Steps: 62 | Train Loss: 0.5262373 Vali Loss: 1.1940733 Test Loss: 0.4494427\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 2.2934300899505615\n","Epoch: 9, Steps: 62 | Train Loss: 0.5261312 Vali Loss: 1.1936947 Test Loss: 0.4492835\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 2.331716775894165\n","Epoch: 10, Steps: 62 | Train Loss: 0.5256464 Vali Loss: 1.1899482 Test Loss: 0.4491680\n","Validation loss decreased (1.191494 --> 1.189948).  Saving model ...\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 2.3924152851104736\n","Epoch: 11, Steps: 62 | Train Loss: 0.5257445 Vali Loss: 1.1947622 Test Loss: 0.4490952\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 2.4990499019622803\n","Epoch: 12, Steps: 62 | Train Loss: 0.5259591 Vali Loss: 1.1945744 Test Loss: 0.4490917\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 2.3403987884521484\n","Epoch: 13, Steps: 62 | Train Loss: 0.5254609 Vali Loss: 1.1943243 Test Loss: 0.4490695\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 2.330094337463379\n","Epoch: 14, Steps: 62 | Train Loss: 0.5252876 Vali Loss: 1.1887485 Test Loss: 0.4490159\n","Validation loss decreased (1.189948 --> 1.188748).  Saving model ...\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 2.3989932537078857\n","Epoch: 15, Steps: 62 | Train Loss: 0.5255840 Vali Loss: 1.1893517 Test Loss: 0.4490285\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 2.2689132690429688\n","Epoch: 16, Steps: 62 | Train Loss: 0.5259293 Vali Loss: 1.1911711 Test Loss: 0.4491029\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 2.3739380836486816\n","Epoch: 17, Steps: 62 | Train Loss: 0.5251246 Vali Loss: 1.1917318 Test Loss: 0.4490642\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 2.4474730491638184\n","Epoch: 18, Steps: 62 | Train Loss: 0.5258295 Vali Loss: 1.1928402 Test Loss: 0.4490550\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 2.4121711254119873\n","Epoch: 19, Steps: 62 | Train Loss: 0.5254841 Vali Loss: 1.1899357 Test Loss: 0.4491025\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 2.2726969718933105\n","Epoch: 20, Steps: 62 | Train Loss: 0.5253298 Vali Loss: 1.1939340 Test Loss: 0.4490167\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 2.381093978881836\n","Epoch: 21, Steps: 62 | Train Loss: 0.5256026 Vali Loss: 1.1928021 Test Loss: 0.4490329\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 2.40847110748291\n","Epoch: 22, Steps: 62 | Train Loss: 0.5258131 Vali Loss: 1.1955080 Test Loss: 0.4490777\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 2.378162145614624\n","Epoch: 23, Steps: 62 | Train Loss: 0.5260314 Vali Loss: 1.1928895 Test Loss: 0.4491242\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 2.3560848236083984\n","Epoch: 24, Steps: 62 | Train Loss: 0.5259695 Vali Loss: 1.1958472 Test Loss: 0.4490534\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 2.431382656097412\n","Epoch: 25, Steps: 62 | Train Loss: 0.5253256 Vali Loss: 1.1934503 Test Loss: 0.4491114\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 2.3840012550354004\n","Epoch: 26, Steps: 62 | Train Loss: 0.5253736 Vali Loss: 1.1948075 Test Loss: 0.4490406\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 2.3099453449249268\n","Epoch: 27, Steps: 62 | Train Loss: 0.5254770 Vali Loss: 1.1928383 Test Loss: 0.4490772\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 2.4101970195770264\n","Epoch: 28, Steps: 62 | Train Loss: 0.5258555 Vali Loss: 1.1900421 Test Loss: 0.4490445\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 2.5103325843811035\n","Epoch: 29, Steps: 62 | Train Loss: 0.5251059 Vali Loss: 1.1925617 Test Loss: 0.4491029\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 2.4255127906799316\n","Epoch: 30, Steps: 62 | Train Loss: 0.5255343 Vali Loss: 1.1968614 Test Loss: 0.4491011\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 2.3783822059631348\n","Epoch: 31, Steps: 62 | Train Loss: 0.5256851 Vali Loss: 1.1936836 Test Loss: 0.4490011\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 2.3899595737457275\n","Epoch: 32, Steps: 62 | Train Loss: 0.5253027 Vali Loss: 1.1938555 Test Loss: 0.4490914\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 2.3399765491485596\n","Epoch: 33, Steps: 62 | Train Loss: 0.5256591 Vali Loss: 1.1953075 Test Loss: 0.4490664\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 2.3746981620788574\n","Epoch: 34, Steps: 62 | Train Loss: 0.5256824 Vali Loss: 1.1928154 Test Loss: 0.4490367\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 2.399857997894287\n","Epoch: 35, Steps: 62 | Train Loss: 0.5255113 Vali Loss: 1.1914250 Test Loss: 0.4491203\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 2.4769864082336426\n","Epoch: 36, Steps: 62 | Train Loss: 0.5253602 Vali Loss: 1.1899977 Test Loss: 0.4489993\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 2.347062349319458\n","Epoch: 37, Steps: 62 | Train Loss: 0.5256183 Vali Loss: 1.1909909 Test Loss: 0.4490835\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 2.27742600440979\n","Epoch: 38, Steps: 62 | Train Loss: 0.5257284 Vali Loss: 1.1914331 Test Loss: 0.4490618\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 2.523362159729004\n","Epoch: 39, Steps: 62 | Train Loss: 0.5252864 Vali Loss: 1.1911649 Test Loss: 0.4490251\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 2.3370721340179443\n","Epoch: 40, Steps: 62 | Train Loss: 0.5256583 Vali Loss: 1.1930250 Test Loss: 0.4490706\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 2.3429830074310303\n","Epoch: 41, Steps: 62 | Train Loss: 0.5256517 Vali Loss: 1.1903925 Test Loss: 0.4490484\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 2.3917126655578613\n","Epoch: 42, Steps: 62 | Train Loss: 0.5254172 Vali Loss: 1.1907058 Test Loss: 0.4490355\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 2.2978129386901855\n","Epoch: 43, Steps: 62 | Train Loss: 0.5252236 Vali Loss: 1.1932026 Test Loss: 0.4491092\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 2.3561081886291504\n","Epoch: 44, Steps: 62 | Train Loss: 0.5254931 Vali Loss: 1.1896530 Test Loss: 0.4489965\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 2.406395435333252\n","Epoch: 45, Steps: 62 | Train Loss: 0.5256872 Vali Loss: 1.1950676 Test Loss: 0.4490466\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 2.4752860069274902\n","Epoch: 46, Steps: 62 | Train Loss: 0.5258931 Vali Loss: 1.1940457 Test Loss: 0.4490332\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 2.4057888984680176\n","Epoch: 47, Steps: 62 | Train Loss: 0.5256232 Vali Loss: 1.1955434 Test Loss: 0.4490817\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 2.349030017852783\n","Epoch: 48, Steps: 62 | Train Loss: 0.5256710 Vali Loss: 1.1938779 Test Loss: 0.4490536\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 2.3406474590301514\n","Epoch: 49, Steps: 62 | Train Loss: 0.5251814 Vali Loss: 1.1957505 Test Loss: 0.4490432\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 2.3264145851135254\n","Epoch: 50, Steps: 62 | Train Loss: 0.5252228 Vali Loss: 1.1926004 Test Loss: 0.4491052\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 2.3687005043029785\n","Epoch: 51, Steps: 62 | Train Loss: 0.5254020 Vali Loss: 1.1872350 Test Loss: 0.4490547\n","Validation loss decreased (1.188748 --> 1.187235).  Saving model ...\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 2.4938228130340576\n","Epoch: 52, Steps: 62 | Train Loss: 0.5254870 Vali Loss: 1.1933546 Test Loss: 0.4489786\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 2.5045559406280518\n","Epoch: 53, Steps: 62 | Train Loss: 0.5253008 Vali Loss: 1.1909016 Test Loss: 0.4490835\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 2.3026442527770996\n","Epoch: 54, Steps: 62 | Train Loss: 0.5258010 Vali Loss: 1.1920826 Test Loss: 0.4491062\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 2.3742904663085938\n","Epoch: 55, Steps: 62 | Train Loss: 0.5256693 Vali Loss: 1.1938199 Test Loss: 0.4490627\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 2.5557234287261963\n","Epoch: 56, Steps: 62 | Train Loss: 0.5253955 Vali Loss: 1.1939307 Test Loss: 0.4490240\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 2.324122190475464\n","Epoch: 57, Steps: 62 | Train Loss: 0.5252961 Vali Loss: 1.1911072 Test Loss: 0.4490491\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 2.412195920944214\n","Epoch: 58, Steps: 62 | Train Loss: 0.5256566 Vali Loss: 1.1940963 Test Loss: 0.4490451\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 2.5062499046325684\n","Epoch: 59, Steps: 62 | Train Loss: 0.5254730 Vali Loss: 1.1944419 Test Loss: 0.4491332\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 2.3485050201416016\n","Epoch: 60, Steps: 62 | Train Loss: 0.5251243 Vali Loss: 1.1926425 Test Loss: 0.4490711\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 2.3751766681671143\n","Epoch: 61, Steps: 62 | Train Loss: 0.5256538 Vali Loss: 1.1926880 Test Loss: 0.4491190\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 2.4326794147491455\n","Epoch: 62, Steps: 62 | Train Loss: 0.5258046 Vali Loss: 1.1904502 Test Loss: 0.4492148\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 2.464088201522827\n","Epoch: 63, Steps: 62 | Train Loss: 0.5257153 Vali Loss: 1.1958737 Test Loss: 0.4490302\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 2.4115021228790283\n","Epoch: 64, Steps: 62 | Train Loss: 0.5255340 Vali Loss: 1.1950469 Test Loss: 0.4490859\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 2.3808000087738037\n","Epoch: 65, Steps: 62 | Train Loss: 0.5255673 Vali Loss: 1.1946384 Test Loss: 0.4490264\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 2.453433036804199\n","Epoch: 66, Steps: 62 | Train Loss: 0.5253497 Vali Loss: 1.1957282 Test Loss: 0.4490449\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 2.401895523071289\n","Epoch: 67, Steps: 62 | Train Loss: 0.5256405 Vali Loss: 1.1964589 Test Loss: 0.4490469\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 2.422729253768921\n","Epoch: 68, Steps: 62 | Train Loss: 0.5257736 Vali Loss: 1.1936016 Test Loss: 0.4490762\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 2.537639617919922\n","Epoch: 69, Steps: 62 | Train Loss: 0.5253353 Vali Loss: 1.1899083 Test Loss: 0.4491031\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 2.4007506370544434\n","Epoch: 70, Steps: 62 | Train Loss: 0.5254719 Vali Loss: 1.1932853 Test Loss: 0.4491066\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 2.350994825363159\n","Epoch: 71, Steps: 62 | Train Loss: 0.5258718 Vali Loss: 1.1896312 Test Loss: 0.4491037\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 2.396122694015503\n","Epoch: 72, Steps: 62 | Train Loss: 0.5254060 Vali Loss: 1.1919612 Test Loss: 0.4490882\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 2.535814046859741\n","Epoch: 73, Steps: 62 | Train Loss: 0.5255708 Vali Loss: 1.1931874 Test Loss: 0.4490665\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 2.366392135620117\n","Epoch: 74, Steps: 62 | Train Loss: 0.5253923 Vali Loss: 1.1877766 Test Loss: 0.4490879\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 2.373187780380249\n","Epoch: 75, Steps: 62 | Train Loss: 0.5258354 Vali Loss: 1.1904014 Test Loss: 0.4490705\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 2.431331157684326\n","Epoch: 76, Steps: 62 | Train Loss: 0.5256790 Vali Loss: 1.1940663 Test Loss: 0.4490430\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 2.3510544300079346\n","Epoch: 77, Steps: 62 | Train Loss: 0.5255768 Vali Loss: 1.1890514 Test Loss: 0.4490470\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 2.4325451850891113\n","Epoch: 78, Steps: 62 | Train Loss: 0.5255552 Vali Loss: 1.1929280 Test Loss: 0.4490903\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 2.4423983097076416\n","Epoch: 79, Steps: 62 | Train Loss: 0.5253797 Vali Loss: 1.1926521 Test Loss: 0.4490874\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 2.456921339035034\n","Epoch: 80, Steps: 62 | Train Loss: 0.5256946 Vali Loss: 1.1897564 Test Loss: 0.4490826\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 2.3934926986694336\n","Epoch: 81, Steps: 62 | Train Loss: 0.5258044 Vali Loss: 1.1918863 Test Loss: 0.4491006\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 2.338343381881714\n","Epoch: 82, Steps: 62 | Train Loss: 0.5254641 Vali Loss: 1.1920575 Test Loss: 0.4490464\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 2.4936017990112305\n","Epoch: 83, Steps: 62 | Train Loss: 0.5256442 Vali Loss: 1.1920459 Test Loss: 0.4490593\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 2.382937431335449\n","Epoch: 84, Steps: 62 | Train Loss: 0.5256436 Vali Loss: 1.1973490 Test Loss: 0.4491156\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 2.420820474624634\n","Epoch: 85, Steps: 62 | Train Loss: 0.5257087 Vali Loss: 1.1941708 Test Loss: 0.4491449\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 2.5180416107177734\n","Epoch: 86, Steps: 62 | Train Loss: 0.5258092 Vali Loss: 1.1955026 Test Loss: 0.4490535\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 2.3294966220855713\n","Epoch: 87, Steps: 62 | Train Loss: 0.5252545 Vali Loss: 1.1981922 Test Loss: 0.4490011\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 2.356937885284424\n","Epoch: 88, Steps: 62 | Train Loss: 0.5260594 Vali Loss: 1.1876605 Test Loss: 0.4490801\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 2.4277942180633545\n","Epoch: 89, Steps: 62 | Train Loss: 0.5258101 Vali Loss: 1.1910696 Test Loss: 0.4490626\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 2.542083740234375\n","Epoch: 90, Steps: 62 | Train Loss: 0.5254827 Vali Loss: 1.1939462 Test Loss: 0.4490670\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 2.3640923500061035\n","Epoch: 91, Steps: 62 | Train Loss: 0.5255591 Vali Loss: 1.1945772 Test Loss: 0.4490667\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 2.3820271492004395\n","Epoch: 92, Steps: 62 | Train Loss: 0.5256800 Vali Loss: 1.1949682 Test Loss: 0.4490299\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 2.401815414428711\n","Epoch: 93, Steps: 62 | Train Loss: 0.5255689 Vali Loss: 1.1932515 Test Loss: 0.4490615\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 2.3347280025482178\n","Epoch: 94, Steps: 62 | Train Loss: 0.5253697 Vali Loss: 1.1950535 Test Loss: 0.4490505\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 2.37827205657959\n","Epoch: 95, Steps: 62 | Train Loss: 0.5257313 Vali Loss: 1.1949244 Test Loss: 0.4490329\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 2.508575201034546\n","Epoch: 96, Steps: 62 | Train Loss: 0.5252580 Vali Loss: 1.1911725 Test Loss: 0.4490714\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 2.406323194503784\n","Epoch: 97, Steps: 62 | Train Loss: 0.5255629 Vali Loss: 1.1903989 Test Loss: 0.4491255\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 2.345252752304077\n","Epoch: 98, Steps: 62 | Train Loss: 0.5255884 Vali Loss: 1.1890924 Test Loss: 0.4490508\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 2.4133834838867188\n","Epoch: 99, Steps: 62 | Train Loss: 0.5252173 Vali Loss: 1.1907417 Test Loss: 0.4491251\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 2.4419219493865967\n","Epoch: 100, Steps: 62 | Train Loss: 0.5255905 Vali Loss: 1.1936264 Test Loss: 0.4490667\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2545\n","mse:0.44905462861061096, mae:0.4516724944114685, rse:0.6405840516090393\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  720\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  1\n","Exp_Main init!\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 7585\n","val 2161\n","test 2161\n","Epoch: 1 cost time: 2.436152696609497\n","Epoch: 1, Steps: 59 | Train Loss: 0.8918176 Vali Loss: 1.9671168 Test Loss: 0.7739766\n","Validation loss decreased (inf --> 1.967117).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 2.5388355255126953\n","Epoch: 2, Steps: 59 | Train Loss: 0.7513243 Vali Loss: 1.5388899 Test Loss: 0.5099305\n","Validation loss decreased (1.967117 --> 1.538890).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 2.4402453899383545\n","Epoch: 3, Steps: 59 | Train Loss: 0.6701907 Vali Loss: 1.4760239 Test Loss: 0.4703296\n","Validation loss decreased (1.538890 --> 1.476024).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 2.3967831134796143\n","Epoch: 4, Steps: 59 | Train Loss: 0.6528726 Vali Loss: 1.4663404 Test Loss: 0.4625506\n","Validation loss decreased (1.476024 --> 1.466340).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 2.523033618927002\n","Epoch: 5, Steps: 59 | Train Loss: 0.6467347 Vali Loss: 1.4702351 Test Loss: 0.4595256\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 2.459021806716919\n","Epoch: 6, Steps: 59 | Train Loss: 0.6439460 Vali Loss: 1.4616756 Test Loss: 0.4580373\n","Validation loss decreased (1.466340 --> 1.461676).  Saving model ...\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 2.4518160820007324\n","Epoch: 7, Steps: 59 | Train Loss: 0.6424277 Vali Loss: 1.4637198 Test Loss: 0.4572904\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 2.4506170749664307\n","Epoch: 8, Steps: 59 | Train Loss: 0.6415895 Vali Loss: 1.4575500 Test Loss: 0.4569476\n","Validation loss decreased (1.461676 --> 1.457550).  Saving model ...\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 2.45208740234375\n","Epoch: 9, Steps: 59 | Train Loss: 0.6410007 Vali Loss: 1.4609618 Test Loss: 0.4567651\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 2.4259369373321533\n","Epoch: 10, Steps: 59 | Train Loss: 0.6407194 Vali Loss: 1.4641504 Test Loss: 0.4566791\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 2.45531964302063\n","Epoch: 11, Steps: 59 | Train Loss: 0.6409766 Vali Loss: 1.4620934 Test Loss: 0.4567078\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 2.5506744384765625\n","Epoch: 12, Steps: 59 | Train Loss: 0.6413712 Vali Loss: 1.4615340 Test Loss: 0.4565333\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 2.4285829067230225\n","Epoch: 13, Steps: 59 | Train Loss: 0.6411352 Vali Loss: 1.4604332 Test Loss: 0.4566112\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 2.3469583988189697\n","Epoch: 14, Steps: 59 | Train Loss: 0.6405171 Vali Loss: 1.4598991 Test Loss: 0.4565960\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 2.5365676879882812\n","Epoch: 15, Steps: 59 | Train Loss: 0.6406816 Vali Loss: 1.4640107 Test Loss: 0.4566277\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 2.4126040935516357\n","Epoch: 16, Steps: 59 | Train Loss: 0.6410056 Vali Loss: 1.4610072 Test Loss: 0.4565466\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 2.420416831970215\n","Epoch: 17, Steps: 59 | Train Loss: 0.6405458 Vali Loss: 1.4603643 Test Loss: 0.4566195\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 2.5199804306030273\n","Epoch: 18, Steps: 59 | Train Loss: 0.6408567 Vali Loss: 1.4608860 Test Loss: 0.4565776\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 2.419606924057007\n","Epoch: 19, Steps: 59 | Train Loss: 0.6404780 Vali Loss: 1.4601678 Test Loss: 0.4565738\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 2.4062795639038086\n","Epoch: 20, Steps: 59 | Train Loss: 0.6407125 Vali Loss: 1.4602685 Test Loss: 0.4565872\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 2.5247950553894043\n","Epoch: 21, Steps: 59 | Train Loss: 0.6407872 Vali Loss: 1.4516919 Test Loss: 0.4566143\n","Validation loss decreased (1.457550 --> 1.451692).  Saving model ...\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 2.522857666015625\n","Epoch: 22, Steps: 59 | Train Loss: 0.6410702 Vali Loss: 1.4603889 Test Loss: 0.4566116\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 2.412240505218506\n","Epoch: 23, Steps: 59 | Train Loss: 0.6411548 Vali Loss: 1.4601035 Test Loss: 0.4565955\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 2.3760955333709717\n","Epoch: 24, Steps: 59 | Train Loss: 0.6409689 Vali Loss: 1.4575574 Test Loss: 0.4566066\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 2.5412821769714355\n","Epoch: 25, Steps: 59 | Train Loss: 0.6407837 Vali Loss: 1.4623413 Test Loss: 0.4565725\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 2.380035400390625\n","Epoch: 26, Steps: 59 | Train Loss: 0.6410265 Vali Loss: 1.4600990 Test Loss: 0.4564961\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 2.435180425643921\n","Epoch: 27, Steps: 59 | Train Loss: 0.6408507 Vali Loss: 1.4630946 Test Loss: 0.4565699\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 2.5422024726867676\n","Epoch: 28, Steps: 59 | Train Loss: 0.6410458 Vali Loss: 1.4606626 Test Loss: 0.4565965\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 2.345052719116211\n","Epoch: 29, Steps: 59 | Train Loss: 0.6409446 Vali Loss: 1.4617771 Test Loss: 0.4565973\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 2.403996706008911\n","Epoch: 30, Steps: 59 | Train Loss: 0.6406653 Vali Loss: 1.4612637 Test Loss: 0.4565891\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 2.524179458618164\n","Epoch: 31, Steps: 59 | Train Loss: 0.6404743 Vali Loss: 1.4615371 Test Loss: 0.4565664\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 2.4774322509765625\n","Epoch: 32, Steps: 59 | Train Loss: 0.6412541 Vali Loss: 1.4617558 Test Loss: 0.4566311\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 2.4929986000061035\n","Epoch: 33, Steps: 59 | Train Loss: 0.6408907 Vali Loss: 1.4620390 Test Loss: 0.4565671\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 2.478317975997925\n","Epoch: 34, Steps: 59 | Train Loss: 0.6407557 Vali Loss: 1.4610643 Test Loss: 0.4565516\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 2.4612045288085938\n","Epoch: 35, Steps: 59 | Train Loss: 0.6410914 Vali Loss: 1.4650624 Test Loss: 0.4565682\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 2.316925048828125\n","Epoch: 36, Steps: 59 | Train Loss: 0.6407807 Vali Loss: 1.4610391 Test Loss: 0.4565907\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 2.3831183910369873\n","Epoch: 37, Steps: 59 | Train Loss: 0.6404254 Vali Loss: 1.4584119 Test Loss: 0.4565581\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 2.5671815872192383\n","Epoch: 38, Steps: 59 | Train Loss: 0.6409214 Vali Loss: 1.4614363 Test Loss: 0.4566165\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 2.4185614585876465\n","Epoch: 39, Steps: 59 | Train Loss: 0.6410848 Vali Loss: 1.4598801 Test Loss: 0.4566507\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 2.4717302322387695\n","Epoch: 40, Steps: 59 | Train Loss: 0.6412179 Vali Loss: 1.4579258 Test Loss: 0.4566251\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 2.4240033626556396\n","Epoch: 41, Steps: 59 | Train Loss: 0.6407746 Vali Loss: 1.4614780 Test Loss: 0.4566231\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 2.4383299350738525\n","Epoch: 42, Steps: 59 | Train Loss: 0.6410787 Vali Loss: 1.4580586 Test Loss: 0.4565736\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 2.435290813446045\n","Epoch: 43, Steps: 59 | Train Loss: 0.6409645 Vali Loss: 1.4586165 Test Loss: 0.4565000\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 2.768954038619995\n","Epoch: 44, Steps: 59 | Train Loss: 0.6405626 Vali Loss: 1.4590588 Test Loss: 0.4564734\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 2.511913537979126\n","Epoch: 45, Steps: 59 | Train Loss: 0.6411302 Vali Loss: 1.4598830 Test Loss: 0.4565828\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 2.4230661392211914\n","Epoch: 46, Steps: 59 | Train Loss: 0.6407932 Vali Loss: 1.4581308 Test Loss: 0.4565847\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 2.375098705291748\n","Epoch: 47, Steps: 59 | Train Loss: 0.6405644 Vali Loss: 1.4611502 Test Loss: 0.4566008\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 2.5655713081359863\n","Epoch: 48, Steps: 59 | Train Loss: 0.6408865 Vali Loss: 1.4577649 Test Loss: 0.4565610\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 2.4523587226867676\n","Epoch: 49, Steps: 59 | Train Loss: 0.6407293 Vali Loss: 1.4627197 Test Loss: 0.4566098\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 2.4238734245300293\n","Epoch: 50, Steps: 59 | Train Loss: 0.6409215 Vali Loss: 1.4658790 Test Loss: 0.4565871\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 2.501154899597168\n","Epoch: 51, Steps: 59 | Train Loss: 0.6403928 Vali Loss: 1.4536095 Test Loss: 0.4565662\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 2.466204881668091\n","Epoch: 52, Steps: 59 | Train Loss: 0.6408836 Vali Loss: 1.4551303 Test Loss: 0.4566525\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 2.400052547454834\n","Epoch: 53, Steps: 59 | Train Loss: 0.6402093 Vali Loss: 1.4567986 Test Loss: 0.4565621\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 2.5821874141693115\n","Epoch: 54, Steps: 59 | Train Loss: 0.6410156 Vali Loss: 1.4554014 Test Loss: 0.4565719\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 2.5595178604125977\n","Epoch: 55, Steps: 59 | Train Loss: 0.6410397 Vali Loss: 1.4641712 Test Loss: 0.4565162\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 2.3765084743499756\n","Epoch: 56, Steps: 59 | Train Loss: 0.6404436 Vali Loss: 1.4618242 Test Loss: 0.4565412\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 2.4789860248565674\n","Epoch: 57, Steps: 59 | Train Loss: 0.6407600 Vali Loss: 1.4645095 Test Loss: 0.4565385\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 2.5386745929718018\n","Epoch: 58, Steps: 59 | Train Loss: 0.6408384 Vali Loss: 1.4583473 Test Loss: 0.4565852\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 2.3458991050720215\n","Epoch: 59, Steps: 59 | Train Loss: 0.6409058 Vali Loss: 1.4640592 Test Loss: 0.4566163\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 2.4646718502044678\n","Epoch: 60, Steps: 59 | Train Loss: 0.6409877 Vali Loss: 1.4581556 Test Loss: 0.4565509\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 2.5834245681762695\n","Epoch: 61, Steps: 59 | Train Loss: 0.6409679 Vali Loss: 1.4618363 Test Loss: 0.4565611\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 2.3384127616882324\n","Epoch: 62, Steps: 59 | Train Loss: 0.6406407 Vali Loss: 1.4604620 Test Loss: 0.4565761\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 2.3439087867736816\n","Epoch: 63, Steps: 59 | Train Loss: 0.6410287 Vali Loss: 1.4626492 Test Loss: 0.4565728\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 2.673349618911743\n","Epoch: 64, Steps: 59 | Train Loss: 0.6408252 Vali Loss: 1.4591734 Test Loss: 0.4565091\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 2.4240307807922363\n","Epoch: 65, Steps: 59 | Train Loss: 0.6407568 Vali Loss: 1.4647609 Test Loss: 0.4566071\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 2.483423948287964\n","Epoch: 66, Steps: 59 | Train Loss: 0.6410270 Vali Loss: 1.4577757 Test Loss: 0.4565510\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 2.4638495445251465\n","Epoch: 67, Steps: 59 | Train Loss: 0.6402833 Vali Loss: 1.4606168 Test Loss: 0.4566291\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 2.4011783599853516\n","Epoch: 68, Steps: 59 | Train Loss: 0.6408656 Vali Loss: 1.4625015 Test Loss: 0.4565400\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 2.397132396697998\n","Epoch: 69, Steps: 59 | Train Loss: 0.6405392 Vali Loss: 1.4623220 Test Loss: 0.4565863\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 2.486259937286377\n","Epoch: 70, Steps: 59 | Train Loss: 0.6405011 Vali Loss: 1.4563646 Test Loss: 0.4566309\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 2.5626704692840576\n","Epoch: 71, Steps: 59 | Train Loss: 0.6407750 Vali Loss: 1.4669402 Test Loss: 0.4566098\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 2.3998501300811768\n","Epoch: 72, Steps: 59 | Train Loss: 0.6408116 Vali Loss: 1.4564381 Test Loss: 0.4565960\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 2.4392199516296387\n","Epoch: 73, Steps: 59 | Train Loss: 0.6410500 Vali Loss: 1.4600332 Test Loss: 0.4566100\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 2.5783989429473877\n","Epoch: 74, Steps: 59 | Train Loss: 0.6410226 Vali Loss: 1.4541466 Test Loss: 0.4565116\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 2.436157703399658\n","Epoch: 75, Steps: 59 | Train Loss: 0.6408217 Vali Loss: 1.4640374 Test Loss: 0.4565775\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 2.4716029167175293\n","Epoch: 76, Steps: 59 | Train Loss: 0.6407905 Vali Loss: 1.4588426 Test Loss: 0.4565599\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 2.569258689880371\n","Epoch: 77, Steps: 59 | Train Loss: 0.6409809 Vali Loss: 1.4623473 Test Loss: 0.4566230\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 2.3566462993621826\n","Epoch: 78, Steps: 59 | Train Loss: 0.6407686 Vali Loss: 1.4629779 Test Loss: 0.4566273\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 2.4103543758392334\n","Epoch: 79, Steps: 59 | Train Loss: 0.6407651 Vali Loss: 1.4623519 Test Loss: 0.4565954\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 2.4674923419952393\n","Epoch: 80, Steps: 59 | Train Loss: 0.6409834 Vali Loss: 1.4553212 Test Loss: 0.4566371\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 2.5295281410217285\n","Epoch: 81, Steps: 59 | Train Loss: 0.6410250 Vali Loss: 1.4593520 Test Loss: 0.4565569\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 2.4363300800323486\n","Epoch: 82, Steps: 59 | Train Loss: 0.6407771 Vali Loss: 1.4601958 Test Loss: 0.4565948\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 2.41601300239563\n","Epoch: 83, Steps: 59 | Train Loss: 0.6410778 Vali Loss: 1.4599912 Test Loss: 0.4565879\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 2.4476492404937744\n","Epoch: 84, Steps: 59 | Train Loss: 0.6404441 Vali Loss: 1.4598114 Test Loss: 0.4565865\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 2.4272918701171875\n","Epoch: 85, Steps: 59 | Train Loss: 0.6411249 Vali Loss: 1.4622606 Test Loss: 0.4566177\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 2.446611166000366\n","Epoch: 86, Steps: 59 | Train Loss: 0.6410387 Vali Loss: 1.4578843 Test Loss: 0.4566316\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 2.587736129760742\n","Epoch: 87, Steps: 59 | Train Loss: 0.6410032 Vali Loss: 1.4637179 Test Loss: 0.4565813\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 2.443189859390259\n","Epoch: 88, Steps: 59 | Train Loss: 0.6408747 Vali Loss: 1.4676176 Test Loss: 0.4566196\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 2.3554699420928955\n","Epoch: 89, Steps: 59 | Train Loss: 0.6410033 Vali Loss: 1.4587026 Test Loss: 0.4565561\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 2.5537707805633545\n","Epoch: 90, Steps: 59 | Train Loss: 0.6410772 Vali Loss: 1.4620087 Test Loss: 0.4565499\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 2.429166793823242\n","Epoch: 91, Steps: 59 | Train Loss: 0.6404994 Vali Loss: 1.4556302 Test Loss: 0.4566680\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 2.4536030292510986\n","Epoch: 92, Steps: 59 | Train Loss: 0.6408966 Vali Loss: 1.4598323 Test Loss: 0.4565104\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 2.5339088439941406\n","Epoch: 93, Steps: 59 | Train Loss: 0.6408954 Vali Loss: 1.4597770 Test Loss: 0.4565496\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 2.534773111343384\n","Epoch: 94, Steps: 59 | Train Loss: 0.6407786 Vali Loss: 1.4632642 Test Loss: 0.4565792\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 2.3835926055908203\n","Epoch: 95, Steps: 59 | Train Loss: 0.6406554 Vali Loss: 1.4598240 Test Loss: 0.4565734\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 2.501893997192383\n","Epoch: 96, Steps: 59 | Train Loss: 0.6407672 Vali Loss: 1.4606389 Test Loss: 0.4565767\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 2.6051690578460693\n","Epoch: 97, Steps: 59 | Train Loss: 0.6406375 Vali Loss: 1.4642816 Test Loss: 0.4565339\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 2.496306896209717\n","Epoch: 98, Steps: 59 | Train Loss: 0.6413645 Vali Loss: 1.4628241 Test Loss: 0.4566071\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 2.457735300064087\n","Epoch: 99, Steps: 59 | Train Loss: 0.6412480 Vali Loss: 1.4608946 Test Loss: 0.4565223\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 2.5578396320343018\n","Epoch: 100, Steps: 59 | Train Loss: 0.6407120 Vali Loss: 1.4567027 Test Loss: 0.4565815\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2161\n","mse:0.45661476254463196, mae:0.4724871814250946, rse:0.6490229368209839\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n"]}],"source":["arg_pred_len_list = [96, 192, 336, 720]\n","\n","for arg_pred_len in arg_pred_len_list:\n","  # prediction len 설정\n","\n","  args.pred_len = arg_pred_len\n","  Exp = Exp_Main\n","  print(\"Current Prediction Length : \", str(arg_pred_len))\n","  print(\"\\n\\n\\n\")\n","\n","  if args.is_training:\n","      for ii in range(args.itr):\n","          # setting record of experiments\n","          setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n","              args.model_id,\n","              args.model,\n","              args.data,\n","              args.features,\n","              args.seq_len,\n","              args.label_len,\n","              args.pred_len,\n","              args.d_model,\n","              args.n_heads,\n","              args.e_layers,\n","              args.d_layers,\n","              args.d_ff,\n","              args.factor,\n","              args.embed,\n","              args.distil,\n","              args.des,ii)\n","\n","          exp = Exp(args)  # set experiments\n","\n","          print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","          exp.train(setting)\n","\n","          print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","          exp.test(setting)\n","\n","          if args.do_predict:\n","              print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","              exp.predict(setting, True)\n","\n","          torch.cuda.empty_cache()\n","\n","          print(\"\\n\\n\\n\\n\\n\")\n","\n","  # 실험에서 사용되지 않는 경우.\n","  else:\n","      ii = 0\n","      setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n","                                                                                                  args.model,\n","                                                                                                  args.data,\n","                                                                                                  args.features,\n","                                                                                                  args.seq_len,\n","                                                                                                  args.label_len,\n","                                                                                                  args.pred_len,\n","                                                                                                  args.d_model,\n","                                                                                                  args.n_heads,\n","                                                                                                  args.e_layers,\n","                                                                                                  args.d_layers,\n","                                                                                                  args.d_ff,\n","                                                                                                  args.factor,\n","                                                                                                  args.embed,\n","                                                                                                  args.distil,\n","                                                                                                  args.des, ii)\n","\n","      exp = Exp(args)  # set experiments\n","      print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","      exp.test(setting, test=1)\n","      torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{},"source":["### ILI 데이터셋 실험"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1701022421753,"user":{"displayName":"공자","userId":"09701607017816361852"},"user_tz":-540},"id":"1a4-IiiKewKL","outputId":"019d195d-d62b-4032-e35f-3f120a496fde"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","<__main__.Args object at 0x7dc84006eaa0>\n"]}],"source":["arg_seq_len=104\n","\n","model_name='PatchTST'\n","\n","root_path_name='./dataset/'\n","data_path_name='national_illness.csv'\n","model_id_name='national_illness'\n","data_name='custom'\n","\n","random_seed=2021\n","\n","class Args:\n","    random_seed = 2021\n","\n","    is_training = 1\n","    model_id = model_id_name\n","    model = model_name\n","\n","    data = data_name\n","    root_path = root_path_name\n","    data_path = data_path_name\n","    features = 'M'\n","    target = 'OT'\n","    freq = 'h'\n","    checkpoints = './checkpoints/'\n","\n","    seq_len = arg_seq_len\n","    fc_dropout= 0.3\n","    head_dropout = 0.0\n","    patch_len = 24\n","    stride = 2\n","    decomposition = 1\n","    enc_in = 7\n","    d_model = 16\n","    n_heads = 4\n","    e_layers = 3\n","    d_ff = 128\n","    dropout = 0.3\n","    itr = 1 # 학습 횟수\n","    train_epochs = 100\n","    batch_size = 16\n","    learning_rate = 0.0025\n","    des = 'Exp'\n","    use_gpu = True\n","    gpu = 0\n","    use_multi_gpu = False\n","    devices = '0'\n","    label_len = 48\n","    d_layers = 1\n","    factor = 1\n","    distil = True\n","    embed = 'timeF'\n","    individual = 0\n","    padding_patch = 'end'\n","    revin = 1\n","    affine = 0\n","    subtract_last = 0\n","    kernel_size = 25\n","    embed_type = 0\n","    dec_in = 7\n","    c_out = 7\n","    moving_avg = 25\n","    activation = 'gelu'\n","    output_attention = False\n","    do_predict = True\n","    patience = 100\n","    num_workers = 10 # DataLoader에 사용할 subprocess 개수\n","    loss = 'MSE'\n","    lradj = 'type1'\n","    pct_start = 0.3\n","    use_amp = False\n","    test_flop = False\n","\n","args = Args();\n","\n","# random seed\n","fix_seed = args.random_seed\n","random.seed(fix_seed)\n","torch.manual_seed(fix_seed)\n","np.random.seed(fix_seed)\n","\n","args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.dvices = args.devices.replace(' ', '')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1093504,"status":"ok","timestamp":1701023515253,"user":{"displayName":"공자","userId":"09701607017816361852"},"user_tz":-540},"id":"QqyBn83xfZuM","outputId":"e57fa76c-0138-44e7-c93f-c1ac66c63c89"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current Prediction Length :  24\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  1\n","Exp_Main init!\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl24_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 549\n","val 74\n","test 170\n","Epoch: 1 cost time: 1.3578271865844727\n","Epoch: 1, Steps: 34 | Train Loss: 0.8419029 Vali Loss: 0.3564295 Test Loss: 2.5420666\n","Validation loss decreased (inf --> 0.356429).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 1.429696798324585\n","Epoch: 2, Steps: 34 | Train Loss: 0.7607539 Vali Loss: 0.4714639 Test Loss: 1.9161060\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.00125\n","Epoch: 3 cost time: 1.3903183937072754\n","Epoch: 3, Steps: 34 | Train Loss: 0.5118038 Vali Loss: 0.2834300 Test Loss: 1.4217727\n","Validation loss decreased (0.356429 --> 0.283430).  Saving model ...\n","Updating learning rate to 0.000625\n","Epoch: 4 cost time: 1.3789291381835938\n","Epoch: 4, Steps: 34 | Train Loss: 0.4356324 Vali Loss: 0.2647816 Test Loss: 1.6011801\n","Validation loss decreased (0.283430 --> 0.264782).  Saving model ...\n","Updating learning rate to 0.0003125\n","Epoch: 5 cost time: 1.3048155307769775\n","Epoch: 5, Steps: 34 | Train Loss: 0.4086041 Vali Loss: 0.2717496 Test Loss: 1.5926800\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.00015625\n","Epoch: 6 cost time: 1.3816463947296143\n","Epoch: 6, Steps: 34 | Train Loss: 0.3925980 Vali Loss: 0.2484881 Test Loss: 1.5198023\n","Validation loss decreased (0.264782 --> 0.248488).  Saving model ...\n","Updating learning rate to 7.8125e-05\n","Epoch: 7 cost time: 1.3576140403747559\n","Epoch: 7, Steps: 34 | Train Loss: 0.3802075 Vali Loss: 0.2508625 Test Loss: 1.4908186\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.90625e-05\n","Epoch: 8 cost time: 1.3709020614624023\n","Epoch: 8, Steps: 34 | Train Loss: 0.3752735 Vali Loss: 0.2522415 Test Loss: 1.4905260\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.953125e-05\n","Epoch: 9 cost time: 1.3984081745147705\n","Epoch: 9, Steps: 34 | Train Loss: 0.3828439 Vali Loss: 0.2659528 Test Loss: 1.4969454\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 9.765625e-06\n","Epoch: 10 cost time: 1.3015809059143066\n","Epoch: 10, Steps: 34 | Train Loss: 0.3804019 Vali Loss: 0.2657945 Test Loss: 1.4837911\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 4.8828125e-06\n","Epoch: 11 cost time: 1.3386287689208984\n","Epoch: 11, Steps: 34 | Train Loss: 0.3815706 Vali Loss: 0.2590312 Test Loss: 1.4739314\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.44140625e-06\n","Epoch: 12 cost time: 1.3742363452911377\n","Epoch: 12, Steps: 34 | Train Loss: 0.3850227 Vali Loss: 0.2541376 Test Loss: 1.4859749\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.220703125e-06\n","Epoch: 13 cost time: 1.3423233032226562\n","Epoch: 13, Steps: 34 | Train Loss: 0.3803936 Vali Loss: 0.2643797 Test Loss: 1.4976047\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 6.103515625e-07\n","Epoch: 14 cost time: 1.403475284576416\n","Epoch: 14, Steps: 34 | Train Loss: 0.3727996 Vali Loss: 0.2664372 Test Loss: 1.4783921\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.0517578125e-07\n","Epoch: 15 cost time: 1.393606185913086\n","Epoch: 15, Steps: 34 | Train Loss: 0.3844187 Vali Loss: 0.2508142 Test Loss: 1.4810154\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.52587890625e-07\n","Epoch: 16 cost time: 1.3450641632080078\n","Epoch: 16, Steps: 34 | Train Loss: 0.3811924 Vali Loss: 0.2484968 Test Loss: 1.4738525\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 7.62939453125e-08\n","Epoch: 17 cost time: 1.3339967727661133\n","Epoch: 17, Steps: 34 | Train Loss: 0.3842748 Vali Loss: 0.2604430 Test Loss: 1.4736801\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 3.814697265625e-08\n","Epoch: 18 cost time: 1.3324627876281738\n","Epoch: 18, Steps: 34 | Train Loss: 0.3839048 Vali Loss: 0.2508883 Test Loss: 1.4814256\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.9073486328125e-08\n","Epoch: 19 cost time: 1.3917787075042725\n","Epoch: 19, Steps: 34 | Train Loss: 0.3835012 Vali Loss: 0.2674669 Test Loss: 1.4910114\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 9.5367431640625e-09\n","Epoch: 20 cost time: 1.415419101715088\n","Epoch: 20, Steps: 34 | Train Loss: 0.3879753 Vali Loss: 0.2418604 Test Loss: 1.4769380\n","Validation loss decreased (0.248488 --> 0.241860).  Saving model ...\n","Updating learning rate to 4.76837158203125e-09\n","Epoch: 21 cost time: 1.3168773651123047\n","Epoch: 21, Steps: 34 | Train Loss: 0.3844615 Vali Loss: 0.2484221 Test Loss: 1.4932542\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 2.384185791015625e-09\n","Epoch: 22 cost time: 1.3738327026367188\n","Epoch: 22, Steps: 34 | Train Loss: 0.3803405 Vali Loss: 0.2660100 Test Loss: 1.4843292\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.1920928955078125e-09\n","Epoch: 23 cost time: 1.3462882041931152\n","Epoch: 23, Steps: 34 | Train Loss: 0.3843959 Vali Loss: 0.2591448 Test Loss: 1.4860892\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 5.960464477539063e-10\n","Epoch: 24 cost time: 1.296809434890747\n","Epoch: 24, Steps: 34 | Train Loss: 0.3834123 Vali Loss: 0.2650565 Test Loss: 1.4870663\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 2.9802322387695313e-10\n","Epoch: 25 cost time: 1.3824269771575928\n","Epoch: 25, Steps: 34 | Train Loss: 0.3831141 Vali Loss: 0.2646483 Test Loss: 1.4653947\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.4901161193847657e-10\n","Epoch: 26 cost time: 1.3862299919128418\n","Epoch: 26, Steps: 34 | Train Loss: 0.3846023 Vali Loss: 0.2514800 Test Loss: 1.4862771\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 7.450580596923828e-11\n","Epoch: 27 cost time: 1.352430820465088\n","Epoch: 27, Steps: 34 | Train Loss: 0.3778489 Vali Loss: 0.2575056 Test Loss: 1.4801133\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 3.725290298461914e-11\n","Epoch: 28 cost time: 1.3703150749206543\n","Epoch: 28, Steps: 34 | Train Loss: 0.3807870 Vali Loss: 0.2591448 Test Loss: 1.4824455\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.862645149230957e-11\n","Epoch: 29 cost time: 1.3466641902923584\n","Epoch: 29, Steps: 34 | Train Loss: 0.3791855 Vali Loss: 0.2593377 Test Loss: 1.4801896\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 9.313225746154785e-12\n","Epoch: 30 cost time: 1.3260102272033691\n","Epoch: 30, Steps: 34 | Train Loss: 0.3783498 Vali Loss: 0.2526457 Test Loss: 1.4770858\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 4.656612873077393e-12\n","Epoch: 31 cost time: 1.4094252586364746\n","Epoch: 31, Steps: 34 | Train Loss: 0.3833147 Vali Loss: 0.2711839 Test Loss: 1.4830004\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 2.3283064365386963e-12\n","Epoch: 32 cost time: 1.3673202991485596\n","Epoch: 32, Steps: 34 | Train Loss: 0.3795855 Vali Loss: 0.2691181 Test Loss: 1.4750421\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.1641532182693482e-12\n","Epoch: 33 cost time: 1.3559868335723877\n","Epoch: 33, Steps: 34 | Train Loss: 0.3825210 Vali Loss: 0.2513202 Test Loss: 1.4693981\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 5.820766091346741e-13\n","Epoch: 34 cost time: 1.3129899501800537\n","Epoch: 34, Steps: 34 | Train Loss: 0.3768224 Vali Loss: 0.2736047 Test Loss: 1.4820741\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 2.9103830456733704e-13\n","Epoch: 35 cost time: 1.2940242290496826\n","Epoch: 35, Steps: 34 | Train Loss: 0.3867587 Vali Loss: 0.2644772 Test Loss: 1.4771115\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 1.4551915228366852e-13\n","Epoch: 36 cost time: 1.3566367626190186\n","Epoch: 36, Steps: 34 | Train Loss: 0.3838700 Vali Loss: 0.2555332 Test Loss: 1.4902759\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 7.275957614183426e-14\n","Epoch: 37 cost time: 1.3983733654022217\n","Epoch: 37, Steps: 34 | Train Loss: 0.3849586 Vali Loss: 0.2624314 Test Loss: 1.4697120\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 3.637978807091713e-14\n","Epoch: 38 cost time: 1.3538415431976318\n","Epoch: 38, Steps: 34 | Train Loss: 0.3827440 Vali Loss: 0.2590491 Test Loss: 1.4836044\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 1.8189894035458565e-14\n","Epoch: 39 cost time: 1.317288875579834\n","Epoch: 39, Steps: 34 | Train Loss: 0.3828843 Vali Loss: 0.2737945 Test Loss: 1.4685529\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 9.094947017729283e-15\n","Epoch: 40 cost time: 1.3363234996795654\n","Epoch: 40, Steps: 34 | Train Loss: 0.3789469 Vali Loss: 0.2736310 Test Loss: 1.4917010\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 4.547473508864641e-15\n","Epoch: 41 cost time: 1.3327786922454834\n","Epoch: 41, Steps: 34 | Train Loss: 0.3807064 Vali Loss: 0.2674914 Test Loss: 1.4832525\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 2.2737367544323206e-15\n","Epoch: 42 cost time: 1.3687958717346191\n","Epoch: 42, Steps: 34 | Train Loss: 0.3847535 Vali Loss: 0.2605419 Test Loss: 1.4885346\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 1.1368683772161603e-15\n","Epoch: 43 cost time: 1.3597874641418457\n","Epoch: 43, Steps: 34 | Train Loss: 0.3805997 Vali Loss: 0.2663354 Test Loss: 1.4812336\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 5.684341886080802e-16\n","Epoch: 44 cost time: 1.2958319187164307\n","Epoch: 44, Steps: 34 | Train Loss: 0.3791780 Vali Loss: 0.2797233 Test Loss: 1.4955559\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 2.842170943040401e-16\n","Epoch: 45 cost time: 1.2927687168121338\n","Epoch: 45, Steps: 34 | Train Loss: 0.3898962 Vali Loss: 0.2638605 Test Loss: 1.4730299\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 1.4210854715202004e-16\n","Epoch: 46 cost time: 1.316077470779419\n","Epoch: 46, Steps: 34 | Train Loss: 0.3837702 Vali Loss: 0.2626165 Test Loss: 1.4765103\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 7.105427357601002e-17\n","Epoch: 47 cost time: 1.3842110633850098\n","Epoch: 47, Steps: 34 | Train Loss: 0.3739514 Vali Loss: 0.2451114 Test Loss: 1.4856718\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 3.552713678800501e-17\n","Epoch: 48 cost time: 1.454089879989624\n","Epoch: 48, Steps: 34 | Train Loss: 0.3797964 Vali Loss: 0.2778320 Test Loss: 1.4906443\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 1.7763568394002505e-17\n","Epoch: 49 cost time: 1.314133882522583\n","Epoch: 49, Steps: 34 | Train Loss: 0.3725758 Vali Loss: 0.2728113 Test Loss: 1.4829545\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 8.881784197001253e-18\n","Epoch: 50 cost time: 1.3064415454864502\n","Epoch: 50, Steps: 34 | Train Loss: 0.3857952 Vali Loss: 0.2633378 Test Loss: 1.4869072\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 4.440892098500626e-18\n","Epoch: 51 cost time: 1.256162405014038\n","Epoch: 51, Steps: 34 | Train Loss: 0.3811486 Vali Loss: 0.2646604 Test Loss: 1.4840640\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 2.220446049250313e-18\n","Epoch: 52 cost time: 1.3327760696411133\n","Epoch: 52, Steps: 34 | Train Loss: 0.3874428 Vali Loss: 0.2546760 Test Loss: 1.4849812\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 1.1102230246251566e-18\n","Epoch: 53 cost time: 1.4558145999908447\n","Epoch: 53, Steps: 34 | Train Loss: 0.3717549 Vali Loss: 0.2607029 Test Loss: 1.4886377\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 5.551115123125783e-19\n","Epoch: 54 cost time: 1.40366792678833\n","Epoch: 54, Steps: 34 | Train Loss: 0.3798105 Vali Loss: 0.2567962 Test Loss: 1.4833124\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 2.7755575615628914e-19\n","Epoch: 55 cost time: 1.2960360050201416\n","Epoch: 55, Steps: 34 | Train Loss: 0.3814235 Vali Loss: 0.2655413 Test Loss: 1.4714868\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 1.3877787807814457e-19\n","Epoch: 56 cost time: 1.3713812828063965\n","Epoch: 56, Steps: 34 | Train Loss: 0.3844035 Vali Loss: 0.2549963 Test Loss: 1.4903424\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 6.938893903907229e-20\n","Epoch: 57 cost time: 1.3752622604370117\n","Epoch: 57, Steps: 34 | Train Loss: 0.3858541 Vali Loss: 0.2602565 Test Loss: 1.4680607\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 3.469446951953614e-20\n","Epoch: 58 cost time: 1.3862354755401611\n","Epoch: 58, Steps: 34 | Train Loss: 0.3826867 Vali Loss: 0.2561695 Test Loss: 1.4868033\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 1.734723475976807e-20\n","Epoch: 59 cost time: 1.403552532196045\n","Epoch: 59, Steps: 34 | Train Loss: 0.3828645 Vali Loss: 0.2663637 Test Loss: 1.4843255\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 8.673617379884036e-21\n","Epoch: 60 cost time: 1.3571538925170898\n","Epoch: 60, Steps: 34 | Train Loss: 0.3829261 Vali Loss: 0.2793041 Test Loss: 1.4881377\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 4.336808689942018e-21\n","Epoch: 61 cost time: 1.3088982105255127\n","Epoch: 61, Steps: 34 | Train Loss: 0.3811559 Vali Loss: 0.2776607 Test Loss: 1.4625318\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 2.168404344971009e-21\n","Epoch: 62 cost time: 1.3185734748840332\n","Epoch: 62, Steps: 34 | Train Loss: 0.3857394 Vali Loss: 0.2593775 Test Loss: 1.4871601\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 1.0842021724855045e-21\n","Epoch: 63 cost time: 1.3824994564056396\n","Epoch: 63, Steps: 34 | Train Loss: 0.3792862 Vali Loss: 0.2579942 Test Loss: 1.4859642\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 5.421010862427522e-22\n","Epoch: 64 cost time: 1.3738665580749512\n","Epoch: 64, Steps: 34 | Train Loss: 0.3800874 Vali Loss: 0.2577621 Test Loss: 1.4914627\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 2.710505431213761e-22\n","Epoch: 65 cost time: 1.402496576309204\n","Epoch: 65, Steps: 34 | Train Loss: 0.3815619 Vali Loss: 0.2641903 Test Loss: 1.4803828\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 1.3552527156068806e-22\n","Epoch: 66 cost time: 1.348639726638794\n","Epoch: 66, Steps: 34 | Train Loss: 0.3837308 Vali Loss: 0.2572064 Test Loss: 1.4870201\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 6.776263578034403e-23\n","Epoch: 67 cost time: 1.3672630786895752\n","Epoch: 67, Steps: 34 | Train Loss: 0.3860621 Vali Loss: 0.2716544 Test Loss: 1.4868958\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 3.3881317890172014e-23\n","Epoch: 68 cost time: 1.3989405632019043\n","Epoch: 68, Steps: 34 | Train Loss: 0.3795006 Vali Loss: 0.2677129 Test Loss: 1.5020916\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 1.6940658945086007e-23\n","Epoch: 69 cost time: 1.313948631286621\n","Epoch: 69, Steps: 34 | Train Loss: 0.3837384 Vali Loss: 0.2606437 Test Loss: 1.4794285\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 8.470329472543004e-24\n","Epoch: 70 cost time: 1.342069149017334\n","Epoch: 70, Steps: 34 | Train Loss: 0.3785287 Vali Loss: 0.2416606 Test Loss: 1.4966453\n","Validation loss decreased (0.241860 --> 0.241661).  Saving model ...\n","Updating learning rate to 4.235164736271502e-24\n","Epoch: 71 cost time: 1.3721213340759277\n","Epoch: 71, Steps: 34 | Train Loss: 0.3805099 Vali Loss: 0.2531679 Test Loss: 1.4824927\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 2.117582368135751e-24\n","Epoch: 72 cost time: 1.3331077098846436\n","Epoch: 72, Steps: 34 | Train Loss: 0.3728086 Vali Loss: 0.2635293 Test Loss: 1.4803646\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.0587911840678754e-24\n","Epoch: 73 cost time: 1.3329200744628906\n","Epoch: 73, Steps: 34 | Train Loss: 0.3833481 Vali Loss: 0.2723027 Test Loss: 1.4898570\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 5.293955920339377e-25\n","Epoch: 74 cost time: 1.3824734687805176\n","Epoch: 74, Steps: 34 | Train Loss: 0.3840885 Vali Loss: 0.2697783 Test Loss: 1.4813282\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 2.6469779601696886e-25\n","Epoch: 75 cost time: 1.3838858604431152\n","Epoch: 75, Steps: 34 | Train Loss: 0.3836191 Vali Loss: 0.2635570 Test Loss: 1.4769437\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.3234889800848443e-25\n","Epoch: 76 cost time: 1.4989616870880127\n","Epoch: 76, Steps: 34 | Train Loss: 0.3734706 Vali Loss: 0.2753320 Test Loss: 1.4686352\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 6.617444900424222e-26\n","Epoch: 77 cost time: 1.3594532012939453\n","Epoch: 77, Steps: 34 | Train Loss: 0.3825612 Vali Loss: 0.2672613 Test Loss: 1.4951365\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 3.308722450212111e-26\n","Epoch: 78 cost time: 1.3301010131835938\n","Epoch: 78, Steps: 34 | Train Loss: 0.3822785 Vali Loss: 0.2608405 Test Loss: 1.4862967\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.6543612251060554e-26\n","Epoch: 79 cost time: 1.3377165794372559\n","Epoch: 79, Steps: 34 | Train Loss: 0.3865261 Vali Loss: 0.2735296 Test Loss: 1.4828960\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 8.271806125530277e-27\n","Epoch: 80 cost time: 1.3470087051391602\n","Epoch: 80, Steps: 34 | Train Loss: 0.3824954 Vali Loss: 0.2567154 Test Loss: 1.5028096\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 4.1359030627651385e-27\n","Epoch: 81 cost time: 1.361994981765747\n","Epoch: 81, Steps: 34 | Train Loss: 0.3833338 Vali Loss: 0.2672240 Test Loss: 1.4764729\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 2.0679515313825692e-27\n","Epoch: 82 cost time: 1.4406416416168213\n","Epoch: 82, Steps: 34 | Train Loss: 0.3796316 Vali Loss: 0.2566227 Test Loss: 1.4831264\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.0339757656912846e-27\n","Epoch: 83 cost time: 1.3646926879882812\n","Epoch: 83, Steps: 34 | Train Loss: 0.3812513 Vali Loss: 0.2630272 Test Loss: 1.4851034\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 5.169878828456423e-28\n","Epoch: 84 cost time: 1.3626208305358887\n","Epoch: 84, Steps: 34 | Train Loss: 0.3842376 Vali Loss: 0.2495548 Test Loss: 1.4957260\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 2.5849394142282115e-28\n","Epoch: 85 cost time: 1.3332030773162842\n","Epoch: 85, Steps: 34 | Train Loss: 0.3819806 Vali Loss: 0.2691386 Test Loss: 1.4838405\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 1.2924697071141058e-28\n","Epoch: 86 cost time: 1.364103078842163\n","Epoch: 86, Steps: 34 | Train Loss: 0.3829330 Vali Loss: 0.2574517 Test Loss: 1.4796289\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 6.462348535570529e-29\n","Epoch: 87 cost time: 1.381669044494629\n","Epoch: 87, Steps: 34 | Train Loss: 0.3834909 Vali Loss: 0.2513922 Test Loss: 1.4889201\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 3.2311742677852644e-29\n","Epoch: 88 cost time: 1.3229434490203857\n","Epoch: 88, Steps: 34 | Train Loss: 0.3850429 Vali Loss: 0.2519464 Test Loss: 1.4923277\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 1.6155871338926322e-29\n","Epoch: 89 cost time: 1.3579397201538086\n","Epoch: 89, Steps: 34 | Train Loss: 0.3867498 Vali Loss: 0.2588915 Test Loss: 1.4883986\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 8.077935669463161e-30\n","Epoch: 90 cost time: 1.3111672401428223\n","Epoch: 90, Steps: 34 | Train Loss: 0.3866678 Vali Loss: 0.2524827 Test Loss: 1.4770793\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 4.0389678347315805e-30\n","Epoch: 91 cost time: 1.3363990783691406\n","Epoch: 91, Steps: 34 | Train Loss: 0.3806330 Vali Loss: 0.2664959 Test Loss: 1.5020704\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 2.0194839173657903e-30\n","Epoch: 92 cost time: 1.420119285583496\n","Epoch: 92, Steps: 34 | Train Loss: 0.3827722 Vali Loss: 0.2597539 Test Loss: 1.4815123\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 1.0097419586828951e-30\n","Epoch: 93 cost time: 1.4087445735931396\n","Epoch: 93, Steps: 34 | Train Loss: 0.3845760 Vali Loss: 0.2756181 Test Loss: 1.5047284\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 5.048709793414476e-31\n","Epoch: 94 cost time: 1.361649990081787\n","Epoch: 94, Steps: 34 | Train Loss: 0.3812207 Vali Loss: 0.2624736 Test Loss: 1.4927883\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 2.524354896707238e-31\n","Epoch: 95 cost time: 1.3463773727416992\n","Epoch: 95, Steps: 34 | Train Loss: 0.3820879 Vali Loss: 0.2655307 Test Loss: 1.4930868\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 1.262177448353619e-31\n","Epoch: 96 cost time: 1.2961246967315674\n","Epoch: 96, Steps: 34 | Train Loss: 0.3818215 Vali Loss: 0.2671095 Test Loss: 1.4743387\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 6.310887241768095e-32\n","Epoch: 97 cost time: 1.3541498184204102\n","Epoch: 97, Steps: 34 | Train Loss: 0.3833287 Vali Loss: 0.2556573 Test Loss: 1.4702541\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 3.1554436208840473e-32\n","Epoch: 98 cost time: 1.450287103652954\n","Epoch: 98, Steps: 34 | Train Loss: 0.3832387 Vali Loss: 0.2793263 Test Loss: 1.4881549\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 1.5777218104420236e-32\n","Epoch: 99 cost time: 1.3616299629211426\n","Epoch: 99, Steps: 34 | Train Loss: 0.3818192 Vali Loss: 0.2655745 Test Loss: 1.4884198\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 7.888609052210118e-33\n","Epoch: 100 cost time: 1.3301260471343994\n","Epoch: 100, Steps: 34 | Train Loss: 0.3825065 Vali Loss: 0.2561458 Test Loss: 1.4901350\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 3.944304526105059e-33\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl24_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 170\n","mse:1.4966450929641724, mae:0.7994899749755859, rse:0.5903795957565308\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl24_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  36\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  1\n","Exp_Main init!\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl36_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 537\n","val 62\n","test 158\n","Epoch: 1 cost time: 1.3504295349121094\n","Epoch: 1, Steps: 33 | Train Loss: 0.9167027 Vali Loss: 0.3527840 Test Loss: 2.7012320\n","Validation loss decreased (inf --> 0.352784).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 1.4470787048339844\n","Epoch: 2, Steps: 33 | Train Loss: 0.7420997 Vali Loss: 0.3756991 Test Loss: 1.9311235\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.00125\n","Epoch: 3 cost time: 1.3362996578216553\n","Epoch: 3, Steps: 33 | Train Loss: 0.5373852 Vali Loss: 0.2559387 Test Loss: 1.8305078\n","Validation loss decreased (0.352784 --> 0.255939).  Saving model ...\n","Updating learning rate to 0.000625\n","Epoch: 4 cost time: 1.2866833209991455\n","Epoch: 4, Steps: 33 | Train Loss: 0.4583868 Vali Loss: 0.2604176 Test Loss: 1.8191910\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0003125\n","Epoch: 5 cost time: 1.3020007610321045\n","Epoch: 5, Steps: 33 | Train Loss: 0.4256753 Vali Loss: 0.2229504 Test Loss: 1.6685447\n","Validation loss decreased (0.255939 --> 0.222950).  Saving model ...\n","Updating learning rate to 0.00015625\n","Epoch: 6 cost time: 1.297084093093872\n","Epoch: 6, Steps: 33 | Train Loss: 0.4148970 Vali Loss: 0.2332407 Test Loss: 1.7065328\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.8125e-05\n","Epoch: 7 cost time: 1.3941066265106201\n","Epoch: 7, Steps: 33 | Train Loss: 0.4134339 Vali Loss: 0.2402217 Test Loss: 1.6923945\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.90625e-05\n","Epoch: 8 cost time: 1.4014625549316406\n","Epoch: 8, Steps: 33 | Train Loss: 0.4074399 Vali Loss: 0.2212976 Test Loss: 1.6854143\n","Validation loss decreased (0.222950 --> 0.221298).  Saving model ...\n","Updating learning rate to 1.953125e-05\n","Epoch: 9 cost time: 1.3305020332336426\n","Epoch: 9, Steps: 33 | Train Loss: 0.4068109 Vali Loss: 0.2274437 Test Loss: 1.6671349\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 9.765625e-06\n","Epoch: 10 cost time: 1.3090968132019043\n","Epoch: 10, Steps: 33 | Train Loss: 0.4005288 Vali Loss: 0.2258096 Test Loss: 1.6674764\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 4.8828125e-06\n","Epoch: 11 cost time: 1.3671298027038574\n","Epoch: 11, Steps: 33 | Train Loss: 0.4076719 Vali Loss: 0.2219657 Test Loss: 1.6736094\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 2.44140625e-06\n","Epoch: 12 cost time: 1.35679030418396\n","Epoch: 12, Steps: 33 | Train Loss: 0.4070421 Vali Loss: 0.2153186 Test Loss: 1.6822058\n","Validation loss decreased (0.221298 --> 0.215319).  Saving model ...\n","Updating learning rate to 1.220703125e-06\n","Epoch: 13 cost time: 1.374471664428711\n","Epoch: 13, Steps: 33 | Train Loss: 0.4013930 Vali Loss: 0.2258115 Test Loss: 1.6738409\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 6.103515625e-07\n","Epoch: 14 cost time: 1.3008110523223877\n","Epoch: 14, Steps: 33 | Train Loss: 0.4026095 Vali Loss: 0.2284539 Test Loss: 1.6618857\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.0517578125e-07\n","Epoch: 15 cost time: 1.288949728012085\n","Epoch: 15, Steps: 33 | Train Loss: 0.4073122 Vali Loss: 0.2212693 Test Loss: 1.6718917\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.52587890625e-07\n","Epoch: 16 cost time: 1.3051762580871582\n","Epoch: 16, Steps: 33 | Train Loss: 0.4028275 Vali Loss: 0.2468476 Test Loss: 1.6642263\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 7.62939453125e-08\n","Epoch: 17 cost time: 1.304239273071289\n","Epoch: 17, Steps: 33 | Train Loss: 0.4099006 Vali Loss: 0.2305704 Test Loss: 1.6789393\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 3.814697265625e-08\n","Epoch: 18 cost time: 1.3591101169586182\n","Epoch: 18, Steps: 33 | Train Loss: 0.4071386 Vali Loss: 0.2220724 Test Loss: 1.6692170\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.9073486328125e-08\n","Epoch: 19 cost time: 1.3794784545898438\n","Epoch: 19, Steps: 33 | Train Loss: 0.3950372 Vali Loss: 0.2211198 Test Loss: 1.6841587\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 9.5367431640625e-09\n","Epoch: 20 cost time: 1.3401482105255127\n","Epoch: 20, Steps: 33 | Train Loss: 0.4030517 Vali Loss: 0.2374183 Test Loss: 1.6797224\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 4.76837158203125e-09\n","Epoch: 21 cost time: 1.335068702697754\n","Epoch: 21, Steps: 33 | Train Loss: 0.4044063 Vali Loss: 0.2328098 Test Loss: 1.6728077\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 2.384185791015625e-09\n","Epoch: 22 cost time: 1.326594352722168\n","Epoch: 22, Steps: 33 | Train Loss: 0.4098200 Vali Loss: 0.2226248 Test Loss: 1.6783010\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 1.1920928955078125e-09\n","Epoch: 23 cost time: 1.2817604541778564\n","Epoch: 23, Steps: 33 | Train Loss: 0.4089939 Vali Loss: 0.2331953 Test Loss: 1.6766616\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 5.960464477539063e-10\n","Epoch: 24 cost time: 1.353853702545166\n","Epoch: 24, Steps: 33 | Train Loss: 0.4076029 Vali Loss: 0.2214568 Test Loss: 1.6827894\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.9802322387695313e-10\n","Epoch: 25 cost time: 1.341829538345337\n","Epoch: 25, Steps: 33 | Train Loss: 0.4076151 Vali Loss: 0.2266824 Test Loss: 1.6708697\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.4901161193847657e-10\n","Epoch: 26 cost time: 1.3299684524536133\n","Epoch: 26, Steps: 33 | Train Loss: 0.4082123 Vali Loss: 0.2323262 Test Loss: 1.6757894\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 7.450580596923828e-11\n","Epoch: 27 cost time: 1.300081491470337\n","Epoch: 27, Steps: 33 | Train Loss: 0.4037205 Vali Loss: 0.2310706 Test Loss: 1.6858438\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 3.725290298461914e-11\n","Epoch: 28 cost time: 1.3603732585906982\n","Epoch: 28, Steps: 33 | Train Loss: 0.4026978 Vali Loss: 0.2244153 Test Loss: 1.6781459\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.862645149230957e-11\n","Epoch: 29 cost time: 1.3231761455535889\n","Epoch: 29, Steps: 33 | Train Loss: 0.4047835 Vali Loss: 0.2291303 Test Loss: 1.6759926\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 9.313225746154785e-12\n","Epoch: 30 cost time: 1.4079704284667969\n","Epoch: 30, Steps: 33 | Train Loss: 0.3980561 Vali Loss: 0.2182250 Test Loss: 1.6690508\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 4.656612873077393e-12\n","Epoch: 31 cost time: 1.3065531253814697\n","Epoch: 31, Steps: 33 | Train Loss: 0.4120841 Vali Loss: 0.2158051 Test Loss: 1.6713309\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 2.3283064365386963e-12\n","Epoch: 32 cost time: 1.2943463325500488\n","Epoch: 32, Steps: 33 | Train Loss: 0.4062533 Vali Loss: 0.2158482 Test Loss: 1.6795589\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 1.1641532182693482e-12\n","Epoch: 33 cost time: 1.3155758380889893\n","Epoch: 33, Steps: 33 | Train Loss: 0.4019157 Vali Loss: 0.2206616 Test Loss: 1.6801127\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 5.820766091346741e-13\n","Epoch: 34 cost time: 1.2794971466064453\n","Epoch: 34, Steps: 33 | Train Loss: 0.4068228 Vali Loss: 0.2284205 Test Loss: 1.6861260\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 2.9103830456733704e-13\n","Epoch: 35 cost time: 1.434654712677002\n","Epoch: 35, Steps: 33 | Train Loss: 0.4083067 Vali Loss: 0.2245800 Test Loss: 1.6804328\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 1.4551915228366852e-13\n","Epoch: 36 cost time: 1.421724796295166\n","Epoch: 36, Steps: 33 | Train Loss: 0.4082238 Vali Loss: 0.2362580 Test Loss: 1.6831365\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 7.275957614183426e-14\n","Epoch: 37 cost time: 1.3293163776397705\n","Epoch: 37, Steps: 33 | Train Loss: 0.4005803 Vali Loss: 0.2230691 Test Loss: 1.6658250\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 3.637978807091713e-14\n","Epoch: 38 cost time: 1.3386881351470947\n","Epoch: 38, Steps: 33 | Train Loss: 0.4070651 Vali Loss: 0.2283473 Test Loss: 1.6671971\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 1.8189894035458565e-14\n","Epoch: 39 cost time: 1.3000762462615967\n","Epoch: 39, Steps: 33 | Train Loss: 0.4004512 Vali Loss: 0.2330444 Test Loss: 1.6804297\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 9.094947017729283e-15\n","Epoch: 40 cost time: 1.3160455226898193\n","Epoch: 40, Steps: 33 | Train Loss: 0.4012155 Vali Loss: 0.2360447 Test Loss: 1.6828202\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 4.547473508864641e-15\n","Epoch: 41 cost time: 1.3968982696533203\n","Epoch: 41, Steps: 33 | Train Loss: 0.4097868 Vali Loss: 0.2386356 Test Loss: 1.6780444\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 2.2737367544323206e-15\n","Epoch: 42 cost time: 1.2735984325408936\n","Epoch: 42, Steps: 33 | Train Loss: 0.4020176 Vali Loss: 0.2218626 Test Loss: 1.6645339\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 1.1368683772161603e-15\n","Epoch: 43 cost time: 1.3003301620483398\n","Epoch: 43, Steps: 33 | Train Loss: 0.4082982 Vali Loss: 0.2366148 Test Loss: 1.6797477\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 5.684341886080802e-16\n","Epoch: 44 cost time: 1.3420486450195312\n","Epoch: 44, Steps: 33 | Train Loss: 0.3993264 Vali Loss: 0.2255813 Test Loss: 1.6823153\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 2.842170943040401e-16\n","Epoch: 45 cost time: 1.3438129425048828\n","Epoch: 45, Steps: 33 | Train Loss: 0.4072310 Vali Loss: 0.2272143 Test Loss: 1.6836635\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 1.4210854715202004e-16\n","Epoch: 46 cost time: 1.423546314239502\n","Epoch: 46, Steps: 33 | Train Loss: 0.4052970 Vali Loss: 0.2264603 Test Loss: 1.6780385\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 7.105427357601002e-17\n","Epoch: 47 cost time: 1.4061505794525146\n","Epoch: 47, Steps: 33 | Train Loss: 0.4049711 Vali Loss: 0.2354949 Test Loss: 1.6595448\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 3.552713678800501e-17\n","Epoch: 48 cost time: 1.3177111148834229\n","Epoch: 48, Steps: 33 | Train Loss: 0.4047315 Vali Loss: 0.2365807 Test Loss: 1.6865145\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 1.7763568394002505e-17\n","Epoch: 49 cost time: 1.3122146129608154\n","Epoch: 49, Steps: 33 | Train Loss: 0.4065157 Vali Loss: 0.2362285 Test Loss: 1.6810559\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 8.881784197001253e-18\n","Epoch: 50 cost time: 1.2914879322052002\n","Epoch: 50, Steps: 33 | Train Loss: 0.4057637 Vali Loss: 0.2279997 Test Loss: 1.6804810\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 4.440892098500626e-18\n","Epoch: 51 cost time: 1.3371751308441162\n","Epoch: 51, Steps: 33 | Train Loss: 0.4099210 Vali Loss: 0.2275195 Test Loss: 1.6738139\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 2.220446049250313e-18\n","Epoch: 52 cost time: 1.3845477104187012\n","Epoch: 52, Steps: 33 | Train Loss: 0.4059788 Vali Loss: 0.2304902 Test Loss: 1.6711848\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 1.1102230246251566e-18\n","Epoch: 53 cost time: 1.3466525077819824\n","Epoch: 53, Steps: 33 | Train Loss: 0.4076490 Vali Loss: 0.2316346 Test Loss: 1.6794248\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 5.551115123125783e-19\n","Epoch: 54 cost time: 1.3628532886505127\n","Epoch: 54, Steps: 33 | Train Loss: 0.4080010 Vali Loss: 0.2222073 Test Loss: 1.6803365\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 2.7755575615628914e-19\n","Epoch: 55 cost time: 1.3050811290740967\n","Epoch: 55, Steps: 33 | Train Loss: 0.4075292 Vali Loss: 0.2390845 Test Loss: 1.6720432\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 1.3877787807814457e-19\n","Epoch: 56 cost time: 1.3466110229492188\n","Epoch: 56, Steps: 33 | Train Loss: 0.4076234 Vali Loss: 0.2260135 Test Loss: 1.6731411\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 6.938893903907229e-20\n","Epoch: 57 cost time: 1.424102544784546\n","Epoch: 57, Steps: 33 | Train Loss: 0.4029345 Vali Loss: 0.2264673 Test Loss: 1.6814969\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 3.469446951953614e-20\n","Epoch: 58 cost time: 1.3993752002716064\n","Epoch: 58, Steps: 33 | Train Loss: 0.4013305 Vali Loss: 0.2256941 Test Loss: 1.6687756\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 1.734723475976807e-20\n","Epoch: 59 cost time: 1.3342342376708984\n","Epoch: 59, Steps: 33 | Train Loss: 0.4073090 Vali Loss: 0.2181080 Test Loss: 1.6838206\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 8.673617379884036e-21\n","Epoch: 60 cost time: 1.2833220958709717\n","Epoch: 60, Steps: 33 | Train Loss: 0.4062480 Vali Loss: 0.2320529 Test Loss: 1.6740935\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 4.336808689942018e-21\n","Epoch: 61 cost time: 1.325798749923706\n","Epoch: 61, Steps: 33 | Train Loss: 0.4069942 Vali Loss: 0.2527702 Test Loss: 1.6772926\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 2.168404344971009e-21\n","Epoch: 62 cost time: 1.337151050567627\n","Epoch: 62, Steps: 33 | Train Loss: 0.4044007 Vali Loss: 0.2212666 Test Loss: 1.6752908\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 1.0842021724855045e-21\n","Epoch: 63 cost time: 1.3650729656219482\n","Epoch: 63, Steps: 33 | Train Loss: 0.3969091 Vali Loss: 0.2265195 Test Loss: 1.6670737\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 5.421010862427522e-22\n","Epoch: 64 cost time: 1.4064970016479492\n","Epoch: 64, Steps: 33 | Train Loss: 0.4055212 Vali Loss: 0.2315363 Test Loss: 1.6852990\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 2.710505431213761e-22\n","Epoch: 65 cost time: 1.339440107345581\n","Epoch: 65, Steps: 33 | Train Loss: 0.4018192 Vali Loss: 0.2223664 Test Loss: 1.6711216\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 1.3552527156068806e-22\n","Epoch: 66 cost time: 1.362588882446289\n","Epoch: 66, Steps: 33 | Train Loss: 0.4010798 Vali Loss: 0.2257113 Test Loss: 1.6683958\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 6.776263578034403e-23\n","Epoch: 67 cost time: 1.3107383251190186\n","Epoch: 67, Steps: 33 | Train Loss: 0.4070735 Vali Loss: 0.2281155 Test Loss: 1.6766437\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 3.3881317890172014e-23\n","Epoch: 68 cost time: 1.3937034606933594\n","Epoch: 68, Steps: 33 | Train Loss: 0.4002000 Vali Loss: 0.2355756 Test Loss: 1.6663442\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 1.6940658945086007e-23\n","Epoch: 69 cost time: 1.398921012878418\n","Epoch: 69, Steps: 33 | Train Loss: 0.4020230 Vali Loss: 0.2150071 Test Loss: 1.6718349\n","Validation loss decreased (0.215319 --> 0.215007).  Saving model ...\n","Updating learning rate to 8.470329472543004e-24\n","Epoch: 70 cost time: 1.3140268325805664\n","Epoch: 70, Steps: 33 | Train Loss: 0.4032922 Vali Loss: 0.2265062 Test Loss: 1.6794579\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.235164736271502e-24\n","Epoch: 71 cost time: 1.3365135192871094\n","Epoch: 71, Steps: 33 | Train Loss: 0.4029436 Vali Loss: 0.2194956 Test Loss: 1.6741166\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.117582368135751e-24\n","Epoch: 72 cost time: 1.3497743606567383\n","Epoch: 72, Steps: 33 | Train Loss: 0.4060082 Vali Loss: 0.2278150 Test Loss: 1.6711367\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.0587911840678754e-24\n","Epoch: 73 cost time: 1.3735449314117432\n","Epoch: 73, Steps: 33 | Train Loss: 0.4026557 Vali Loss: 0.2306894 Test Loss: 1.6738992\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 5.293955920339377e-25\n","Epoch: 74 cost time: 1.4460248947143555\n","Epoch: 74, Steps: 33 | Train Loss: 0.3959672 Vali Loss: 0.2377119 Test Loss: 1.6790390\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.6469779601696886e-25\n","Epoch: 75 cost time: 1.3044610023498535\n","Epoch: 75, Steps: 33 | Train Loss: 0.4008349 Vali Loss: 0.2175729 Test Loss: 1.6762166\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.3234889800848443e-25\n","Epoch: 76 cost time: 1.3571484088897705\n","Epoch: 76, Steps: 33 | Train Loss: 0.3884774 Vali Loss: 0.2266218 Test Loss: 1.6749612\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 6.617444900424222e-26\n","Epoch: 77 cost time: 1.30238938331604\n","Epoch: 77, Steps: 33 | Train Loss: 0.3993073 Vali Loss: 0.2216075 Test Loss: 1.6660619\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.308722450212111e-26\n","Epoch: 78 cost time: 1.3541851043701172\n","Epoch: 78, Steps: 33 | Train Loss: 0.4060751 Vali Loss: 0.2363838 Test Loss: 1.6800113\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.6543612251060554e-26\n","Epoch: 79 cost time: 1.4355535507202148\n","Epoch: 79, Steps: 33 | Train Loss: 0.4014306 Vali Loss: 0.2251417 Test Loss: 1.6687300\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 8.271806125530277e-27\n","Epoch: 80 cost time: 1.4133174419403076\n","Epoch: 80, Steps: 33 | Train Loss: 0.3995502 Vali Loss: 0.2310871 Test Loss: 1.6742098\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 4.1359030627651385e-27\n","Epoch: 81 cost time: 1.2958717346191406\n","Epoch: 81, Steps: 33 | Train Loss: 0.4039135 Vali Loss: 0.2224879 Test Loss: 1.6716180\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.0679515313825692e-27\n","Epoch: 82 cost time: 1.3018250465393066\n","Epoch: 82, Steps: 33 | Train Loss: 0.4025707 Vali Loss: 0.2198938 Test Loss: 1.6680717\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.0339757656912846e-27\n","Epoch: 83 cost time: 1.3921401500701904\n","Epoch: 83, Steps: 33 | Train Loss: 0.4049702 Vali Loss: 0.2284263 Test Loss: 1.6711617\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 5.169878828456423e-28\n","Epoch: 84 cost time: 1.4008080959320068\n","Epoch: 84, Steps: 33 | Train Loss: 0.4044081 Vali Loss: 0.2304577 Test Loss: 1.6695588\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 2.5849394142282115e-28\n","Epoch: 85 cost time: 1.344022274017334\n","Epoch: 85, Steps: 33 | Train Loss: 0.3961336 Vali Loss: 0.2308631 Test Loss: 1.6748624\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.2924697071141058e-28\n","Epoch: 86 cost time: 1.3004090785980225\n","Epoch: 86, Steps: 33 | Train Loss: 0.4063195 Vali Loss: 0.2208143 Test Loss: 1.6800632\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 6.462348535570529e-29\n","Epoch: 87 cost time: 1.2974400520324707\n","Epoch: 87, Steps: 33 | Train Loss: 0.4083044 Vali Loss: 0.2505319 Test Loss: 1.6747146\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 3.2311742677852644e-29\n","Epoch: 88 cost time: 1.3053369522094727\n","Epoch: 88, Steps: 33 | Train Loss: 0.4087885 Vali Loss: 0.2121940 Test Loss: 1.6625161\n","Validation loss decreased (0.215007 --> 0.212194).  Saving model ...\n","Updating learning rate to 1.6155871338926322e-29\n","Epoch: 89 cost time: 1.3374435901641846\n","Epoch: 89, Steps: 33 | Train Loss: 0.4034209 Vali Loss: 0.2327493 Test Loss: 1.6695279\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 8.077935669463161e-30\n","Epoch: 90 cost time: 1.3889296054840088\n","Epoch: 90, Steps: 33 | Train Loss: 0.4068314 Vali Loss: 0.2282434 Test Loss: 1.6763530\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 4.0389678347315805e-30\n","Epoch: 91 cost time: 1.4013051986694336\n","Epoch: 91, Steps: 33 | Train Loss: 0.4062474 Vali Loss: 0.2279308 Test Loss: 1.6780292\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 2.0194839173657903e-30\n","Epoch: 92 cost time: 1.3215985298156738\n","Epoch: 92, Steps: 33 | Train Loss: 0.4050918 Vali Loss: 0.2284366 Test Loss: 1.6785876\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 1.0097419586828951e-30\n","Epoch: 93 cost time: 1.334918737411499\n","Epoch: 93, Steps: 33 | Train Loss: 0.4015604 Vali Loss: 0.2275439 Test Loss: 1.6739981\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 5.048709793414476e-31\n","Epoch: 94 cost time: 1.2766978740692139\n","Epoch: 94, Steps: 33 | Train Loss: 0.4083084 Vali Loss: 0.2210900 Test Loss: 1.6643897\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 2.524354896707238e-31\n","Epoch: 95 cost time: 1.3341288566589355\n","Epoch: 95, Steps: 33 | Train Loss: 0.4067204 Vali Loss: 0.2379138 Test Loss: 1.6832095\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 1.262177448353619e-31\n","Epoch: 96 cost time: 1.3558480739593506\n","Epoch: 96, Steps: 33 | Train Loss: 0.3964653 Vali Loss: 0.2227960 Test Loss: 1.6790558\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 6.310887241768095e-32\n","Epoch: 97 cost time: 1.321747064590454\n","Epoch: 97, Steps: 33 | Train Loss: 0.4062300 Vali Loss: 0.2301932 Test Loss: 1.6824338\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 3.1554436208840473e-32\n","Epoch: 98 cost time: 1.337007761001587\n","Epoch: 98, Steps: 33 | Train Loss: 0.4097336 Vali Loss: 0.2216607 Test Loss: 1.6711496\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 1.5777218104420236e-32\n","Epoch: 99 cost time: 1.3401618003845215\n","Epoch: 99, Steps: 33 | Train Loss: 0.4062805 Vali Loss: 0.2286227 Test Loss: 1.6903434\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 7.888609052210118e-33\n","Epoch: 100 cost time: 1.319225549697876\n","Epoch: 100, Steps: 33 | Train Loss: 0.4060284 Vali Loss: 0.2367061 Test Loss: 1.6721566\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 3.944304526105059e-33\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl36_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 158\n","mse:1.6625161170959473, mae:0.852337658405304, rse:0.6183992028236389\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl36_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  48\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  1\n","Exp_Main init!\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl48_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 525\n","val 50\n","test 146\n","Epoch: 1 cost time: 1.3872649669647217\n","Epoch: 1, Steps: 32 | Train Loss: 0.9230276 Vali Loss: 0.3525093 Test Loss: 2.9173939\n","Validation loss decreased (inf --> 0.352509).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 1.3188247680664062\n","Epoch: 2, Steps: 32 | Train Loss: 0.8386048 Vali Loss: 1.0660363 Test Loss: 4.2432013\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.00125\n","Epoch: 3 cost time: 1.2982068061828613\n","Epoch: 3, Steps: 32 | Train Loss: 0.5804455 Vali Loss: 0.2183308 Test Loss: 1.7938120\n","Validation loss decreased (0.352509 --> 0.218331).  Saving model ...\n","Updating learning rate to 0.000625\n","Epoch: 4 cost time: 1.2775230407714844\n","Epoch: 4, Steps: 32 | Train Loss: 0.4891046 Vali Loss: 0.2137760 Test Loss: 1.9903052\n","Validation loss decreased (0.218331 --> 0.213776).  Saving model ...\n","Updating learning rate to 0.0003125\n","Epoch: 5 cost time: 1.3538131713867188\n","Epoch: 5, Steps: 32 | Train Loss: 0.4728180 Vali Loss: 0.2041568 Test Loss: 1.9699266\n","Validation loss decreased (0.213776 --> 0.204157).  Saving model ...\n","Updating learning rate to 0.00015625\n","Epoch: 6 cost time: 1.4021763801574707\n","Epoch: 6, Steps: 32 | Train Loss: 0.4623893 Vali Loss: 0.2136165 Test Loss: 2.0092261\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.8125e-05\n","Epoch: 7 cost time: 1.2806446552276611\n","Epoch: 7, Steps: 32 | Train Loss: 0.4536178 Vali Loss: 0.2052164 Test Loss: 1.9607080\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.90625e-05\n","Epoch: 8 cost time: 1.319223403930664\n","Epoch: 8, Steps: 32 | Train Loss: 0.4509073 Vali Loss: 0.2032034 Test Loss: 1.9425875\n","Validation loss decreased (0.204157 --> 0.203203).  Saving model ...\n","Updating learning rate to 1.953125e-05\n","Epoch: 9 cost time: 1.3204190731048584\n","Epoch: 9, Steps: 32 | Train Loss: 0.4506765 Vali Loss: 0.2029483 Test Loss: 1.9451728\n","Validation loss decreased (0.203203 --> 0.202948).  Saving model ...\n","Updating learning rate to 9.765625e-06\n","Epoch: 10 cost time: 1.2908658981323242\n","Epoch: 10, Steps: 32 | Train Loss: 0.4451605 Vali Loss: 0.2037239 Test Loss: 1.9499654\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.8828125e-06\n","Epoch: 11 cost time: 1.3108725547790527\n","Epoch: 11, Steps: 32 | Train Loss: 0.4481509 Vali Loss: 0.2041758 Test Loss: 1.9506011\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.44140625e-06\n","Epoch: 12 cost time: 1.3772892951965332\n","Epoch: 12, Steps: 32 | Train Loss: 0.4439032 Vali Loss: 0.2059567 Test Loss: 1.9563885\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.220703125e-06\n","Epoch: 13 cost time: 1.2754404544830322\n","Epoch: 13, Steps: 32 | Train Loss: 0.4481609 Vali Loss: 0.2007675 Test Loss: 1.9514593\n","Validation loss decreased (0.202948 --> 0.200768).  Saving model ...\n","Updating learning rate to 6.103515625e-07\n","Epoch: 14 cost time: 1.298694372177124\n","Epoch: 14, Steps: 32 | Train Loss: 0.4488267 Vali Loss: 0.2059523 Test Loss: 1.9516013\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.0517578125e-07\n","Epoch: 15 cost time: 1.284752368927002\n","Epoch: 15, Steps: 32 | Train Loss: 0.4372392 Vali Loss: 0.2057949 Test Loss: 1.9510326\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.52587890625e-07\n","Epoch: 16 cost time: 1.3676707744598389\n","Epoch: 16, Steps: 32 | Train Loss: 0.4392047 Vali Loss: 0.2024756 Test Loss: 1.9500231\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 7.62939453125e-08\n","Epoch: 17 cost time: 1.4211041927337646\n","Epoch: 17, Steps: 32 | Train Loss: 0.4384867 Vali Loss: 0.2043554 Test Loss: 1.9563192\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 3.814697265625e-08\n","Epoch: 18 cost time: 1.306535005569458\n","Epoch: 18, Steps: 32 | Train Loss: 0.4408422 Vali Loss: 0.2062529 Test Loss: 1.9506427\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.9073486328125e-08\n","Epoch: 19 cost time: 1.2719078063964844\n","Epoch: 19, Steps: 32 | Train Loss: 0.4424981 Vali Loss: 0.2064493 Test Loss: 1.9602163\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 9.5367431640625e-09\n","Epoch: 20 cost time: 1.3093540668487549\n","Epoch: 20, Steps: 32 | Train Loss: 0.4492092 Vali Loss: 0.2091322 Test Loss: 1.9491808\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 4.76837158203125e-09\n","Epoch: 21 cost time: 1.5301775932312012\n","Epoch: 21, Steps: 32 | Train Loss: 0.4458930 Vali Loss: 0.2060900 Test Loss: 1.9546242\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 2.384185791015625e-09\n","Epoch: 22 cost time: 1.3748207092285156\n","Epoch: 22, Steps: 32 | Train Loss: 0.4447941 Vali Loss: 0.2009421 Test Loss: 1.9410616\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.1920928955078125e-09\n","Epoch: 23 cost time: 1.3353919982910156\n","Epoch: 23, Steps: 32 | Train Loss: 0.4467379 Vali Loss: 0.2018825 Test Loss: 1.9529595\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 5.960464477539063e-10\n","Epoch: 24 cost time: 1.3411033153533936\n","Epoch: 24, Steps: 32 | Train Loss: 0.4428746 Vali Loss: 0.2061201 Test Loss: 1.9579817\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 2.9802322387695313e-10\n","Epoch: 25 cost time: 1.3826992511749268\n","Epoch: 25, Steps: 32 | Train Loss: 0.4437219 Vali Loss: 0.2019168 Test Loss: 1.9587388\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.4901161193847657e-10\n","Epoch: 26 cost time: 1.3195185661315918\n","Epoch: 26, Steps: 32 | Train Loss: 0.4436753 Vali Loss: 0.2078531 Test Loss: 1.9543271\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 7.450580596923828e-11\n","Epoch: 27 cost time: 1.442763090133667\n","Epoch: 27, Steps: 32 | Train Loss: 0.4486475 Vali Loss: 0.2085442 Test Loss: 1.9538950\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 3.725290298461914e-11\n","Epoch: 28 cost time: 1.338287353515625\n","Epoch: 28, Steps: 32 | Train Loss: 0.4407952 Vali Loss: 0.2034652 Test Loss: 1.9518666\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 1.862645149230957e-11\n","Epoch: 29 cost time: 1.3656821250915527\n","Epoch: 29, Steps: 32 | Train Loss: 0.4390231 Vali Loss: 0.2091534 Test Loss: 1.9542847\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 9.313225746154785e-12\n","Epoch: 30 cost time: 1.3119254112243652\n","Epoch: 30, Steps: 32 | Train Loss: 0.4501875 Vali Loss: 0.2060032 Test Loss: 1.9566023\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 4.656612873077393e-12\n","Epoch: 31 cost time: 1.3376290798187256\n","Epoch: 31, Steps: 32 | Train Loss: 0.4364439 Vali Loss: 0.2033976 Test Loss: 1.9556192\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 2.3283064365386963e-12\n","Epoch: 32 cost time: 1.47776198387146\n","Epoch: 32, Steps: 32 | Train Loss: 0.4484937 Vali Loss: 0.2052896 Test Loss: 1.9517817\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.1641532182693482e-12\n","Epoch: 33 cost time: 1.4463825225830078\n","Epoch: 33, Steps: 32 | Train Loss: 0.4451133 Vali Loss: 0.2054321 Test Loss: 1.9489430\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 5.820766091346741e-13\n","Epoch: 34 cost time: 1.3429152965545654\n","Epoch: 34, Steps: 32 | Train Loss: 0.4512425 Vali Loss: 0.2006670 Test Loss: 1.9511948\n","Validation loss decreased (0.200768 --> 0.200667).  Saving model ...\n","Updating learning rate to 2.9103830456733704e-13\n","Epoch: 35 cost time: 1.3216395378112793\n","Epoch: 35, Steps: 32 | Train Loss: 0.4507680 Vali Loss: 0.2099327 Test Loss: 1.9528351\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.4551915228366852e-13\n","Epoch: 36 cost time: 1.2938232421875\n","Epoch: 36, Steps: 32 | Train Loss: 0.4430025 Vali Loss: 0.2043881 Test Loss: 1.9465375\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 7.275957614183426e-14\n","Epoch: 37 cost time: 1.3185646533966064\n","Epoch: 37, Steps: 32 | Train Loss: 0.4421143 Vali Loss: 0.2041073 Test Loss: 1.9533830\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 3.637978807091713e-14\n","Epoch: 38 cost time: 1.3514015674591064\n","Epoch: 38, Steps: 32 | Train Loss: 0.4388279 Vali Loss: 0.2100653 Test Loss: 1.9521743\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 1.8189894035458565e-14\n","Epoch: 39 cost time: 1.3033132553100586\n","Epoch: 39, Steps: 32 | Train Loss: 0.4346428 Vali Loss: 0.2001705 Test Loss: 1.9484564\n","Validation loss decreased (0.200667 --> 0.200171).  Saving model ...\n","Updating learning rate to 9.094947017729283e-15\n","Epoch: 40 cost time: 1.308687686920166\n","Epoch: 40, Steps: 32 | Train Loss: 0.4433792 Vali Loss: 0.2044895 Test Loss: 1.9579606\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.547473508864641e-15\n","Epoch: 41 cost time: 1.3377346992492676\n","Epoch: 41, Steps: 32 | Train Loss: 0.4403849 Vali Loss: 0.2070313 Test Loss: 1.9521569\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.2737367544323206e-15\n","Epoch: 42 cost time: 1.3596253395080566\n","Epoch: 42, Steps: 32 | Train Loss: 0.4498710 Vali Loss: 0.2096013 Test Loss: 1.9563097\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.1368683772161603e-15\n","Epoch: 43 cost time: 1.3982789516448975\n","Epoch: 43, Steps: 32 | Train Loss: 0.4403855 Vali Loss: 0.2080402 Test Loss: 1.9563029\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 5.684341886080802e-16\n","Epoch: 44 cost time: 1.4088492393493652\n","Epoch: 44, Steps: 32 | Train Loss: 0.4404731 Vali Loss: 0.2040971 Test Loss: 1.9532579\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.842170943040401e-16\n","Epoch: 45 cost time: 1.2847259044647217\n","Epoch: 45, Steps: 32 | Train Loss: 0.4348510 Vali Loss: 0.2087589 Test Loss: 1.9509261\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.4210854715202004e-16\n","Epoch: 46 cost time: 1.3302137851715088\n","Epoch: 46, Steps: 32 | Train Loss: 0.4365602 Vali Loss: 0.2007030 Test Loss: 1.9572171\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 7.105427357601002e-17\n","Epoch: 47 cost time: 1.3181166648864746\n","Epoch: 47, Steps: 32 | Train Loss: 0.4469873 Vali Loss: 0.2088168 Test Loss: 1.9545699\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.552713678800501e-17\n","Epoch: 48 cost time: 1.3807494640350342\n","Epoch: 48, Steps: 32 | Train Loss: 0.4483102 Vali Loss: 0.2086246 Test Loss: 1.9543338\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.7763568394002505e-17\n","Epoch: 49 cost time: 1.3804535865783691\n","Epoch: 49, Steps: 32 | Train Loss: 0.4289583 Vali Loss: 0.2018664 Test Loss: 1.9590640\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 8.881784197001253e-18\n","Epoch: 50 cost time: 1.329261064529419\n","Epoch: 50, Steps: 32 | Train Loss: 0.4462926 Vali Loss: 0.2033926 Test Loss: 1.9542893\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 4.440892098500626e-18\n","Epoch: 51 cost time: 1.3558998107910156\n","Epoch: 51, Steps: 32 | Train Loss: 0.4454967 Vali Loss: 0.2027286 Test Loss: 1.9545161\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.220446049250313e-18\n","Epoch: 52 cost time: 1.3376100063323975\n","Epoch: 52, Steps: 32 | Train Loss: 0.4459207 Vali Loss: 0.2016724 Test Loss: 1.9584910\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.1102230246251566e-18\n","Epoch: 53 cost time: 1.3163459300994873\n","Epoch: 53, Steps: 32 | Train Loss: 0.4413899 Vali Loss: 0.2079944 Test Loss: 1.9570467\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 5.551115123125783e-19\n","Epoch: 54 cost time: 1.3533999919891357\n","Epoch: 54, Steps: 32 | Train Loss: 0.4380373 Vali Loss: 0.2072742 Test Loss: 1.9540108\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 2.7755575615628914e-19\n","Epoch: 55 cost time: 1.3585035800933838\n","Epoch: 55, Steps: 32 | Train Loss: 0.4441707 Vali Loss: 0.2101355 Test Loss: 1.9555297\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.3877787807814457e-19\n","Epoch: 56 cost time: 1.2973077297210693\n","Epoch: 56, Steps: 32 | Train Loss: 0.4406503 Vali Loss: 0.2049028 Test Loss: 1.9494016\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 6.938893903907229e-20\n","Epoch: 57 cost time: 1.3082308769226074\n","Epoch: 57, Steps: 32 | Train Loss: 0.4361327 Vali Loss: 0.2046931 Test Loss: 1.9496782\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 3.469446951953614e-20\n","Epoch: 58 cost time: 1.363603115081787\n","Epoch: 58, Steps: 32 | Train Loss: 0.4464601 Vali Loss: 0.2011474 Test Loss: 1.9565805\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.734723475976807e-20\n","Epoch: 59 cost time: 1.3988876342773438\n","Epoch: 59, Steps: 32 | Train Loss: 0.4447129 Vali Loss: 0.2044954 Test Loss: 1.9588517\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 8.673617379884036e-21\n","Epoch: 60 cost time: 1.4318299293518066\n","Epoch: 60, Steps: 32 | Train Loss: 0.4449926 Vali Loss: 0.2072889 Test Loss: 1.9618526\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 4.336808689942018e-21\n","Epoch: 61 cost time: 1.367798089981079\n","Epoch: 61, Steps: 32 | Train Loss: 0.4467506 Vali Loss: 0.2071507 Test Loss: 1.9553648\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 2.168404344971009e-21\n","Epoch: 62 cost time: 1.3855934143066406\n","Epoch: 62, Steps: 32 | Train Loss: 0.4425795 Vali Loss: 0.2056449 Test Loss: 1.9554626\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 1.0842021724855045e-21\n","Epoch: 63 cost time: 1.3331208229064941\n","Epoch: 63, Steps: 32 | Train Loss: 0.4502792 Vali Loss: 0.2047368 Test Loss: 1.9519149\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 5.421010862427522e-22\n","Epoch: 64 cost time: 1.3066761493682861\n","Epoch: 64, Steps: 32 | Train Loss: 0.4432302 Vali Loss: 0.2044768 Test Loss: 1.9495400\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 2.710505431213761e-22\n","Epoch: 65 cost time: 1.4078648090362549\n","Epoch: 65, Steps: 32 | Train Loss: 0.4417998 Vali Loss: 0.1999844 Test Loss: 1.9531479\n","Validation loss decreased (0.200171 --> 0.199984).  Saving model ...\n","Updating learning rate to 1.3552527156068806e-22\n","Epoch: 66 cost time: 1.341806411743164\n","Epoch: 66, Steps: 32 | Train Loss: 0.4414825 Vali Loss: 0.2019337 Test Loss: 1.9468608\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 6.776263578034403e-23\n","Epoch: 67 cost time: 1.3678817749023438\n","Epoch: 67, Steps: 32 | Train Loss: 0.4469468 Vali Loss: 0.2043065 Test Loss: 1.9495261\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.3881317890172014e-23\n","Epoch: 68 cost time: 1.3603551387786865\n","Epoch: 68, Steps: 32 | Train Loss: 0.4491019 Vali Loss: 0.2066219 Test Loss: 1.9491844\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.6940658945086007e-23\n","Epoch: 69 cost time: 1.3142821788787842\n","Epoch: 69, Steps: 32 | Train Loss: 0.4337065 Vali Loss: 0.2071984 Test Loss: 1.9661318\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 8.470329472543004e-24\n","Epoch: 70 cost time: 1.3818376064300537\n","Epoch: 70, Steps: 32 | Train Loss: 0.4468752 Vali Loss: 0.2053770 Test Loss: 1.9597564\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 4.235164736271502e-24\n","Epoch: 71 cost time: 1.4323160648345947\n","Epoch: 71, Steps: 32 | Train Loss: 0.4480309 Vali Loss: 0.2001733 Test Loss: 1.9521594\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 2.117582368135751e-24\n","Epoch: 72 cost time: 1.3477869033813477\n","Epoch: 72, Steps: 32 | Train Loss: 0.4495853 Vali Loss: 0.2102840 Test Loss: 1.9600832\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 1.0587911840678754e-24\n","Epoch: 73 cost time: 1.3027565479278564\n","Epoch: 73, Steps: 32 | Train Loss: 0.4452805 Vali Loss: 0.2050894 Test Loss: 1.9494939\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 5.293955920339377e-25\n","Epoch: 74 cost time: 1.286470651626587\n","Epoch: 74, Steps: 32 | Train Loss: 0.4470356 Vali Loss: 0.2056469 Test Loss: 1.9548109\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 2.6469779601696886e-25\n","Epoch: 75 cost time: 1.39616060256958\n","Epoch: 75, Steps: 32 | Train Loss: 0.4422339 Vali Loss: 0.2049195 Test Loss: 1.9496111\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 1.3234889800848443e-25\n","Epoch: 76 cost time: 1.3892462253570557\n","Epoch: 76, Steps: 32 | Train Loss: 0.4466450 Vali Loss: 0.2047577 Test Loss: 1.9571233\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 6.617444900424222e-26\n","Epoch: 77 cost time: 1.3638484477996826\n","Epoch: 77, Steps: 32 | Train Loss: 0.4414078 Vali Loss: 0.2068928 Test Loss: 1.9580795\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 3.308722450212111e-26\n","Epoch: 78 cost time: 1.3597843647003174\n","Epoch: 78, Steps: 32 | Train Loss: 0.4459489 Vali Loss: 0.2080612 Test Loss: 1.9489297\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.6543612251060554e-26\n","Epoch: 79 cost time: 1.3145503997802734\n","Epoch: 79, Steps: 32 | Train Loss: 0.4504071 Vali Loss: 0.2016351 Test Loss: 1.9573451\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 8.271806125530277e-27\n","Epoch: 80 cost time: 1.3735430240631104\n","Epoch: 80, Steps: 32 | Train Loss: 0.4413332 Vali Loss: 0.2007153 Test Loss: 1.9525666\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 4.1359030627651385e-27\n","Epoch: 81 cost time: 1.3780300617218018\n","Epoch: 81, Steps: 32 | Train Loss: 0.4451445 Vali Loss: 0.2022901 Test Loss: 1.9580413\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 2.0679515313825692e-27\n","Epoch: 82 cost time: 1.3261399269104004\n","Epoch: 82, Steps: 32 | Train Loss: 0.4463214 Vali Loss: 0.2080631 Test Loss: 1.9566214\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 1.0339757656912846e-27\n","Epoch: 83 cost time: 1.2927391529083252\n","Epoch: 83, Steps: 32 | Train Loss: 0.4454209 Vali Loss: 0.2009925 Test Loss: 1.9596487\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 5.169878828456423e-28\n","Epoch: 84 cost time: 1.3303406238555908\n","Epoch: 84, Steps: 32 | Train Loss: 0.4391638 Vali Loss: 0.2054443 Test Loss: 1.9609426\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 2.5849394142282115e-28\n","Epoch: 85 cost time: 1.3111472129821777\n","Epoch: 85, Steps: 32 | Train Loss: 0.4460662 Vali Loss: 0.2029162 Test Loss: 1.9527228\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 1.2924697071141058e-28\n","Epoch: 86 cost time: 1.4182684421539307\n","Epoch: 86, Steps: 32 | Train Loss: 0.4449367 Vali Loss: 0.2085282 Test Loss: 1.9537294\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 6.462348535570529e-29\n","Epoch: 87 cost time: 1.4342873096466064\n","Epoch: 87, Steps: 32 | Train Loss: 0.4473999 Vali Loss: 0.2017771 Test Loss: 1.9519963\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 3.2311742677852644e-29\n","Epoch: 88 cost time: 1.3962528705596924\n","Epoch: 88, Steps: 32 | Train Loss: 0.4437122 Vali Loss: 0.2045867 Test Loss: 1.9541487\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 1.6155871338926322e-29\n","Epoch: 89 cost time: 1.3248093128204346\n","Epoch: 89, Steps: 32 | Train Loss: 0.4403603 Vali Loss: 0.2007390 Test Loss: 1.9580969\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 8.077935669463161e-30\n","Epoch: 90 cost time: 1.293593406677246\n","Epoch: 90, Steps: 32 | Train Loss: 0.4399492 Vali Loss: 0.2094099 Test Loss: 1.9575233\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 4.0389678347315805e-30\n","Epoch: 91 cost time: 1.3578720092773438\n","Epoch: 91, Steps: 32 | Train Loss: 0.4412650 Vali Loss: 0.2010941 Test Loss: 1.9537067\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 2.0194839173657903e-30\n","Epoch: 92 cost time: 1.426626205444336\n","Epoch: 92, Steps: 32 | Train Loss: 0.4385136 Vali Loss: 0.2035565 Test Loss: 1.9563569\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 1.0097419586828951e-30\n","Epoch: 93 cost time: 1.3153111934661865\n","Epoch: 93, Steps: 32 | Train Loss: 0.4545094 Vali Loss: 0.2104387 Test Loss: 1.9591022\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 5.048709793414476e-31\n","Epoch: 94 cost time: 1.3320116996765137\n","Epoch: 94, Steps: 32 | Train Loss: 0.4342050 Vali Loss: 0.2042749 Test Loss: 1.9514896\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 2.524354896707238e-31\n","Epoch: 95 cost time: 1.3701140880584717\n","Epoch: 95, Steps: 32 | Train Loss: 0.4497171 Vali Loss: 0.2048015 Test Loss: 1.9414690\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 1.262177448353619e-31\n","Epoch: 96 cost time: 1.3948049545288086\n","Epoch: 96, Steps: 32 | Train Loss: 0.4513245 Vali Loss: 0.2042341 Test Loss: 1.9556853\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 6.310887241768095e-32\n","Epoch: 97 cost time: 1.4330072402954102\n","Epoch: 97, Steps: 32 | Train Loss: 0.4481531 Vali Loss: 0.2015061 Test Loss: 1.9580233\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 3.1554436208840473e-32\n","Epoch: 98 cost time: 1.3232488632202148\n","Epoch: 98, Steps: 32 | Train Loss: 0.4445926 Vali Loss: 0.2048564 Test Loss: 1.9491844\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 1.5777218104420236e-32\n","Epoch: 99 cost time: 1.361957311630249\n","Epoch: 99, Steps: 32 | Train Loss: 0.4409377 Vali Loss: 0.2086835 Test Loss: 1.9540982\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 7.888609052210118e-33\n","Epoch: 100 cost time: 1.3643107414245605\n","Epoch: 100, Steps: 32 | Train Loss: 0.4531252 Vali Loss: 0.2004020 Test Loss: 1.9509830\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 3.944304526105059e-33\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl48_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 146\n","mse:1.9531478881835938, mae:0.9245817065238953, rse:0.6685310006141663\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl48_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n","Current Prediction Length :  60\n","\n","\n","\n","\n","Use GPU: cuda:0\n","model loaded...\n","decomposition :  1\n","Exp_Main init!\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl60_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 513\n","val 38\n","test 134\n","Epoch: 1 cost time: 1.411527395248413\n","Epoch: 1, Steps: 32 | Train Loss: 0.9228852 Vali Loss: 0.3457697 Test Loss: 2.8379292\n","Validation loss decreased (inf --> 0.345770).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 1.3880412578582764\n","Epoch: 2, Steps: 32 | Train Loss: 0.8432371 Vali Loss: 0.4098260 Test Loss: 1.9160311\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.00125\n","Epoch: 3 cost time: 1.3469269275665283\n","Epoch: 3, Steps: 32 | Train Loss: 0.5719822 Vali Loss: 0.3056507 Test Loss: 1.7924812\n","Validation loss decreased (0.345770 --> 0.305651).  Saving model ...\n","Updating learning rate to 0.000625\n","Epoch: 4 cost time: 1.3411412239074707\n","Epoch: 4, Steps: 32 | Train Loss: 0.4922853 Vali Loss: 0.2498623 Test Loss: 2.0130377\n","Validation loss decreased (0.305651 --> 0.249862).  Saving model ...\n","Updating learning rate to 0.0003125\n","Epoch: 5 cost time: 1.3325376510620117\n","Epoch: 5, Steps: 32 | Train Loss: 0.4632103 Vali Loss: 0.2633715 Test Loss: 2.0368395\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.00015625\n","Epoch: 6 cost time: 1.388490915298462\n","Epoch: 6, Steps: 32 | Train Loss: 0.4494512 Vali Loss: 0.2721581 Test Loss: 1.9997590\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 7.8125e-05\n","Epoch: 7 cost time: 1.2952358722686768\n","Epoch: 7, Steps: 32 | Train Loss: 0.4473975 Vali Loss: 0.2770259 Test Loss: 2.0415936\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 3.90625e-05\n","Epoch: 8 cost time: 1.3597636222839355\n","Epoch: 8, Steps: 32 | Train Loss: 0.4424484 Vali Loss: 0.2682086 Test Loss: 2.0319934\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 1.953125e-05\n","Epoch: 9 cost time: 1.3861141204833984\n","Epoch: 9, Steps: 32 | Train Loss: 0.4378350 Vali Loss: 0.2622994 Test Loss: 2.0330081\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 9.765625e-06\n","Epoch: 10 cost time: 1.3361537456512451\n","Epoch: 10, Steps: 32 | Train Loss: 0.4443380 Vali Loss: 0.2701563 Test Loss: 2.0189276\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 4.8828125e-06\n","Epoch: 11 cost time: 1.420278549194336\n","Epoch: 11, Steps: 32 | Train Loss: 0.4378056 Vali Loss: 0.2530301 Test Loss: 2.0245621\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 2.44140625e-06\n","Epoch: 12 cost time: 1.4398460388183594\n","Epoch: 12, Steps: 32 | Train Loss: 0.4395176 Vali Loss: 0.2573971 Test Loss: 2.0446010\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.220703125e-06\n","Epoch: 13 cost time: 1.3488221168518066\n","Epoch: 13, Steps: 32 | Train Loss: 0.4392133 Vali Loss: 0.2566055 Test Loss: 2.0313849\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 6.103515625e-07\n","Epoch: 14 cost time: 1.3727641105651855\n","Epoch: 14, Steps: 32 | Train Loss: 0.4371992 Vali Loss: 0.2665543 Test Loss: 2.0289571\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 3.0517578125e-07\n","Epoch: 15 cost time: 1.291672945022583\n","Epoch: 15, Steps: 32 | Train Loss: 0.4366034 Vali Loss: 0.2672171 Test Loss: 2.0103314\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 1.52587890625e-07\n","Epoch: 16 cost time: 1.4164881706237793\n","Epoch: 16, Steps: 32 | Train Loss: 0.4389368 Vali Loss: 0.2625656 Test Loss: 2.0230932\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 7.62939453125e-08\n","Epoch: 17 cost time: 1.4063818454742432\n","Epoch: 17, Steps: 32 | Train Loss: 0.4335009 Vali Loss: 0.2691197 Test Loss: 2.0749354\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 3.814697265625e-08\n","Epoch: 18 cost time: 1.3790252208709717\n","Epoch: 18, Steps: 32 | Train Loss: 0.4364252 Vali Loss: 0.2665892 Test Loss: 2.0424676\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 1.9073486328125e-08\n","Epoch: 19 cost time: 1.3555388450622559\n","Epoch: 19, Steps: 32 | Train Loss: 0.4332763 Vali Loss: 0.2519664 Test Loss: 2.0326533\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 9.5367431640625e-09\n","Epoch: 20 cost time: 1.3098492622375488\n","Epoch: 20, Steps: 32 | Train Loss: 0.4367727 Vali Loss: 0.2640632 Test Loss: 2.0372622\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 4.76837158203125e-09\n","Epoch: 21 cost time: 1.3982174396514893\n","Epoch: 21, Steps: 32 | Train Loss: 0.4353951 Vali Loss: 0.2668413 Test Loss: 2.0233536\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 2.384185791015625e-09\n","Epoch: 22 cost time: 1.4322192668914795\n","Epoch: 22, Steps: 32 | Train Loss: 0.4347054 Vali Loss: 0.2571217 Test Loss: 2.0207419\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 1.1920928955078125e-09\n","Epoch: 23 cost time: 1.3501691818237305\n","Epoch: 23, Steps: 32 | Train Loss: 0.4345027 Vali Loss: 0.2691597 Test Loss: 2.0430365\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 5.960464477539063e-10\n","Epoch: 24 cost time: 1.342968225479126\n","Epoch: 24, Steps: 32 | Train Loss: 0.4374736 Vali Loss: 0.2619523 Test Loss: 2.0312381\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 2.9802322387695313e-10\n","Epoch: 25 cost time: 1.3330137729644775\n","Epoch: 25, Steps: 32 | Train Loss: 0.4364359 Vali Loss: 0.2688265 Test Loss: 2.0332398\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 1.4901161193847657e-10\n","Epoch: 26 cost time: 1.3192505836486816\n","Epoch: 26, Steps: 32 | Train Loss: 0.4369027 Vali Loss: 0.2517954 Test Loss: 2.0460303\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 7.450580596923828e-11\n","Epoch: 27 cost time: 1.4405326843261719\n","Epoch: 27, Steps: 32 | Train Loss: 0.4350294 Vali Loss: 0.2622198 Test Loss: 2.0581532\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 3.725290298461914e-11\n","Epoch: 28 cost time: 1.4036931991577148\n","Epoch: 28, Steps: 32 | Train Loss: 0.4394712 Vali Loss: 0.2641092 Test Loss: 2.0138860\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 1.862645149230957e-11\n","Epoch: 29 cost time: 1.3813996315002441\n","Epoch: 29, Steps: 32 | Train Loss: 0.4372342 Vali Loss: 0.2594958 Test Loss: 2.0293794\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 9.313225746154785e-12\n","Epoch: 30 cost time: 1.44832444190979\n","Epoch: 30, Steps: 32 | Train Loss: 0.4369939 Vali Loss: 0.2563135 Test Loss: 2.0109079\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 4.656612873077393e-12\n","Epoch: 31 cost time: 1.3725948333740234\n","Epoch: 31, Steps: 32 | Train Loss: 0.4380694 Vali Loss: 0.2738642 Test Loss: 2.0336721\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 2.3283064365386963e-12\n","Epoch: 32 cost time: 1.4199187755584717\n","Epoch: 32, Steps: 32 | Train Loss: 0.4367189 Vali Loss: 0.2654350 Test Loss: 2.0041919\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 1.1641532182693482e-12\n","Epoch: 33 cost time: 1.4439325332641602\n","Epoch: 33, Steps: 32 | Train Loss: 0.4387600 Vali Loss: 0.2548653 Test Loss: 2.0411284\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 5.820766091346741e-13\n","Epoch: 34 cost time: 1.3769891262054443\n","Epoch: 34, Steps: 32 | Train Loss: 0.4417180 Vali Loss: 0.2672126 Test Loss: 2.0296965\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 2.9103830456733704e-13\n","Epoch: 35 cost time: 1.3706810474395752\n","Epoch: 35, Steps: 32 | Train Loss: 0.4390029 Vali Loss: 0.2667868 Test Loss: 2.0524483\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 1.4551915228366852e-13\n","Epoch: 36 cost time: 1.3915560245513916\n","Epoch: 36, Steps: 32 | Train Loss: 0.4373814 Vali Loss: 0.2683820 Test Loss: 2.0389333\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 7.275957614183426e-14\n","Epoch: 37 cost time: 1.4705908298492432\n","Epoch: 37, Steps: 32 | Train Loss: 0.4380958 Vali Loss: 0.2599574 Test Loss: 2.0556479\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 3.637978807091713e-14\n","Epoch: 38 cost time: 1.500537395477295\n","Epoch: 38, Steps: 32 | Train Loss: 0.4378793 Vali Loss: 0.2611046 Test Loss: 2.0444338\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 1.8189894035458565e-14\n","Epoch: 39 cost time: 1.3078045845031738\n","Epoch: 39, Steps: 32 | Train Loss: 0.4357206 Vali Loss: 0.2554881 Test Loss: 2.0568571\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 9.094947017729283e-15\n","Epoch: 40 cost time: 1.366567611694336\n","Epoch: 40, Steps: 32 | Train Loss: 0.4374649 Vali Loss: 0.2636292 Test Loss: 2.0267100\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 4.547473508864641e-15\n","Epoch: 41 cost time: 1.3255000114440918\n","Epoch: 41, Steps: 32 | Train Loss: 0.4352779 Vali Loss: 0.2504187 Test Loss: 2.0245471\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 2.2737367544323206e-15\n","Epoch: 42 cost time: 1.373924732208252\n","Epoch: 42, Steps: 32 | Train Loss: 0.4420011 Vali Loss: 0.2618449 Test Loss: 2.0270870\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 1.1368683772161603e-15\n","Epoch: 43 cost time: 1.4507203102111816\n","Epoch: 43, Steps: 32 | Train Loss: 0.4367029 Vali Loss: 0.2616732 Test Loss: 2.0191326\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 5.684341886080802e-16\n","Epoch: 44 cost time: 1.3875455856323242\n","Epoch: 44, Steps: 32 | Train Loss: 0.4388911 Vali Loss: 0.2614789 Test Loss: 2.0419688\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 2.842170943040401e-16\n","Epoch: 45 cost time: 1.404111623764038\n","Epoch: 45, Steps: 32 | Train Loss: 0.4366252 Vali Loss: 0.2655500 Test Loss: 2.0205770\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 1.4210854715202004e-16\n","Epoch: 46 cost time: 1.3777577877044678\n","Epoch: 46, Steps: 32 | Train Loss: 0.4359168 Vali Loss: 0.2659218 Test Loss: 2.0454283\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 7.105427357601002e-17\n","Epoch: 47 cost time: 1.8618323802947998\n","Epoch: 47, Steps: 32 | Train Loss: 0.4391870 Vali Loss: 0.2712882 Test Loss: 2.0210960\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 3.552713678800501e-17\n","Epoch: 48 cost time: 1.4279377460479736\n","Epoch: 48, Steps: 32 | Train Loss: 0.4372479 Vali Loss: 0.2500319 Test Loss: 2.0193968\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 1.7763568394002505e-17\n","Epoch: 49 cost time: 1.3735103607177734\n","Epoch: 49, Steps: 32 | Train Loss: 0.4347443 Vali Loss: 0.2749616 Test Loss: 2.0367575\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 8.881784197001253e-18\n","Epoch: 50 cost time: 1.3424205780029297\n","Epoch: 50, Steps: 32 | Train Loss: 0.4363307 Vali Loss: 0.2663144 Test Loss: 2.0388255\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 4.440892098500626e-18\n","Epoch: 51 cost time: 1.3686997890472412\n","Epoch: 51, Steps: 32 | Train Loss: 0.4407275 Vali Loss: 0.2562148 Test Loss: 2.0138309\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 2.220446049250313e-18\n","Epoch: 52 cost time: 1.382289171218872\n","Epoch: 52, Steps: 32 | Train Loss: 0.4399926 Vali Loss: 0.2744606 Test Loss: 2.0455508\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 1.1102230246251566e-18\n","Epoch: 53 cost time: 1.4720101356506348\n","Epoch: 53, Steps: 32 | Train Loss: 0.4341942 Vali Loss: 0.2581008 Test Loss: 2.0273612\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 5.551115123125783e-19\n","Epoch: 54 cost time: 1.3634922504425049\n","Epoch: 54, Steps: 32 | Train Loss: 0.4344163 Vali Loss: 0.2718432 Test Loss: 2.0051785\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 2.7755575615628914e-19\n","Epoch: 55 cost time: 1.3483328819274902\n","Epoch: 55, Steps: 32 | Train Loss: 0.4395105 Vali Loss: 0.2640227 Test Loss: 2.0309284\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 1.3877787807814457e-19\n","Epoch: 56 cost time: 1.3464252948760986\n","Epoch: 56, Steps: 32 | Train Loss: 0.4396512 Vali Loss: 0.2705739 Test Loss: 2.0082150\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 6.938893903907229e-20\n","Epoch: 57 cost time: 1.4124796390533447\n","Epoch: 57, Steps: 32 | Train Loss: 0.4349736 Vali Loss: 0.2649771 Test Loss: 2.0261045\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 3.469446951953614e-20\n","Epoch: 58 cost time: 1.458606481552124\n","Epoch: 58, Steps: 32 | Train Loss: 0.4386767 Vali Loss: 0.2637740 Test Loss: 2.0455260\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 1.734723475976807e-20\n","Epoch: 59 cost time: 1.4111428260803223\n","Epoch: 59, Steps: 32 | Train Loss: 0.4374745 Vali Loss: 0.2674578 Test Loss: 2.0172760\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 8.673617379884036e-21\n","Epoch: 60 cost time: 1.4495205879211426\n","Epoch: 60, Steps: 32 | Train Loss: 0.4387842 Vali Loss: 0.2617692 Test Loss: 2.0388303\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 4.336808689942018e-21\n","Epoch: 61 cost time: 1.4412987232208252\n","Epoch: 61, Steps: 32 | Train Loss: 0.4361968 Vali Loss: 0.2652546 Test Loss: 2.0071876\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 2.168404344971009e-21\n","Epoch: 62 cost time: 1.4499602317810059\n","Epoch: 62, Steps: 32 | Train Loss: 0.4365196 Vali Loss: 0.2563942 Test Loss: 2.0249944\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 1.0842021724855045e-21\n","Epoch: 63 cost time: 1.4937260150909424\n","Epoch: 63, Steps: 32 | Train Loss: 0.4365310 Vali Loss: 0.2748643 Test Loss: 2.0188620\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 5.421010862427522e-22\n","Epoch: 64 cost time: 1.4275729656219482\n","Epoch: 64, Steps: 32 | Train Loss: 0.4372529 Vali Loss: 0.2605602 Test Loss: 2.0272398\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 2.710505431213761e-22\n","Epoch: 65 cost time: 1.3317444324493408\n","Epoch: 65, Steps: 32 | Train Loss: 0.4380051 Vali Loss: 0.2523385 Test Loss: 2.0226917\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 1.3552527156068806e-22\n","Epoch: 66 cost time: 1.3378942012786865\n","Epoch: 66, Steps: 32 | Train Loss: 0.4405804 Vali Loss: 0.2614201 Test Loss: 2.0380640\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 6.776263578034403e-23\n","Epoch: 67 cost time: 1.394233226776123\n","Epoch: 67, Steps: 32 | Train Loss: 0.4362487 Vali Loss: 0.2702100 Test Loss: 2.0388489\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 3.3881317890172014e-23\n","Epoch: 68 cost time: 1.4269523620605469\n","Epoch: 68, Steps: 32 | Train Loss: 0.4367433 Vali Loss: 0.2687683 Test Loss: 2.0257397\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 1.6940658945086007e-23\n","Epoch: 69 cost time: 1.4613676071166992\n","Epoch: 69, Steps: 32 | Train Loss: 0.4385135 Vali Loss: 0.2606008 Test Loss: 2.0226302\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 8.470329472543004e-24\n","Epoch: 70 cost time: 1.414027214050293\n","Epoch: 70, Steps: 32 | Train Loss: 0.4376274 Vali Loss: 0.2733107 Test Loss: 2.0397058\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 4.235164736271502e-24\n","Epoch: 71 cost time: 1.4278526306152344\n","Epoch: 71, Steps: 32 | Train Loss: 0.4382465 Vali Loss: 0.2556655 Test Loss: 2.0362992\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 2.117582368135751e-24\n","Epoch: 72 cost time: 1.4207398891448975\n","Epoch: 72, Steps: 32 | Train Loss: 0.4390447 Vali Loss: 0.2593977 Test Loss: 2.0400097\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 1.0587911840678754e-24\n","Epoch: 73 cost time: 1.4438464641571045\n","Epoch: 73, Steps: 32 | Train Loss: 0.4386421 Vali Loss: 0.2526848 Test Loss: 2.0184140\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 5.293955920339377e-25\n","Epoch: 74 cost time: 1.4099247455596924\n","Epoch: 74, Steps: 32 | Train Loss: 0.4387922 Vali Loss: 0.2584615 Test Loss: 2.0262299\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 2.6469779601696886e-25\n","Epoch: 75 cost time: 1.3657972812652588\n","Epoch: 75, Steps: 32 | Train Loss: 0.4338187 Vali Loss: 0.2713861 Test Loss: 2.0358171\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 1.3234889800848443e-25\n","Epoch: 76 cost time: 1.3855106830596924\n","Epoch: 76, Steps: 32 | Train Loss: 0.4376407 Vali Loss: 0.2509338 Test Loss: 2.0121119\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 6.617444900424222e-26\n","Epoch: 77 cost time: 1.3525137901306152\n","Epoch: 77, Steps: 32 | Train Loss: 0.4401146 Vali Loss: 0.2639772 Test Loss: 2.0495138\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 3.308722450212111e-26\n","Epoch: 78 cost time: 1.4549229145050049\n","Epoch: 78, Steps: 32 | Train Loss: 0.4340746 Vali Loss: 0.2712738 Test Loss: 2.0268726\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 1.6543612251060554e-26\n","Epoch: 79 cost time: 1.4751720428466797\n","Epoch: 79, Steps: 32 | Train Loss: 0.4357993 Vali Loss: 0.2527474 Test Loss: 2.0367174\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 8.271806125530277e-27\n","Epoch: 80 cost time: 1.419663906097412\n","Epoch: 80, Steps: 32 | Train Loss: 0.4359113 Vali Loss: 0.2474464 Test Loss: 2.0478253\n","Validation loss decreased (0.249862 --> 0.247446).  Saving model ...\n","Updating learning rate to 4.1359030627651385e-27\n","Epoch: 81 cost time: 1.384263515472412\n","Epoch: 81, Steps: 32 | Train Loss: 0.4366712 Vali Loss: 0.2605253 Test Loss: 2.0069323\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 2.0679515313825692e-27\n","Epoch: 82 cost time: 1.3350341320037842\n","Epoch: 82, Steps: 32 | Train Loss: 0.4386062 Vali Loss: 0.2583113 Test Loss: 2.0077329\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.0339757656912846e-27\n","Epoch: 83 cost time: 1.384324073791504\n","Epoch: 83, Steps: 32 | Train Loss: 0.4340543 Vali Loss: 0.2533234 Test Loss: 2.0462427\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 5.169878828456423e-28\n","Epoch: 84 cost time: 1.4553625583648682\n","Epoch: 84, Steps: 32 | Train Loss: 0.4360713 Vali Loss: 0.2632149 Test Loss: 2.0396562\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 2.5849394142282115e-28\n","Epoch: 85 cost time: 1.44606351852417\n","Epoch: 85, Steps: 32 | Train Loss: 0.4373294 Vali Loss: 0.2711022 Test Loss: 2.0241618\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.2924697071141058e-28\n","Epoch: 86 cost time: 1.4549424648284912\n","Epoch: 86, Steps: 32 | Train Loss: 0.4423143 Vali Loss: 0.2618741 Test Loss: 2.0348058\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 6.462348535570529e-29\n","Epoch: 87 cost time: 1.520015001296997\n","Epoch: 87, Steps: 32 | Train Loss: 0.4372227 Vali Loss: 0.2640778 Test Loss: 2.0341053\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 3.2311742677852644e-29\n","Epoch: 88 cost time: 1.5142509937286377\n","Epoch: 88, Steps: 32 | Train Loss: 0.4384969 Vali Loss: 0.2684682 Test Loss: 2.0315657\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.6155871338926322e-29\n","Epoch: 89 cost time: 1.52298903465271\n","Epoch: 89, Steps: 32 | Train Loss: 0.4380982 Vali Loss: 0.2439826 Test Loss: 2.0110137\n","Validation loss decreased (0.247446 --> 0.243983).  Saving model ...\n","Updating learning rate to 8.077935669463161e-30\n","Epoch: 90 cost time: 1.38130521774292\n","Epoch: 90, Steps: 32 | Train Loss: 0.4388239 Vali Loss: 0.2623271 Test Loss: 2.0242951\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.0389678347315805e-30\n","Epoch: 91 cost time: 1.3773548603057861\n","Epoch: 91, Steps: 32 | Train Loss: 0.4376475 Vali Loss: 0.2640866 Test Loss: 2.0331442\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.0194839173657903e-30\n","Epoch: 92 cost time: 1.371971607208252\n","Epoch: 92, Steps: 32 | Train Loss: 0.4391488 Vali Loss: 0.2603485 Test Loss: 2.0334249\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.0097419586828951e-30\n","Epoch: 93 cost time: 1.4321789741516113\n","Epoch: 93, Steps: 32 | Train Loss: 0.4358815 Vali Loss: 0.2611626 Test Loss: 2.0240602\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 5.048709793414476e-31\n","Epoch: 94 cost time: 1.5145976543426514\n","Epoch: 94, Steps: 32 | Train Loss: 0.4371903 Vali Loss: 0.2463094 Test Loss: 2.0222745\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.524354896707238e-31\n","Epoch: 95 cost time: 1.4567835330963135\n","Epoch: 95, Steps: 32 | Train Loss: 0.4314780 Vali Loss: 0.2743463 Test Loss: 2.0196490\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.262177448353619e-31\n","Epoch: 96 cost time: 1.4515223503112793\n","Epoch: 96, Steps: 32 | Train Loss: 0.4385294 Vali Loss: 0.2528535 Test Loss: 2.0350595\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 6.310887241768095e-32\n","Epoch: 97 cost time: 1.4480268955230713\n","Epoch: 97, Steps: 32 | Train Loss: 0.4372018 Vali Loss: 0.2611369 Test Loss: 2.0479889\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.1554436208840473e-32\n","Epoch: 98 cost time: 1.397062063217163\n","Epoch: 98, Steps: 32 | Train Loss: 0.4380848 Vali Loss: 0.2622885 Test Loss: 2.0328472\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.5777218104420236e-32\n","Epoch: 99 cost time: 1.499344825744629\n","Epoch: 99, Steps: 32 | Train Loss: 0.4387954 Vali Loss: 0.2695633 Test Loss: 2.0396609\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 7.888609052210118e-33\n","Epoch: 100 cost time: 1.377997636795044\n","Epoch: 100, Steps: 32 | Train Loss: 0.4390954 Vali Loss: 0.2582712 Test Loss: 2.0455775\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 3.944304526105059e-33\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl60_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 134\n","mse:2.0110137462615967, mae:0.9551602602005005, rse:0.6776297092437744\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl60_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","\n","\n","\n","\n","\n","\n"]}],"source":["arg_pred_len_list = [24, 36, 48, 60]\n","\n","for arg_pred_len in arg_pred_len_list:\n","  # prediction len 설정\n","\n","  args.pred_len = arg_pred_len\n","  Exp = Exp_Main\n","  print(\"Current Prediction Length : \", str(arg_pred_len))\n","  print(\"\\n\\n\\n\")\n","\n","  if args.is_training:\n","      for ii in range(args.itr):\n","          # setting record of experiments\n","          setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n","              args.model_id,\n","              args.model,\n","              args.data,\n","              args.features,\n","              args.seq_len,\n","              args.label_len,\n","              args.pred_len,\n","              args.d_model,\n","              args.n_heads,\n","              args.e_layers,\n","              args.d_layers,\n","              args.d_ff,\n","              args.factor,\n","              args.embed,\n","              args.distil,\n","              args.des,ii)\n","\n","          exp = Exp(args)  # set experiments\n","\n","          print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","          exp.train(setting)\n","\n","          print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","          exp.test(setting)\n","\n","          if args.do_predict:\n","              print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","              exp.predict(setting, True)\n","\n","          torch.cuda.empty_cache()\n","\n","          print(\"\\n\\n\\n\\n\\n\")\n","\n","  # 실험에서 사용되지 않는 경우.\n","  else:\n","      ii = 0\n","      setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n","                                                                                                  args.model,\n","                                                                                                  args.data,\n","                                                                                                  args.features,\n","                                                                                                  args.seq_len,\n","                                                                                                  args.label_len,\n","                                                                                                  args.pred_len,\n","                                                                                                  args.d_model,\n","                                                                                                  args.n_heads,\n","                                                                                                  args.e_layers,\n","                                                                                                  args.d_layers,\n","                                                                                                  args.d_ff,\n","                                                                                                  args.factor,\n","                                                                                                  args.embed,\n","                                                                                                  args.distil,\n","                                                                                                  args.des, ii)\n","\n","      exp = Exp(args)  # set experiments\n","      print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","      exp.test(setting, test=1)\n","      torch.cuda.empty_cache()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
