{"cells":[{"cell_type":"markdown","metadata":{},"source":["### 전체 실험 결과 표"]},{"cell_type":"markdown","metadata":{},"source":["![image](./Experiment_image.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NYRX3cQb-_T"},"outputs":[],"source":["import argparse\n","import os\n","import torch\n","from exp.exp_main import Exp_Main\n","import random\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"7vi_Isb9576r"},"source":["### ETTh1 데이터셋 실험"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1262778,"status":"ok","timestamp":1701027722975,"user":{"displayName":"박종현","userId":"16384752064104668219"},"user_tz":-540},"id":"-Sv7kqlMcG3t","outputId":"f7aa1e43-cd7c-4e65-ff71-9c0de2c78f4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","Use GPU: cuda:0\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl96_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 8209\n","val 2785\n","test 2785\n","Epoch: 1 cost time: 5.217586994171143\n","Epoch: 1, Steps: 64 | Train Loss: 0.7404664 Vali Loss: 1.4723815 Test Loss: 0.8135934\n","Validation loss decreased (inf --> 1.472381).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 1.4147963523864746\n","Epoch: 2, Steps: 64 | Train Loss: 0.5739448 Vali Loss: 0.8930840 Test Loss: 0.4752970\n","Validation loss decreased (1.472381 --> 0.893084).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 1.364166259765625\n","Epoch: 3, Steps: 64 | Train Loss: 0.4709831 Vali Loss: 0.8122665 Test Loss: 0.4430701\n","Validation loss decreased (0.893084 --> 0.812266).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 1.5190579891204834\n","Epoch: 4, Steps: 64 | Train Loss: 0.4497084 Vali Loss: 0.7924042 Test Loss: 0.4346228\n","Validation loss decreased (0.812266 --> 0.792404).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 1.3872957229614258\n","Epoch: 5, Steps: 64 | Train Loss: 0.4412201 Vali Loss: 0.7799913 Test Loss: 0.4309975\n","Validation loss decreased (0.792404 --> 0.779991).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 1.4087951183319092\n","Epoch: 6, Steps: 64 | Train Loss: 0.4374674 Vali Loss: 0.7744005 Test Loss: 0.4292551\n","Validation loss decreased (0.779991 --> 0.774401).  Saving model ...\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 1.4042694568634033\n","Epoch: 7, Steps: 64 | Train Loss: 0.4358634 Vali Loss: 0.7725437 Test Loss: 0.4283787\n","Validation loss decreased (0.774401 --> 0.772544).  Saving model ...\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 1.4319894313812256\n","Epoch: 8, Steps: 64 | Train Loss: 0.4345791 Vali Loss: 0.7704663 Test Loss: 0.4279162\n","Validation loss decreased (0.772544 --> 0.770466).  Saving model ...\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 1.5647203922271729\n","Epoch: 9, Steps: 64 | Train Loss: 0.4343358 Vali Loss: 0.7701163 Test Loss: 0.4277495\n","Validation loss decreased (0.770466 --> 0.770116).  Saving model ...\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 1.448683500289917\n","Epoch: 10, Steps: 64 | Train Loss: 0.4339545 Vali Loss: 0.7679031 Test Loss: 0.4276408\n","Validation loss decreased (0.770116 --> 0.767903).  Saving model ...\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 1.4279899597167969\n","Epoch: 11, Steps: 64 | Train Loss: 0.4338405 Vali Loss: 0.7725194 Test Loss: 0.4276307\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 1.3547985553741455\n","Epoch: 12, Steps: 64 | Train Loss: 0.4338569 Vali Loss: 0.7625846 Test Loss: 0.4274939\n","Validation loss decreased (0.767903 --> 0.762585).  Saving model ...\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 1.414870023727417\n","Epoch: 13, Steps: 64 | Train Loss: 0.4335969 Vali Loss: 0.7723597 Test Loss: 0.4275071\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 1.481328010559082\n","Epoch: 14, Steps: 64 | Train Loss: 0.4332980 Vali Loss: 0.7730165 Test Loss: 0.4275516\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 1.4605772495269775\n","Epoch: 15, Steps: 64 | Train Loss: 0.4335456 Vali Loss: 0.7699968 Test Loss: 0.4274113\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 1.3794405460357666\n","Epoch: 16, Steps: 64 | Train Loss: 0.4334796 Vali Loss: 0.7690060 Test Loss: 0.4275263\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 1.3573026657104492\n","Epoch: 17, Steps: 64 | Train Loss: 0.4333885 Vali Loss: 0.7714328 Test Loss: 0.4274641\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 1.4121694564819336\n","Epoch: 18, Steps: 64 | Train Loss: 0.4333468 Vali Loss: 0.7676719 Test Loss: 0.4274859\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 1.4540607929229736\n","Epoch: 19, Steps: 64 | Train Loss: 0.4331761 Vali Loss: 0.7745031 Test Loss: 0.4274478\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 1.5273983478546143\n","Epoch: 20, Steps: 64 | Train Loss: 0.4338132 Vali Loss: 0.7716935 Test Loss: 0.4275024\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 1.3816914558410645\n","Epoch: 21, Steps: 64 | Train Loss: 0.4337759 Vali Loss: 0.7757373 Test Loss: 0.4274895\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 1.4070188999176025\n","Epoch: 22, Steps: 64 | Train Loss: 0.4337533 Vali Loss: 0.7713112 Test Loss: 0.4274781\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 1.3968579769134521\n","Epoch: 23, Steps: 64 | Train Loss: 0.4336263 Vali Loss: 0.7720426 Test Loss: 0.4274443\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 1.3476290702819824\n","Epoch: 24, Steps: 64 | Train Loss: 0.4335779 Vali Loss: 0.7736568 Test Loss: 0.4274399\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 1.4267151355743408\n","Epoch: 25, Steps: 64 | Train Loss: 0.4334212 Vali Loss: 0.7674748 Test Loss: 0.4274549\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 1.4584262371063232\n","Epoch: 26, Steps: 64 | Train Loss: 0.4336899 Vali Loss: 0.7708247 Test Loss: 0.4274303\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 1.4284989833831787\n","Epoch: 27, Steps: 64 | Train Loss: 0.4336119 Vali Loss: 0.7723203 Test Loss: 0.4275188\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 1.3851912021636963\n","Epoch: 28, Steps: 64 | Train Loss: 0.4332996 Vali Loss: 0.7678254 Test Loss: 0.4275347\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 1.393681287765503\n","Epoch: 29, Steps: 64 | Train Loss: 0.4337267 Vali Loss: 0.7734098 Test Loss: 0.4275000\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 1.4649264812469482\n","Epoch: 30, Steps: 64 | Train Loss: 0.4331806 Vali Loss: 0.7728082 Test Loss: 0.4274619\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 1.4911634922027588\n","Epoch: 31, Steps: 64 | Train Loss: 0.4331128 Vali Loss: 0.7691496 Test Loss: 0.4275133\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 1.4131999015808105\n","Epoch: 32, Steps: 64 | Train Loss: 0.4335914 Vali Loss: 0.7701881 Test Loss: 0.4274970\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 1.482534408569336\n","Epoch: 33, Steps: 64 | Train Loss: 0.4332063 Vali Loss: 0.7733628 Test Loss: 0.4274874\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 1.4407110214233398\n","Epoch: 34, Steps: 64 | Train Loss: 0.4339639 Vali Loss: 0.7694756 Test Loss: 0.4275338\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 1.4333491325378418\n","Epoch: 35, Steps: 64 | Train Loss: 0.4331847 Vali Loss: 0.7736553 Test Loss: 0.4274424\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 1.5079779624938965\n","Epoch: 36, Steps: 64 | Train Loss: 0.4333968 Vali Loss: 0.7711733 Test Loss: 0.4274162\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 1.4050548076629639\n","Epoch: 37, Steps: 64 | Train Loss: 0.4334001 Vali Loss: 0.7727684 Test Loss: 0.4275104\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 1.398956298828125\n","Epoch: 38, Steps: 64 | Train Loss: 0.4339023 Vali Loss: 0.7680808 Test Loss: 0.4274801\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 1.425849437713623\n","Epoch: 39, Steps: 64 | Train Loss: 0.4335066 Vali Loss: 0.7717937 Test Loss: 0.4274876\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 1.3627996444702148\n","Epoch: 40, Steps: 64 | Train Loss: 0.4333133 Vali Loss: 0.7727219 Test Loss: 0.4274903\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 1.458188533782959\n","Epoch: 41, Steps: 64 | Train Loss: 0.4340060 Vali Loss: 0.7713007 Test Loss: 0.4275028\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 1.492798089981079\n","Epoch: 42, Steps: 64 | Train Loss: 0.4338701 Vali Loss: 0.7708579 Test Loss: 0.4274307\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 1.4066016674041748\n","Epoch: 43, Steps: 64 | Train Loss: 0.4331340 Vali Loss: 0.7730308 Test Loss: 0.4275245\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 1.413860559463501\n","Epoch: 44, Steps: 64 | Train Loss: 0.4338967 Vali Loss: 0.7702073 Test Loss: 0.4274864\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 1.4512362480163574\n","Epoch: 45, Steps: 64 | Train Loss: 0.4335327 Vali Loss: 0.7730982 Test Loss: 0.4274787\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 1.5423383712768555\n","Epoch: 46, Steps: 64 | Train Loss: 0.4335327 Vali Loss: 0.7684831 Test Loss: 0.4275080\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 1.4185047149658203\n","Epoch: 47, Steps: 64 | Train Loss: 0.4333240 Vali Loss: 0.7721401 Test Loss: 0.4274700\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 1.3861668109893799\n","Epoch: 48, Steps: 64 | Train Loss: 0.4336911 Vali Loss: 0.7714093 Test Loss: 0.4274753\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 1.399860143661499\n","Epoch: 49, Steps: 64 | Train Loss: 0.4332709 Vali Loss: 0.7723151 Test Loss: 0.4274839\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 1.445784330368042\n","Epoch: 50, Steps: 64 | Train Loss: 0.4337011 Vali Loss: 0.7682405 Test Loss: 0.4275199\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 1.5022425651550293\n","Epoch: 51, Steps: 64 | Train Loss: 0.4338951 Vali Loss: 0.7690644 Test Loss: 0.4274307\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 1.5076894760131836\n","Epoch: 52, Steps: 64 | Train Loss: 0.4338503 Vali Loss: 0.7725064 Test Loss: 0.4274830\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 1.4043846130371094\n","Epoch: 53, Steps: 64 | Train Loss: 0.4335715 Vali Loss: 0.7678323 Test Loss: 0.4274869\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 1.4440197944641113\n","Epoch: 54, Steps: 64 | Train Loss: 0.4331790 Vali Loss: 0.7683228 Test Loss: 0.4275450\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 1.373140573501587\n","Epoch: 55, Steps: 64 | Train Loss: 0.4338131 Vali Loss: 0.7741051 Test Loss: 0.4274508\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 1.4600830078125\n","Epoch: 56, Steps: 64 | Train Loss: 0.4335604 Vali Loss: 0.7695713 Test Loss: 0.4275473\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 1.5393123626708984\n","Epoch: 57, Steps: 64 | Train Loss: 0.4335868 Vali Loss: 0.7689002 Test Loss: 0.4274749\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 1.4467217922210693\n","Epoch: 58, Steps: 64 | Train Loss: 0.4337097 Vali Loss: 0.7711461 Test Loss: 0.4274167\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 1.412416696548462\n","Epoch: 59, Steps: 64 | Train Loss: 0.4335725 Vali Loss: 0.7722667 Test Loss: 0.4275607\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 1.3865759372711182\n","Epoch: 60, Steps: 64 | Train Loss: 0.4335927 Vali Loss: 0.7693235 Test Loss: 0.4274783\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 1.459324598312378\n","Epoch: 61, Steps: 64 | Train Loss: 0.4338506 Vali Loss: 0.7736061 Test Loss: 0.4274368\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 1.5569617748260498\n","Epoch: 62, Steps: 64 | Train Loss: 0.4334591 Vali Loss: 0.7712919 Test Loss: 0.4274042\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 1.4402415752410889\n","Epoch: 63, Steps: 64 | Train Loss: 0.4334781 Vali Loss: 0.7730947 Test Loss: 0.4274659\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 1.438450813293457\n","Epoch: 64, Steps: 64 | Train Loss: 0.4338082 Vali Loss: 0.7701188 Test Loss: 0.4274704\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 1.4041073322296143\n","Epoch: 65, Steps: 64 | Train Loss: 0.4338698 Vali Loss: 0.7679471 Test Loss: 0.4274786\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 1.422222375869751\n","Epoch: 66, Steps: 64 | Train Loss: 0.4335894 Vali Loss: 0.7706289 Test Loss: 0.4275286\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 1.5855836868286133\n","Epoch: 67, Steps: 64 | Train Loss: 0.4328272 Vali Loss: 0.7693551 Test Loss: 0.4274954\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 1.5083298683166504\n","Epoch: 68, Steps: 64 | Train Loss: 0.4333374 Vali Loss: 0.7730458 Test Loss: 0.4274781\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 1.436772108078003\n","Epoch: 69, Steps: 64 | Train Loss: 0.4334466 Vali Loss: 0.7739550 Test Loss: 0.4275720\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 1.4245531558990479\n","Epoch: 70, Steps: 64 | Train Loss: 0.4332059 Vali Loss: 0.7728155 Test Loss: 0.4275190\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 1.4589662551879883\n","Epoch: 71, Steps: 64 | Train Loss: 0.4336232 Vali Loss: 0.7740195 Test Loss: 0.4274391\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 1.4967529773712158\n","Epoch: 72, Steps: 64 | Train Loss: 0.4334432 Vali Loss: 0.7722694 Test Loss: 0.4274593\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 1.4969842433929443\n","Epoch: 73, Steps: 64 | Train Loss: 0.4334562 Vali Loss: 0.7729231 Test Loss: 0.4274823\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 1.3986823558807373\n","Epoch: 74, Steps: 64 | Train Loss: 0.4333117 Vali Loss: 0.7734722 Test Loss: 0.4274746\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 1.4179556369781494\n","Epoch: 75, Steps: 64 | Train Loss: 0.4337272 Vali Loss: 0.7698746 Test Loss: 0.4274921\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 1.4078943729400635\n","Epoch: 76, Steps: 64 | Train Loss: 0.4332550 Vali Loss: 0.7718394 Test Loss: 0.4275156\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 1.4992430210113525\n","Epoch: 77, Steps: 64 | Train Loss: 0.4335832 Vali Loss: 0.7706323 Test Loss: 0.4274654\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 1.5118496417999268\n","Epoch: 78, Steps: 64 | Train Loss: 0.4337149 Vali Loss: 0.7691496 Test Loss: 0.4273553\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 1.3884356021881104\n","Epoch: 79, Steps: 64 | Train Loss: 0.4338706 Vali Loss: 0.7713347 Test Loss: 0.4274499\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 1.411109447479248\n","Epoch: 80, Steps: 64 | Train Loss: 0.4337373 Vali Loss: 0.7709137 Test Loss: 0.4274920\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 1.4058756828308105\n","Epoch: 81, Steps: 64 | Train Loss: 0.4334901 Vali Loss: 0.7715096 Test Loss: 0.4274817\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 1.5546762943267822\n","Epoch: 82, Steps: 64 | Train Loss: 0.4335454 Vali Loss: 0.7719472 Test Loss: 0.4275030\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 1.5261731147766113\n","Epoch: 83, Steps: 64 | Train Loss: 0.4333302 Vali Loss: 0.7695838 Test Loss: 0.4275196\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 1.4043354988098145\n","Epoch: 84, Steps: 64 | Train Loss: 0.4333763 Vali Loss: 0.7748567 Test Loss: 0.4275443\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 1.413374900817871\n","Epoch: 85, Steps: 64 | Train Loss: 0.4332577 Vali Loss: 0.7695796 Test Loss: 0.4274819\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 1.4069254398345947\n","Epoch: 86, Steps: 64 | Train Loss: 0.4333995 Vali Loss: 0.7712401 Test Loss: 0.4274877\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 1.4772629737854004\n","Epoch: 87, Steps: 64 | Train Loss: 0.4333360 Vali Loss: 0.7669348 Test Loss: 0.4274513\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 1.5150341987609863\n","Epoch: 88, Steps: 64 | Train Loss: 0.4333943 Vali Loss: 0.7731569 Test Loss: 0.4274687\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 1.480987787246704\n","Epoch: 89, Steps: 64 | Train Loss: 0.4334767 Vali Loss: 0.7701470 Test Loss: 0.4274808\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 1.4370083808898926\n","Epoch: 90, Steps: 64 | Train Loss: 0.4335164 Vali Loss: 0.7713711 Test Loss: 0.4275130\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 1.4603252410888672\n","Epoch: 91, Steps: 64 | Train Loss: 0.4338923 Vali Loss: 0.7700835 Test Loss: 0.4273961\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 1.4746043682098389\n","Epoch: 92, Steps: 64 | Train Loss: 0.4330203 Vali Loss: 0.7699101 Test Loss: 0.4274565\n","EarlyStopping counter: 80 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 1.5149312019348145\n","Epoch: 93, Steps: 64 | Train Loss: 0.4334077 Vali Loss: 0.7719439 Test Loss: 0.4274908\n","EarlyStopping counter: 81 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 1.4634435176849365\n","Epoch: 94, Steps: 64 | Train Loss: 0.4333823 Vali Loss: 0.7747266 Test Loss: 0.4275042\n","EarlyStopping counter: 82 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 1.5103890895843506\n","Epoch: 95, Steps: 64 | Train Loss: 0.4338845 Vali Loss: 0.7689112 Test Loss: 0.4274503\n","EarlyStopping counter: 83 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 1.4001970291137695\n","Epoch: 96, Steps: 64 | Train Loss: 0.4331019 Vali Loss: 0.7695252 Test Loss: 0.4274580\n","EarlyStopping counter: 84 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 1.4858496189117432\n","Epoch: 97, Steps: 64 | Train Loss: 0.4335297 Vali Loss: 0.7702987 Test Loss: 0.4274718\n","EarlyStopping counter: 85 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 1.5466337203979492\n","Epoch: 98, Steps: 64 | Train Loss: 0.4334450 Vali Loss: 0.7704381 Test Loss: 0.4274763\n","EarlyStopping counter: 86 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 1.457568645477295\n","Epoch: 99, Steps: 64 | Train Loss: 0.4337290 Vali Loss: 0.7703566 Test Loss: 0.4274656\n","EarlyStopping counter: 87 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 1.4371352195739746\n","Epoch: 100, Steps: 64 | Train Loss: 0.4335194 Vali Loss: 0.7695910 Test Loss: 0.4274878\n","EarlyStopping counter: 88 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl96_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2785\n","mse:0.42749401926994324, mae:0.43664199113845825, rse:0.619983971118927\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl96_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","Use GPU: cuda:0\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 8113\n","val 2689\n","test 2689\n","Epoch: 1 cost time: 1.5615012645721436\n","Epoch: 1, Steps: 63 | Train Loss: 0.7549401 Vali Loss: 1.5632818 Test Loss: 0.7854514\n","Validation loss decreased (inf --> 1.563282).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 1.5527620315551758\n","Epoch: 2, Steps: 63 | Train Loss: 0.6083873 Vali Loss: 1.0964661 Test Loss: 0.5115626\n","Validation loss decreased (1.563282 --> 1.096466).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 1.465261459350586\n","Epoch: 3, Steps: 63 | Train Loss: 0.5156879 Vali Loss: 1.0314471 Test Loss: 0.4782634\n","Validation loss decreased (1.096466 --> 1.031447).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 1.508458137512207\n","Epoch: 4, Steps: 63 | Train Loss: 0.4947718 Vali Loss: 1.0116481 Test Loss: 0.4689921\n","Validation loss decreased (1.031447 --> 1.011648).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 1.4669530391693115\n","Epoch: 5, Steps: 63 | Train Loss: 0.4870312 Vali Loss: 1.0031099 Test Loss: 0.4649547\n","Validation loss decreased (1.011648 --> 1.003110).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 1.5387446880340576\n","Epoch: 6, Steps: 63 | Train Loss: 0.4827539 Vali Loss: 0.9988587 Test Loss: 0.4630477\n","Validation loss decreased (1.003110 --> 0.998859).  Saving model ...\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 1.5747778415679932\n","Epoch: 7, Steps: 63 | Train Loss: 0.4810479 Vali Loss: 0.9967405 Test Loss: 0.4621657\n","Validation loss decreased (0.998859 --> 0.996741).  Saving model ...\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 1.4365105628967285\n","Epoch: 8, Steps: 63 | Train Loss: 0.4803690 Vali Loss: 0.9958704 Test Loss: 0.4615915\n","Validation loss decreased (0.996741 --> 0.995870).  Saving model ...\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 1.4787259101867676\n","Epoch: 9, Steps: 63 | Train Loss: 0.4794922 Vali Loss: 0.9958916 Test Loss: 0.4614006\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 1.5173437595367432\n","Epoch: 10, Steps: 63 | Train Loss: 0.4797063 Vali Loss: 0.9952469 Test Loss: 0.4612701\n","Validation loss decreased (0.995870 --> 0.995247).  Saving model ...\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 1.6088101863861084\n","Epoch: 11, Steps: 63 | Train Loss: 0.4791868 Vali Loss: 0.9954744 Test Loss: 0.4612120\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 1.4622840881347656\n","Epoch: 12, Steps: 63 | Train Loss: 0.4793298 Vali Loss: 0.9949816 Test Loss: 0.4611725\n","Validation loss decreased (0.995247 --> 0.994982).  Saving model ...\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 1.4613916873931885\n","Epoch: 13, Steps: 63 | Train Loss: 0.4793742 Vali Loss: 0.9953825 Test Loss: 0.4611738\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 1.487018346786499\n","Epoch: 14, Steps: 63 | Train Loss: 0.4792415 Vali Loss: 0.9953694 Test Loss: 0.4611773\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 1.4985547065734863\n","Epoch: 15, Steps: 63 | Train Loss: 0.4794861 Vali Loss: 0.9949105 Test Loss: 0.4611683\n","Validation loss decreased (0.994982 --> 0.994910).  Saving model ...\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 1.5489568710327148\n","Epoch: 16, Steps: 63 | Train Loss: 0.4790557 Vali Loss: 0.9952737 Test Loss: 0.4611144\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 1.5158045291900635\n","Epoch: 17, Steps: 63 | Train Loss: 0.4792122 Vali Loss: 0.9952435 Test Loss: 0.4611707\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 1.4563870429992676\n","Epoch: 18, Steps: 63 | Train Loss: 0.4794571 Vali Loss: 0.9952049 Test Loss: 0.4612131\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 1.5665860176086426\n","Epoch: 19, Steps: 63 | Train Loss: 0.4790981 Vali Loss: 0.9947427 Test Loss: 0.4611933\n","Validation loss decreased (0.994910 --> 0.994743).  Saving model ...\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 1.5146477222442627\n","Epoch: 20, Steps: 63 | Train Loss: 0.4792548 Vali Loss: 0.9954259 Test Loss: 0.4611201\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 1.5914785861968994\n","Epoch: 21, Steps: 63 | Train Loss: 0.4793011 Vali Loss: 0.9949136 Test Loss: 0.4611590\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 1.5279929637908936\n","Epoch: 22, Steps: 63 | Train Loss: 0.4790927 Vali Loss: 0.9949265 Test Loss: 0.4611017\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 1.5134403705596924\n","Epoch: 23, Steps: 63 | Train Loss: 0.4790427 Vali Loss: 0.9952122 Test Loss: 0.4611693\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 1.4699420928955078\n","Epoch: 24, Steps: 63 | Train Loss: 0.4797258 Vali Loss: 0.9953540 Test Loss: 0.4611626\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 1.5640983581542969\n","Epoch: 25, Steps: 63 | Train Loss: 0.4790040 Vali Loss: 0.9954649 Test Loss: 0.4611726\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 1.6248843669891357\n","Epoch: 26, Steps: 63 | Train Loss: 0.4792709 Vali Loss: 0.9947715 Test Loss: 0.4611619\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 1.5637500286102295\n","Epoch: 27, Steps: 63 | Train Loss: 0.4794319 Vali Loss: 0.9950978 Test Loss: 0.4611438\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 1.4730422496795654\n","Epoch: 28, Steps: 63 | Train Loss: 0.4790300 Vali Loss: 0.9954142 Test Loss: 0.4612181\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 1.4615190029144287\n","Epoch: 29, Steps: 63 | Train Loss: 0.4789563 Vali Loss: 0.9953701 Test Loss: 0.4611849\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 1.5503253936767578\n","Epoch: 30, Steps: 63 | Train Loss: 0.4790719 Vali Loss: 0.9949769 Test Loss: 0.4611662\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 1.4914865493774414\n","Epoch: 31, Steps: 63 | Train Loss: 0.4792664 Vali Loss: 0.9951716 Test Loss: 0.4611186\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 1.456822395324707\n","Epoch: 32, Steps: 63 | Train Loss: 0.4789238 Vali Loss: 0.9952151 Test Loss: 0.4611744\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 1.446779489517212\n","Epoch: 33, Steps: 63 | Train Loss: 0.4792599 Vali Loss: 0.9948629 Test Loss: 0.4611499\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 1.469245433807373\n","Epoch: 34, Steps: 63 | Train Loss: 0.4792817 Vali Loss: 0.9953508 Test Loss: 0.4611751\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 1.5575783252716064\n","Epoch: 35, Steps: 63 | Train Loss: 0.4795335 Vali Loss: 0.9949582 Test Loss: 0.4611524\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 1.470245361328125\n","Epoch: 36, Steps: 63 | Train Loss: 0.4792754 Vali Loss: 0.9954221 Test Loss: 0.4611879\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 1.5185635089874268\n","Epoch: 37, Steps: 63 | Train Loss: 0.4790654 Vali Loss: 0.9951694 Test Loss: 0.4611957\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 1.4875571727752686\n","Epoch: 38, Steps: 63 | Train Loss: 0.4793355 Vali Loss: 0.9954450 Test Loss: 0.4610980\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 1.5154719352722168\n","Epoch: 39, Steps: 63 | Train Loss: 0.4787823 Vali Loss: 0.9953242 Test Loss: 0.4611540\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 1.6065983772277832\n","Epoch: 40, Steps: 63 | Train Loss: 0.4789650 Vali Loss: 0.9948894 Test Loss: 0.4611657\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 1.4723491668701172\n","Epoch: 41, Steps: 63 | Train Loss: 0.4788806 Vali Loss: 0.9952376 Test Loss: 0.4611152\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 1.4424355030059814\n","Epoch: 42, Steps: 63 | Train Loss: 0.4796891 Vali Loss: 0.9949357 Test Loss: 0.4611393\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 1.4860219955444336\n","Epoch: 43, Steps: 63 | Train Loss: 0.4792196 Vali Loss: 0.9954339 Test Loss: 0.4611555\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 1.6438097953796387\n","Epoch: 44, Steps: 63 | Train Loss: 0.4793497 Vali Loss: 0.9952474 Test Loss: 0.4611193\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 1.5609722137451172\n","Epoch: 45, Steps: 63 | Train Loss: 0.4794552 Vali Loss: 0.9953738 Test Loss: 0.4612161\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 1.539297103881836\n","Epoch: 46, Steps: 63 | Train Loss: 0.4793325 Vali Loss: 0.9952793 Test Loss: 0.4611561\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 1.487025260925293\n","Epoch: 47, Steps: 63 | Train Loss: 0.4787795 Vali Loss: 0.9949443 Test Loss: 0.4611844\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 1.5366849899291992\n","Epoch: 48, Steps: 63 | Train Loss: 0.4794782 Vali Loss: 0.9952605 Test Loss: 0.4611813\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 1.5334274768829346\n","Epoch: 49, Steps: 63 | Train Loss: 0.4796966 Vali Loss: 0.9947562 Test Loss: 0.4611812\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 1.556210994720459\n","Epoch: 50, Steps: 63 | Train Loss: 0.4798665 Vali Loss: 0.9951432 Test Loss: 0.4611422\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 1.5020883083343506\n","Epoch: 51, Steps: 63 | Train Loss: 0.4793076 Vali Loss: 0.9951075 Test Loss: 0.4611124\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 1.4912278652191162\n","Epoch: 52, Steps: 63 | Train Loss: 0.4794234 Vali Loss: 0.9955424 Test Loss: 0.4611965\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 1.4756836891174316\n","Epoch: 53, Steps: 63 | Train Loss: 0.4792189 Vali Loss: 0.9950840 Test Loss: 0.4611575\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 1.5932090282440186\n","Epoch: 54, Steps: 63 | Train Loss: 0.4787254 Vali Loss: 0.9948619 Test Loss: 0.4611986\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 1.5898187160491943\n","Epoch: 55, Steps: 63 | Train Loss: 0.4792559 Vali Loss: 0.9953309 Test Loss: 0.4612147\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 1.5535006523132324\n","Epoch: 56, Steps: 63 | Train Loss: 0.4793517 Vali Loss: 0.9949743 Test Loss: 0.4611621\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 1.475494146347046\n","Epoch: 57, Steps: 63 | Train Loss: 0.4796349 Vali Loss: 0.9947612 Test Loss: 0.4611567\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 1.5069711208343506\n","Epoch: 58, Steps: 63 | Train Loss: 0.4788130 Vali Loss: 0.9950530 Test Loss: 0.4611835\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 1.6189570426940918\n","Epoch: 59, Steps: 63 | Train Loss: 0.4789853 Vali Loss: 0.9955030 Test Loss: 0.4611696\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 1.517496109008789\n","Epoch: 60, Steps: 63 | Train Loss: 0.4792832 Vali Loss: 0.9949315 Test Loss: 0.4611570\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 1.4945497512817383\n","Epoch: 61, Steps: 63 | Train Loss: 0.4785109 Vali Loss: 0.9947633 Test Loss: 0.4611521\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 1.456300973892212\n","Epoch: 62, Steps: 63 | Train Loss: 0.4796497 Vali Loss: 0.9952868 Test Loss: 0.4611804\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 1.5826048851013184\n","Epoch: 63, Steps: 63 | Train Loss: 0.4796164 Vali Loss: 0.9954147 Test Loss: 0.4611490\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 1.5706782341003418\n","Epoch: 64, Steps: 63 | Train Loss: 0.4790343 Vali Loss: 0.9955263 Test Loss: 0.4611356\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 1.4719624519348145\n","Epoch: 65, Steps: 63 | Train Loss: 0.4789621 Vali Loss: 0.9953393 Test Loss: 0.4611375\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 1.5265893936157227\n","Epoch: 66, Steps: 63 | Train Loss: 0.4791297 Vali Loss: 0.9950936 Test Loss: 0.4612370\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 1.5478160381317139\n","Epoch: 67, Steps: 63 | Train Loss: 0.4793978 Vali Loss: 0.9950526 Test Loss: 0.4611912\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 1.5917019844055176\n","Epoch: 68, Steps: 63 | Train Loss: 0.4789407 Vali Loss: 0.9953721 Test Loss: 0.4611498\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 1.4940247535705566\n","Epoch: 69, Steps: 63 | Train Loss: 0.4795058 Vali Loss: 0.9953648 Test Loss: 0.4611660\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 1.5189120769500732\n","Epoch: 70, Steps: 63 | Train Loss: 0.4792439 Vali Loss: 0.9951831 Test Loss: 0.4611387\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 1.5424785614013672\n","Epoch: 71, Steps: 63 | Train Loss: 0.4794423 Vali Loss: 0.9954131 Test Loss: 0.4611590\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 1.655867099761963\n","Epoch: 72, Steps: 63 | Train Loss: 0.4792348 Vali Loss: 0.9953116 Test Loss: 0.4611707\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 1.6625843048095703\n","Epoch: 73, Steps: 63 | Train Loss: 0.4792627 Vali Loss: 0.9951796 Test Loss: 0.4612250\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 1.4709324836730957\n","Epoch: 74, Steps: 63 | Train Loss: 0.4794943 Vali Loss: 0.9952916 Test Loss: 0.4611199\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 1.4826889038085938\n","Epoch: 75, Steps: 63 | Train Loss: 0.4790741 Vali Loss: 0.9954202 Test Loss: 0.4611023\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 1.5315124988555908\n","Epoch: 76, Steps: 63 | Train Loss: 0.4792128 Vali Loss: 0.9949521 Test Loss: 0.4611382\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 1.6322340965270996\n","Epoch: 77, Steps: 63 | Train Loss: 0.4794330 Vali Loss: 0.9952397 Test Loss: 0.4611830\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 1.61501145362854\n","Epoch: 78, Steps: 63 | Train Loss: 0.4791391 Vali Loss: 0.9953575 Test Loss: 0.4611520\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 1.4998326301574707\n","Epoch: 79, Steps: 63 | Train Loss: 0.4794237 Vali Loss: 0.9954112 Test Loss: 0.4612205\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 1.528540849685669\n","Epoch: 80, Steps: 63 | Train Loss: 0.4790230 Vali Loss: 0.9948396 Test Loss: 0.4611458\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 1.5148191452026367\n","Epoch: 81, Steps: 63 | Train Loss: 0.4791282 Vali Loss: 0.9951724 Test Loss: 0.4611372\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 1.586618423461914\n","Epoch: 82, Steps: 63 | Train Loss: 0.4790352 Vali Loss: 0.9948727 Test Loss: 0.4611928\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 1.5330195426940918\n","Epoch: 83, Steps: 63 | Train Loss: 0.4794737 Vali Loss: 0.9949310 Test Loss: 0.4612203\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 1.4531505107879639\n","Epoch: 84, Steps: 63 | Train Loss: 0.4793665 Vali Loss: 0.9948621 Test Loss: 0.4611136\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 1.4969079494476318\n","Epoch: 85, Steps: 63 | Train Loss: 0.4791342 Vali Loss: 0.9953296 Test Loss: 0.4611462\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 1.5594325065612793\n","Epoch: 86, Steps: 63 | Train Loss: 0.4789225 Vali Loss: 0.9949863 Test Loss: 0.4611534\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 1.5741071701049805\n","Epoch: 87, Steps: 63 | Train Loss: 0.4793011 Vali Loss: 0.9951922 Test Loss: 0.4611201\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 1.5425677299499512\n","Epoch: 88, Steps: 63 | Train Loss: 0.4791749 Vali Loss: 0.9954049 Test Loss: 0.4611560\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 1.4715874195098877\n","Epoch: 89, Steps: 63 | Train Loss: 0.4795604 Vali Loss: 0.9954674 Test Loss: 0.4611931\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 1.4395787715911865\n","Epoch: 90, Steps: 63 | Train Loss: 0.4791697 Vali Loss: 0.9952384 Test Loss: 0.4610636\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 1.5284059047698975\n","Epoch: 91, Steps: 63 | Train Loss: 0.4793043 Vali Loss: 0.9949383 Test Loss: 0.4611940\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 1.5796689987182617\n","Epoch: 92, Steps: 63 | Train Loss: 0.4789568 Vali Loss: 0.9954020 Test Loss: 0.4611455\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 1.49232816696167\n","Epoch: 93, Steps: 63 | Train Loss: 0.4790048 Vali Loss: 0.9953939 Test Loss: 0.4611122\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 1.51027512550354\n","Epoch: 94, Steps: 63 | Train Loss: 0.4793064 Vali Loss: 0.9954075 Test Loss: 0.4611755\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 1.5266783237457275\n","Epoch: 95, Steps: 63 | Train Loss: 0.4792643 Vali Loss: 0.9951066 Test Loss: 0.4611653\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 1.6311988830566406\n","Epoch: 96, Steps: 63 | Train Loss: 0.4796718 Vali Loss: 0.9953097 Test Loss: 0.4611519\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 1.5100014209747314\n","Epoch: 97, Steps: 63 | Train Loss: 0.4797988 Vali Loss: 0.9951061 Test Loss: 0.4611621\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 1.552506446838379\n","Epoch: 98, Steps: 63 | Train Loss: 0.4794316 Vali Loss: 0.9953473 Test Loss: 0.4611511\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 1.4805982112884521\n","Epoch: 99, Steps: 63 | Train Loss: 0.4792804 Vali Loss: 0.9949323 Test Loss: 0.4611638\n","EarlyStopping counter: 80 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 1.5859315395355225\n","Epoch: 100, Steps: 63 | Train Loss: 0.4788390 Vali Loss: 0.9950617 Test Loss: 0.4611751\n","EarlyStopping counter: 81 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2689\n","mse:0.46119317412376404, mae:0.4560082256793976, rse:0.6449010968208313\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","Use GPU: cuda:0\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 7969\n","val 2545\n","test 2545\n","Epoch: 1 cost time: 1.5384762287139893\n","Epoch: 1, Steps: 62 | Train Loss: 0.8033972 Vali Loss: 1.7082218 Test Loss: 0.7641666\n","Validation loss decreased (inf --> 1.708222).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 1.550567865371704\n","Epoch: 2, Steps: 62 | Train Loss: 0.6630183 Vali Loss: 1.3030787 Test Loss: 0.5161726\n","Validation loss decreased (1.708222 --> 1.303079).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 1.536555528640747\n","Epoch: 3, Steps: 62 | Train Loss: 0.5775634 Vali Loss: 1.2523789 Test Loss: 0.4810620\n","Validation loss decreased (1.303079 --> 1.252379).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 1.6123623847961426\n","Epoch: 4, Steps: 62 | Train Loss: 0.5552729 Vali Loss: 1.2342739 Test Loss: 0.4713572\n","Validation loss decreased (1.252379 --> 1.234274).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 1.611391305923462\n","Epoch: 5, Steps: 62 | Train Loss: 0.5461338 Vali Loss: 1.2324787 Test Loss: 0.4671475\n","Validation loss decreased (1.234274 --> 1.232479).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 1.5190160274505615\n","Epoch: 6, Steps: 62 | Train Loss: 0.5419822 Vali Loss: 1.2352642 Test Loss: 0.4650582\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 1.5370376110076904\n","Epoch: 7, Steps: 62 | Train Loss: 0.5403608 Vali Loss: 1.2264328 Test Loss: 0.4639790\n","Validation loss decreased (1.232479 --> 1.226433).  Saving model ...\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 1.5629312992095947\n","Epoch: 8, Steps: 62 | Train Loss: 0.5394820 Vali Loss: 1.2187599 Test Loss: 0.4635168\n","Validation loss decreased (1.226433 --> 1.218760).  Saving model ...\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 1.6296117305755615\n","Epoch: 9, Steps: 62 | Train Loss: 0.5389465 Vali Loss: 1.2280418 Test Loss: 0.4632846\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 1.5529026985168457\n","Epoch: 10, Steps: 62 | Train Loss: 0.5386489 Vali Loss: 1.2226982 Test Loss: 0.4631776\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 1.5640642642974854\n","Epoch: 11, Steps: 62 | Train Loss: 0.5386651 Vali Loss: 1.2219971 Test Loss: 0.4630824\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 1.5283913612365723\n","Epoch: 12, Steps: 62 | Train Loss: 0.5387997 Vali Loss: 1.2208580 Test Loss: 0.4630376\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 1.5860307216644287\n","Epoch: 13, Steps: 62 | Train Loss: 0.5383889 Vali Loss: 1.2265077 Test Loss: 0.4630221\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 1.602646827697754\n","Epoch: 14, Steps: 62 | Train Loss: 0.5385843 Vali Loss: 1.2206374 Test Loss: 0.4630243\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 1.5730688571929932\n","Epoch: 15, Steps: 62 | Train Loss: 0.5388491 Vali Loss: 1.2211772 Test Loss: 0.4630160\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 1.5166456699371338\n","Epoch: 16, Steps: 62 | Train Loss: 0.5389252 Vali Loss: 1.2214909 Test Loss: 0.4630511\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 1.5363373756408691\n","Epoch: 17, Steps: 62 | Train Loss: 0.5385490 Vali Loss: 1.2214520 Test Loss: 0.4631205\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 1.623375654220581\n","Epoch: 18, Steps: 62 | Train Loss: 0.5385824 Vali Loss: 1.2208221 Test Loss: 0.4630548\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 1.572387933731079\n","Epoch: 19, Steps: 62 | Train Loss: 0.5386424 Vali Loss: 1.2211754 Test Loss: 0.4629969\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 1.5594775676727295\n","Epoch: 20, Steps: 62 | Train Loss: 0.5382148 Vali Loss: 1.2196406 Test Loss: 0.4630129\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 1.5750682353973389\n","Epoch: 21, Steps: 62 | Train Loss: 0.5384019 Vali Loss: 1.2241923 Test Loss: 0.4630148\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 1.6516802310943604\n","Epoch: 22, Steps: 62 | Train Loss: 0.5385236 Vali Loss: 1.2214605 Test Loss: 0.4630320\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 1.646012783050537\n","Epoch: 23, Steps: 62 | Train Loss: 0.5385936 Vali Loss: 1.2238121 Test Loss: 0.4629568\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 1.5879743099212646\n","Epoch: 24, Steps: 62 | Train Loss: 0.5381102 Vali Loss: 1.2212329 Test Loss: 0.4630848\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 1.5847089290618896\n","Epoch: 25, Steps: 62 | Train Loss: 0.5385062 Vali Loss: 1.2233678 Test Loss: 0.4630975\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 1.6046862602233887\n","Epoch: 26, Steps: 62 | Train Loss: 0.5385928 Vali Loss: 1.2236781 Test Loss: 0.4630588\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 1.6937174797058105\n","Epoch: 27, Steps: 62 | Train Loss: 0.5383962 Vali Loss: 1.2225561 Test Loss: 0.4630337\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 1.557882308959961\n","Epoch: 28, Steps: 62 | Train Loss: 0.5385681 Vali Loss: 1.2233824 Test Loss: 0.4630657\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 1.5435190200805664\n","Epoch: 29, Steps: 62 | Train Loss: 0.5383196 Vali Loss: 1.2214041 Test Loss: 0.4630478\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 1.535538911819458\n","Epoch: 30, Steps: 62 | Train Loss: 0.5386687 Vali Loss: 1.2258254 Test Loss: 0.4629657\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 1.6784265041351318\n","Epoch: 31, Steps: 62 | Train Loss: 0.5385948 Vali Loss: 1.2180207 Test Loss: 0.4630443\n","Validation loss decreased (1.218760 --> 1.218021).  Saving model ...\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 1.578871726989746\n","Epoch: 32, Steps: 62 | Train Loss: 0.5383421 Vali Loss: 1.2262330 Test Loss: 0.4630533\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 1.5833420753479004\n","Epoch: 33, Steps: 62 | Train Loss: 0.5379895 Vali Loss: 1.2216018 Test Loss: 0.4629961\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 1.5732841491699219\n","Epoch: 34, Steps: 62 | Train Loss: 0.5384495 Vali Loss: 1.2199003 Test Loss: 0.4629860\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 1.6303458213806152\n","Epoch: 35, Steps: 62 | Train Loss: 0.5384599 Vali Loss: 1.2206328 Test Loss: 0.4630473\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 1.656512975692749\n","Epoch: 36, Steps: 62 | Train Loss: 0.5385073 Vali Loss: 1.2248783 Test Loss: 0.4629930\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 1.557300090789795\n","Epoch: 37, Steps: 62 | Train Loss: 0.5382666 Vali Loss: 1.2230232 Test Loss: 0.4630347\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 1.561617374420166\n","Epoch: 38, Steps: 62 | Train Loss: 0.5383510 Vali Loss: 1.2231872 Test Loss: 0.4629579\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 1.5088427066802979\n","Epoch: 39, Steps: 62 | Train Loss: 0.5377987 Vali Loss: 1.2216470 Test Loss: 0.4629701\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 1.6445050239562988\n","Epoch: 40, Steps: 62 | Train Loss: 0.5382063 Vali Loss: 1.2259015 Test Loss: 0.4629927\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 1.6052544116973877\n","Epoch: 41, Steps: 62 | Train Loss: 0.5387403 Vali Loss: 1.2182819 Test Loss: 0.4630159\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 1.511134147644043\n","Epoch: 42, Steps: 62 | Train Loss: 0.5385864 Vali Loss: 1.2279564 Test Loss: 0.4629631\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 1.5187256336212158\n","Epoch: 43, Steps: 62 | Train Loss: 0.5386266 Vali Loss: 1.2209740 Test Loss: 0.4630093\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 1.622469186782837\n","Epoch: 44, Steps: 62 | Train Loss: 0.5385354 Vali Loss: 1.2216144 Test Loss: 0.4630378\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 1.640484094619751\n","Epoch: 45, Steps: 62 | Train Loss: 0.5386635 Vali Loss: 1.2265134 Test Loss: 0.4630030\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 1.5607664585113525\n","Epoch: 46, Steps: 62 | Train Loss: 0.5386880 Vali Loss: 1.2151027 Test Loss: 0.4630258\n","Validation loss decreased (1.218021 --> 1.215103).  Saving model ...\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 1.5226719379425049\n","Epoch: 47, Steps: 62 | Train Loss: 0.5384338 Vali Loss: 1.2240076 Test Loss: 0.4629382\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 1.5403201580047607\n","Epoch: 48, Steps: 62 | Train Loss: 0.5384924 Vali Loss: 1.2185823 Test Loss: 0.4629465\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 1.6554508209228516\n","Epoch: 49, Steps: 62 | Train Loss: 0.5383224 Vali Loss: 1.2183433 Test Loss: 0.4630488\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 1.5372564792633057\n","Epoch: 50, Steps: 62 | Train Loss: 0.5386613 Vali Loss: 1.2228709 Test Loss: 0.4630215\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 1.607903242111206\n","Epoch: 51, Steps: 62 | Train Loss: 0.5383158 Vali Loss: 1.2226118 Test Loss: 0.4630958\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 1.5494673252105713\n","Epoch: 52, Steps: 62 | Train Loss: 0.5386614 Vali Loss: 1.2224569 Test Loss: 0.4629675\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 1.617891550064087\n","Epoch: 53, Steps: 62 | Train Loss: 0.5383589 Vali Loss: 1.2213063 Test Loss: 0.4630742\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 1.6803333759307861\n","Epoch: 54, Steps: 62 | Train Loss: 0.5383289 Vali Loss: 1.2249409 Test Loss: 0.4629626\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 1.5094592571258545\n","Epoch: 55, Steps: 62 | Train Loss: 0.5385264 Vali Loss: 1.2208687 Test Loss: 0.4630902\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 1.5265724658966064\n","Epoch: 56, Steps: 62 | Train Loss: 0.5387576 Vali Loss: 1.2237874 Test Loss: 0.4630410\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 1.5817012786865234\n","Epoch: 57, Steps: 62 | Train Loss: 0.5385048 Vali Loss: 1.2190436 Test Loss: 0.4630228\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 1.6352152824401855\n","Epoch: 58, Steps: 62 | Train Loss: 0.5383920 Vali Loss: 1.2208500 Test Loss: 0.4630395\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 1.5022964477539062\n","Epoch: 59, Steps: 62 | Train Loss: 0.5383912 Vali Loss: 1.2230455 Test Loss: 0.4630511\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 1.5413835048675537\n","Epoch: 60, Steps: 62 | Train Loss: 0.5384072 Vali Loss: 1.2296816 Test Loss: 0.4630263\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 1.6184453964233398\n","Epoch: 61, Steps: 62 | Train Loss: 0.5386990 Vali Loss: 1.2224959 Test Loss: 0.4629814\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 1.6181471347808838\n","Epoch: 62, Steps: 62 | Train Loss: 0.5383734 Vali Loss: 1.2234818 Test Loss: 0.4630384\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 1.6937131881713867\n","Epoch: 63, Steps: 62 | Train Loss: 0.5383877 Vali Loss: 1.2228378 Test Loss: 0.4630674\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 1.5480432510375977\n","Epoch: 64, Steps: 62 | Train Loss: 0.5384967 Vali Loss: 1.2204560 Test Loss: 0.4630816\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 1.524151086807251\n","Epoch: 65, Steps: 62 | Train Loss: 0.5384942 Vali Loss: 1.2248087 Test Loss: 0.4629953\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 1.5320839881896973\n","Epoch: 66, Steps: 62 | Train Loss: 0.5381847 Vali Loss: 1.2243220 Test Loss: 0.4629964\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 1.6816797256469727\n","Epoch: 67, Steps: 62 | Train Loss: 0.5383361 Vali Loss: 1.2189122 Test Loss: 0.4630130\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 1.5294153690338135\n","Epoch: 68, Steps: 62 | Train Loss: 0.5386606 Vali Loss: 1.2211120 Test Loss: 0.4629957\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 1.5011990070343018\n","Epoch: 69, Steps: 62 | Train Loss: 0.5387854 Vali Loss: 1.2238525 Test Loss: 0.4629440\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 1.535280466079712\n","Epoch: 70, Steps: 62 | Train Loss: 0.5386493 Vali Loss: 1.2221229 Test Loss: 0.4630176\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 1.6882810592651367\n","Epoch: 71, Steps: 62 | Train Loss: 0.5381873 Vali Loss: 1.2246706 Test Loss: 0.4630189\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 1.6264829635620117\n","Epoch: 72, Steps: 62 | Train Loss: 0.5384736 Vali Loss: 1.2244142 Test Loss: 0.4629619\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 1.572859764099121\n","Epoch: 73, Steps: 62 | Train Loss: 0.5386626 Vali Loss: 1.2186711 Test Loss: 0.4630466\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 1.5491528511047363\n","Epoch: 74, Steps: 62 | Train Loss: 0.5385008 Vali Loss: 1.2224514 Test Loss: 0.4630587\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 1.550917148590088\n","Epoch: 75, Steps: 62 | Train Loss: 0.5384927 Vali Loss: 1.2155602 Test Loss: 0.4630229\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 1.6326522827148438\n","Epoch: 76, Steps: 62 | Train Loss: 0.5384102 Vali Loss: 1.2226160 Test Loss: 0.4629980\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 1.5396723747253418\n","Epoch: 77, Steps: 62 | Train Loss: 0.5386032 Vali Loss: 1.2224749 Test Loss: 0.4629772\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 1.6430461406707764\n","Epoch: 78, Steps: 62 | Train Loss: 0.5381844 Vali Loss: 1.2191194 Test Loss: 0.4630085\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 1.5527300834655762\n","Epoch: 79, Steps: 62 | Train Loss: 0.5387873 Vali Loss: 1.2256645 Test Loss: 0.4630080\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 1.6617417335510254\n","Epoch: 80, Steps: 62 | Train Loss: 0.5381298 Vali Loss: 1.2195239 Test Loss: 0.4630563\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 1.5678532123565674\n","Epoch: 81, Steps: 62 | Train Loss: 0.5385082 Vali Loss: 1.2227316 Test Loss: 0.4629740\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 1.5486223697662354\n","Epoch: 82, Steps: 62 | Train Loss: 0.5384986 Vali Loss: 1.2254792 Test Loss: 0.4629616\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 1.525392770767212\n","Epoch: 83, Steps: 62 | Train Loss: 0.5384589 Vali Loss: 1.2226286 Test Loss: 0.4630747\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 1.55488920211792\n","Epoch: 84, Steps: 62 | Train Loss: 0.5386764 Vali Loss: 1.2275813 Test Loss: 0.4629776\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 1.6471731662750244\n","Epoch: 85, Steps: 62 | Train Loss: 0.5380923 Vali Loss: 1.2217970 Test Loss: 0.4630052\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 1.552372694015503\n","Epoch: 86, Steps: 62 | Train Loss: 0.5383519 Vali Loss: 1.2267069 Test Loss: 0.4630442\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 1.555999517440796\n","Epoch: 87, Steps: 62 | Train Loss: 0.5385469 Vali Loss: 1.2221186 Test Loss: 0.4630199\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 1.5877158641815186\n","Epoch: 88, Steps: 62 | Train Loss: 0.5383531 Vali Loss: 1.2238878 Test Loss: 0.4630216\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 1.6812841892242432\n","Epoch: 89, Steps: 62 | Train Loss: 0.5382608 Vali Loss: 1.2218033 Test Loss: 0.4630742\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 1.5839166641235352\n","Epoch: 90, Steps: 62 | Train Loss: 0.5384568 Vali Loss: 1.2247785 Test Loss: 0.4630684\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 1.640190601348877\n","Epoch: 91, Steps: 62 | Train Loss: 0.5384784 Vali Loss: 1.2214711 Test Loss: 0.4629923\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 1.531860589981079\n","Epoch: 92, Steps: 62 | Train Loss: 0.5386842 Vali Loss: 1.2237034 Test Loss: 0.4629792\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 1.6131725311279297\n","Epoch: 93, Steps: 62 | Train Loss: 0.5384474 Vali Loss: 1.2214986 Test Loss: 0.4630735\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 1.6558167934417725\n","Epoch: 94, Steps: 62 | Train Loss: 0.5385756 Vali Loss: 1.2222487 Test Loss: 0.4630393\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 1.5200412273406982\n","Epoch: 95, Steps: 62 | Train Loss: 0.5388294 Vali Loss: 1.2228462 Test Loss: 0.4630143\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 1.5472240447998047\n","Epoch: 96, Steps: 62 | Train Loss: 0.5382857 Vali Loss: 1.2208525 Test Loss: 0.4630241\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 1.5290260314941406\n","Epoch: 97, Steps: 62 | Train Loss: 0.5385516 Vali Loss: 1.2197952 Test Loss: 0.4629667\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 1.751317024230957\n","Epoch: 98, Steps: 62 | Train Loss: 0.5386220 Vali Loss: 1.2174431 Test Loss: 0.4631002\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 1.5790421962738037\n","Epoch: 99, Steps: 62 | Train Loss: 0.5384767 Vali Loss: 1.2251000 Test Loss: 0.4630294\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 1.5730972290039062\n","Epoch: 100, Steps: 62 | Train Loss: 0.5384180 Vali Loss: 1.2216864 Test Loss: 0.4629401\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2545\n","mse:0.4630257487297058, mae:0.46205562353134155, rse:0.6504727602005005\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","Use GPU: cuda:0\n",">>>>>>>start training : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 7585\n","val 2161\n","test 2161\n","Epoch: 1 cost time: 1.645759105682373\n","Epoch: 1, Steps: 59 | Train Loss: 0.9035799 Vali Loss: 1.9745135 Test Loss: 0.7816728\n","Validation loss decreased (inf --> 1.974514).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 1.7069168090820312\n","Epoch: 2, Steps: 59 | Train Loss: 0.7736927 Vali Loss: 1.5453290 Test Loss: 0.5067559\n","Validation loss decreased (1.974514 --> 1.545329).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 1.6522347927093506\n","Epoch: 3, Steps: 59 | Train Loss: 0.6842922 Vali Loss: 1.5054708 Test Loss: 0.4756532\n","Validation loss decreased (1.545329 --> 1.505471).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 1.646331787109375\n","Epoch: 4, Steps: 59 | Train Loss: 0.6629545 Vali Loss: 1.4920584 Test Loss: 0.4676351\n","Validation loss decreased (1.505471 --> 1.492058).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 1.5890955924987793\n","Epoch: 5, Steps: 59 | Train Loss: 0.6555662 Vali Loss: 1.4785144 Test Loss: 0.4644367\n","Validation loss decreased (1.492058 --> 1.478514).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 1.7042410373687744\n","Epoch: 6, Steps: 59 | Train Loss: 0.6518299 Vali Loss: 1.4737718 Test Loss: 0.4631542\n","Validation loss decreased (1.478514 --> 1.473772).  Saving model ...\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 1.6505115032196045\n","Epoch: 7, Steps: 59 | Train Loss: 0.6503027 Vali Loss: 1.4787350 Test Loss: 0.4624687\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 1.663654088973999\n","Epoch: 8, Steps: 59 | Train Loss: 0.6491551 Vali Loss: 1.4808365 Test Loss: 0.4621945\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 1.6532864570617676\n","Epoch: 9, Steps: 59 | Train Loss: 0.6488573 Vali Loss: 1.4766568 Test Loss: 0.4619741\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 1.7217869758605957\n","Epoch: 10, Steps: 59 | Train Loss: 0.6486674 Vali Loss: 1.4771745 Test Loss: 0.4617757\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 1.6240172386169434\n","Epoch: 11, Steps: 59 | Train Loss: 0.6486455 Vali Loss: 1.4774837 Test Loss: 0.4617788\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 1.660956621170044\n","Epoch: 12, Steps: 59 | Train Loss: 0.6483255 Vali Loss: 1.4804256 Test Loss: 0.4618208\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 4.8828125e-08\n","Epoch: 13 cost time: 1.6759979724884033\n","Epoch: 13, Steps: 59 | Train Loss: 0.6485355 Vali Loss: 1.4810991 Test Loss: 0.4618155\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 2.44140625e-08\n","Epoch: 14 cost time: 1.734041690826416\n","Epoch: 14, Steps: 59 | Train Loss: 0.6481576 Vali Loss: 1.4788654 Test Loss: 0.4618524\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.220703125e-08\n","Epoch: 15 cost time: 1.6937634944915771\n","Epoch: 15, Steps: 59 | Train Loss: 0.6485691 Vali Loss: 1.4750510 Test Loss: 0.4617051\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 6.103515625e-09\n","Epoch: 16 cost time: 1.6678006649017334\n","Epoch: 16, Steps: 59 | Train Loss: 0.6482533 Vali Loss: 1.4823217 Test Loss: 0.4617057\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 3.0517578125e-09\n","Epoch: 17 cost time: 1.7228214740753174\n","Epoch: 17, Steps: 59 | Train Loss: 0.6482576 Vali Loss: 1.4731975 Test Loss: 0.4618351\n","Validation loss decreased (1.473772 --> 1.473197).  Saving model ...\n","Updating learning rate to 1.52587890625e-09\n","Epoch: 18 cost time: 1.7498185634613037\n","Epoch: 18, Steps: 59 | Train Loss: 0.6483648 Vali Loss: 1.4789469 Test Loss: 0.4617623\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.62939453125e-10\n","Epoch: 19 cost time: 1.7057380676269531\n","Epoch: 19, Steps: 59 | Train Loss: 0.6483855 Vali Loss: 1.4785109 Test Loss: 0.4617125\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.814697265625e-10\n","Epoch: 20 cost time: 1.6031723022460938\n","Epoch: 20, Steps: 59 | Train Loss: 0.6484754 Vali Loss: 1.4783986 Test Loss: 0.4616927\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.9073486328125e-10\n","Epoch: 21 cost time: 1.6322896480560303\n","Epoch: 21, Steps: 59 | Train Loss: 0.6478961 Vali Loss: 1.4825445 Test Loss: 0.4618196\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 9.5367431640625e-11\n","Epoch: 22 cost time: 1.7063348293304443\n","Epoch: 22, Steps: 59 | Train Loss: 0.6485484 Vali Loss: 1.4783363 Test Loss: 0.4617664\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 4.76837158203125e-11\n","Epoch: 23 cost time: 1.7898924350738525\n","Epoch: 23, Steps: 59 | Train Loss: 0.6484343 Vali Loss: 1.4798005 Test Loss: 0.4617712\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 2.384185791015625e-11\n","Epoch: 24 cost time: 1.6212973594665527\n","Epoch: 24, Steps: 59 | Train Loss: 0.6483031 Vali Loss: 1.4814622 Test Loss: 0.4617068\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 1.1920928955078126e-11\n","Epoch: 25 cost time: 1.6656591892242432\n","Epoch: 25, Steps: 59 | Train Loss: 0.6483000 Vali Loss: 1.4773256 Test Loss: 0.4617034\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 5.960464477539063e-12\n","Epoch: 26 cost time: 1.6466524600982666\n","Epoch: 26, Steps: 59 | Train Loss: 0.6483595 Vali Loss: 1.4781225 Test Loss: 0.4617653\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 2.9802322387695314e-12\n","Epoch: 27 cost time: 1.7611627578735352\n","Epoch: 27, Steps: 59 | Train Loss: 0.6483317 Vali Loss: 1.4724928 Test Loss: 0.4617539\n","Validation loss decreased (1.473197 --> 1.472493).  Saving model ...\n","Updating learning rate to 1.4901161193847657e-12\n","Epoch: 28 cost time: 1.6047041416168213\n","Epoch: 28, Steps: 59 | Train Loss: 0.6481981 Vali Loss: 1.4811897 Test Loss: 0.4617593\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 7.450580596923828e-13\n","Epoch: 29 cost time: 1.6177051067352295\n","Epoch: 29, Steps: 59 | Train Loss: 0.6484040 Vali Loss: 1.4777434 Test Loss: 0.4617001\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 3.725290298461914e-13\n","Epoch: 30 cost time: 1.5887095928192139\n","Epoch: 30, Steps: 59 | Train Loss: 0.6482186 Vali Loss: 1.4747984 Test Loss: 0.4616800\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.862645149230957e-13\n","Epoch: 31 cost time: 1.793433666229248\n","Epoch: 31, Steps: 59 | Train Loss: 0.6481041 Vali Loss: 1.4832050 Test Loss: 0.4617421\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 9.313225746154786e-14\n","Epoch: 32 cost time: 1.6157639026641846\n","Epoch: 32, Steps: 59 | Train Loss: 0.6481987 Vali Loss: 1.4790434 Test Loss: 0.4616809\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 4.656612873077393e-14\n","Epoch: 33 cost time: 1.6767747402191162\n","Epoch: 33, Steps: 59 | Train Loss: 0.6486052 Vali Loss: 1.4808311 Test Loss: 0.4617414\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 2.3283064365386964e-14\n","Epoch: 34 cost time: 1.642655849456787\n","Epoch: 34, Steps: 59 | Train Loss: 0.6481411 Vali Loss: 1.4807602 Test Loss: 0.4617779\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 1.1641532182693482e-14\n","Epoch: 35 cost time: 1.8076889514923096\n","Epoch: 35, Steps: 59 | Train Loss: 0.6480372 Vali Loss: 1.4770967 Test Loss: 0.4617658\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 5.820766091346741e-15\n","Epoch: 36 cost time: 1.7155964374542236\n","Epoch: 36, Steps: 59 | Train Loss: 0.6486477 Vali Loss: 1.4767438 Test Loss: 0.4617873\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 2.9103830456733705e-15\n","Epoch: 37 cost time: 1.6678991317749023\n","Epoch: 37, Steps: 59 | Train Loss: 0.6479828 Vali Loss: 1.4804919 Test Loss: 0.4617573\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 1.4551915228366853e-15\n","Epoch: 38 cost time: 1.6591064929962158\n","Epoch: 38, Steps: 59 | Train Loss: 0.6483690 Vali Loss: 1.4788134 Test Loss: 0.4617546\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 7.275957614183426e-16\n","Epoch: 39 cost time: 1.7334907054901123\n","Epoch: 39, Steps: 59 | Train Loss: 0.6483085 Vali Loss: 1.4739256 Test Loss: 0.4617811\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 3.637978807091713e-16\n","Epoch: 40 cost time: 1.6545164585113525\n","Epoch: 40, Steps: 59 | Train Loss: 0.6482501 Vali Loss: 1.4828618 Test Loss: 0.4618048\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.8189894035458566e-16\n","Epoch: 41 cost time: 1.6588187217712402\n","Epoch: 41, Steps: 59 | Train Loss: 0.6485180 Vali Loss: 1.4794650 Test Loss: 0.4617283\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 9.094947017729283e-17\n","Epoch: 42 cost time: 1.6415777206420898\n","Epoch: 42, Steps: 59 | Train Loss: 0.6482482 Vali Loss: 1.4750311 Test Loss: 0.4617921\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 4.5474735088646414e-17\n","Epoch: 43 cost time: 1.7399675846099854\n","Epoch: 43, Steps: 59 | Train Loss: 0.6483215 Vali Loss: 1.4785104 Test Loss: 0.4617526\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 2.2737367544323207e-17\n","Epoch: 44 cost time: 1.651210069656372\n","Epoch: 44, Steps: 59 | Train Loss: 0.6483851 Vali Loss: 1.4788740 Test Loss: 0.4617474\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 1.1368683772161604e-17\n","Epoch: 45 cost time: 1.6524319648742676\n","Epoch: 45, Steps: 59 | Train Loss: 0.6481788 Vali Loss: 1.4735851 Test Loss: 0.4616914\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 5.684341886080802e-18\n","Epoch: 46 cost time: 1.704540729522705\n","Epoch: 46, Steps: 59 | Train Loss: 0.6482408 Vali Loss: 1.4802938 Test Loss: 0.4617794\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 2.842170943040401e-18\n","Epoch: 47 cost time: 1.7654879093170166\n","Epoch: 47, Steps: 59 | Train Loss: 0.6483853 Vali Loss: 1.4846936 Test Loss: 0.4617282\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 1.4210854715202004e-18\n","Epoch: 48 cost time: 1.664804220199585\n","Epoch: 48, Steps: 59 | Train Loss: 0.6484451 Vali Loss: 1.4827172 Test Loss: 0.4617667\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 7.105427357601002e-19\n","Epoch: 49 cost time: 1.608997106552124\n","Epoch: 49, Steps: 59 | Train Loss: 0.6482788 Vali Loss: 1.4710493 Test Loss: 0.4617769\n","Validation loss decreased (1.472493 --> 1.471049).  Saving model ...\n","Updating learning rate to 3.552713678800501e-19\n","Epoch: 50 cost time: 1.6232390403747559\n","Epoch: 50, Steps: 59 | Train Loss: 0.6486667 Vali Loss: 1.4811717 Test Loss: 0.4617879\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 1.7763568394002505e-19\n","Epoch: 51 cost time: 1.8162176609039307\n","Epoch: 51, Steps: 59 | Train Loss: 0.6481451 Vali Loss: 1.4774909 Test Loss: 0.4616363\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 8.881784197001253e-20\n","Epoch: 52 cost time: 1.704401969909668\n","Epoch: 52, Steps: 59 | Train Loss: 0.6485323 Vali Loss: 1.4765458 Test Loss: 0.4617504\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 4.4408920985006264e-20\n","Epoch: 53 cost time: 1.6568596363067627\n","Epoch: 53, Steps: 59 | Train Loss: 0.6481629 Vali Loss: 1.4836740 Test Loss: 0.4617923\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 2.2204460492503132e-20\n","Epoch: 54 cost time: 1.6248588562011719\n","Epoch: 54, Steps: 59 | Train Loss: 0.6483305 Vali Loss: 1.4716163 Test Loss: 0.4617308\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 1.1102230246251566e-20\n","Epoch: 55 cost time: 1.7200062274932861\n","Epoch: 55, Steps: 59 | Train Loss: 0.6483688 Vali Loss: 1.4740212 Test Loss: 0.4617131\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 5.551115123125783e-21\n","Epoch: 56 cost time: 1.7301313877105713\n","Epoch: 56, Steps: 59 | Train Loss: 0.6482547 Vali Loss: 1.4776778 Test Loss: 0.4617055\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 2.7755575615628915e-21\n","Epoch: 57 cost time: 1.7061207294464111\n","Epoch: 57, Steps: 59 | Train Loss: 0.6483074 Vali Loss: 1.4735817 Test Loss: 0.4617653\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 1.3877787807814457e-21\n","Epoch: 58 cost time: 1.6419017314910889\n","Epoch: 58, Steps: 59 | Train Loss: 0.6486566 Vali Loss: 1.4799991 Test Loss: 0.4617358\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 6.938893903907229e-22\n","Epoch: 59 cost time: 1.712080955505371\n","Epoch: 59, Steps: 59 | Train Loss: 0.6484782 Vali Loss: 1.4786766 Test Loss: 0.4616826\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 3.4694469519536144e-22\n","Epoch: 60 cost time: 1.7511537075042725\n","Epoch: 60, Steps: 59 | Train Loss: 0.6484104 Vali Loss: 1.4763124 Test Loss: 0.4617160\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 1.7347234759768072e-22\n","Epoch: 61 cost time: 1.7492623329162598\n","Epoch: 61, Steps: 59 | Train Loss: 0.6484047 Vali Loss: 1.4746681 Test Loss: 0.4617574\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 8.673617379884036e-23\n","Epoch: 62 cost time: 1.6869351863861084\n","Epoch: 62, Steps: 59 | Train Loss: 0.6483520 Vali Loss: 1.4810617 Test Loss: 0.4617538\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 4.336808689942018e-23\n","Epoch: 63 cost time: 1.7692759037017822\n","Epoch: 63, Steps: 59 | Train Loss: 0.6484098 Vali Loss: 1.4780424 Test Loss: 0.4617747\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 2.168404344971009e-23\n","Epoch: 64 cost time: 1.76560378074646\n","Epoch: 64, Steps: 59 | Train Loss: 0.6481576 Vali Loss: 1.4829185 Test Loss: 0.4617713\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 1.0842021724855045e-23\n","Epoch: 65 cost time: 1.6876816749572754\n","Epoch: 65, Steps: 59 | Train Loss: 0.6478183 Vali Loss: 1.4794583 Test Loss: 0.4618002\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 5.4210108624275224e-24\n","Epoch: 66 cost time: 1.6905465126037598\n","Epoch: 66, Steps: 59 | Train Loss: 0.6481867 Vali Loss: 1.4754746 Test Loss: 0.4617647\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 2.7105054312137612e-24\n","Epoch: 67 cost time: 1.755176305770874\n","Epoch: 67, Steps: 59 | Train Loss: 0.6481460 Vali Loss: 1.4789634 Test Loss: 0.4617270\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 1.3552527156068806e-24\n","Epoch: 68 cost time: 1.7026851177215576\n","Epoch: 68, Steps: 59 | Train Loss: 0.6478546 Vali Loss: 1.4735843 Test Loss: 0.4617575\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 6.776263578034403e-25\n","Epoch: 69 cost time: 1.6982219219207764\n","Epoch: 69, Steps: 59 | Train Loss: 0.6482710 Vali Loss: 1.4800537 Test Loss: 0.4616885\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 3.3881317890172015e-25\n","Epoch: 70 cost time: 1.7038841247558594\n","Epoch: 70, Steps: 59 | Train Loss: 0.6483902 Vali Loss: 1.4791727 Test Loss: 0.4617671\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 1.6940658945086008e-25\n","Epoch: 71 cost time: 1.8178215026855469\n","Epoch: 71, Steps: 59 | Train Loss: 0.6483288 Vali Loss: 1.4708394 Test Loss: 0.4617733\n","Validation loss decreased (1.471049 --> 1.470839).  Saving model ...\n","Updating learning rate to 8.470329472543004e-26\n","Epoch: 72 cost time: 1.7794983386993408\n","Epoch: 72, Steps: 59 | Train Loss: 0.6478778 Vali Loss: 1.4746910 Test Loss: 0.4618496\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 4.235164736271502e-26\n","Epoch: 73 cost time: 1.6532220840454102\n","Epoch: 73, Steps: 59 | Train Loss: 0.6480671 Vali Loss: 1.4739672 Test Loss: 0.4617546\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 2.117582368135751e-26\n","Epoch: 74 cost time: 1.686204195022583\n","Epoch: 74, Steps: 59 | Train Loss: 0.6483631 Vali Loss: 1.4792904 Test Loss: 0.4617462\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 1.0587911840678755e-26\n","Epoch: 75 cost time: 1.7911937236785889\n","Epoch: 75, Steps: 59 | Train Loss: 0.6485450 Vali Loss: 1.4799836 Test Loss: 0.4617855\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 5.2939559203393774e-27\n","Epoch: 76 cost time: 1.7932894229888916\n","Epoch: 76, Steps: 59 | Train Loss: 0.6484018 Vali Loss: 1.4761785 Test Loss: 0.4617217\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 2.6469779601696887e-27\n","Epoch: 77 cost time: 1.6453680992126465\n","Epoch: 77, Steps: 59 | Train Loss: 0.6483961 Vali Loss: 1.4787455 Test Loss: 0.4617049\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 1.3234889800848443e-27\n","Epoch: 78 cost time: 1.667895793914795\n","Epoch: 78, Steps: 59 | Train Loss: 0.6485747 Vali Loss: 1.4840971 Test Loss: 0.4618279\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 6.617444900424222e-28\n","Epoch: 79 cost time: 1.7856428623199463\n","Epoch: 79, Steps: 59 | Train Loss: 0.6483936 Vali Loss: 1.4789077 Test Loss: 0.4616715\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 3.308722450212111e-28\n","Epoch: 80 cost time: 1.8136653900146484\n","Epoch: 80, Steps: 59 | Train Loss: 0.6485360 Vali Loss: 1.4796064 Test Loss: 0.4617402\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 1.6543612251060554e-28\n","Epoch: 81 cost time: 1.639326810836792\n","Epoch: 81, Steps: 59 | Train Loss: 0.6484116 Vali Loss: 1.4780871 Test Loss: 0.4616880\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 8.271806125530277e-29\n","Epoch: 82 cost time: 1.677431583404541\n","Epoch: 82, Steps: 59 | Train Loss: 0.6483548 Vali Loss: 1.4813144 Test Loss: 0.4617942\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 4.1359030627651386e-29\n","Epoch: 83 cost time: 1.7382254600524902\n","Epoch: 83, Steps: 59 | Train Loss: 0.6480960 Vali Loss: 1.4783177 Test Loss: 0.4617839\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 2.0679515313825693e-29\n","Epoch: 84 cost time: 1.756270170211792\n","Epoch: 84, Steps: 59 | Train Loss: 0.6482886 Vali Loss: 1.4810719 Test Loss: 0.4616572\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 1.0339757656912846e-29\n","Epoch: 85 cost time: 1.6729412078857422\n","Epoch: 85, Steps: 59 | Train Loss: 0.6482725 Vali Loss: 1.4742212 Test Loss: 0.4617674\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 5.169878828456423e-30\n","Epoch: 86 cost time: 1.6596925258636475\n","Epoch: 86, Steps: 59 | Train Loss: 0.6486486 Vali Loss: 1.4725266 Test Loss: 0.4617482\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 2.5849394142282116e-30\n","Epoch: 87 cost time: 1.7264466285705566\n","Epoch: 87, Steps: 59 | Train Loss: 0.6485478 Vali Loss: 1.4785119 Test Loss: 0.4617674\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 1.2924697071141058e-30\n","Epoch: 88 cost time: 1.7626731395721436\n","Epoch: 88, Steps: 59 | Train Loss: 0.6484499 Vali Loss: 1.4816754 Test Loss: 0.4618388\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 6.462348535570529e-31\n","Epoch: 89 cost time: 1.6799826622009277\n","Epoch: 89, Steps: 59 | Train Loss: 0.6480521 Vali Loss: 1.4833174 Test Loss: 0.4617137\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 3.2311742677852645e-31\n","Epoch: 90 cost time: 1.679244041442871\n","Epoch: 90, Steps: 59 | Train Loss: 0.6482334 Vali Loss: 1.4820950 Test Loss: 0.4616825\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 1.6155871338926323e-31\n","Epoch: 91 cost time: 1.7277069091796875\n","Epoch: 91, Steps: 59 | Train Loss: 0.6485223 Vali Loss: 1.4800209 Test Loss: 0.4617029\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 8.077935669463161e-32\n","Epoch: 92 cost time: 1.7921137809753418\n","Epoch: 92, Steps: 59 | Train Loss: 0.6485164 Vali Loss: 1.4782844 Test Loss: 0.4615897\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 4.0389678347315806e-32\n","Epoch: 93 cost time: 1.690584659576416\n","Epoch: 93, Steps: 59 | Train Loss: 0.6485229 Vali Loss: 1.4792876 Test Loss: 0.4617576\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 2.0194839173657903e-32\n","Epoch: 94 cost time: 1.6706209182739258\n","Epoch: 94, Steps: 59 | Train Loss: 0.6482649 Vali Loss: 1.4781468 Test Loss: 0.4617459\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 1.0097419586828952e-32\n","Epoch: 95 cost time: 1.7808380126953125\n","Epoch: 95, Steps: 59 | Train Loss: 0.6486890 Vali Loss: 1.4779627 Test Loss: 0.4617950\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 5.048709793414476e-33\n","Epoch: 96 cost time: 1.751948595046997\n","Epoch: 96, Steps: 59 | Train Loss: 0.6483073 Vali Loss: 1.4810125 Test Loss: 0.4617007\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 2.524354896707238e-33\n","Epoch: 97 cost time: 1.6412851810455322\n","Epoch: 97, Steps: 59 | Train Loss: 0.6476754 Vali Loss: 1.4759688 Test Loss: 0.4618599\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 1.262177448353619e-33\n","Epoch: 98 cost time: 1.685673475265503\n","Epoch: 98, Steps: 59 | Train Loss: 0.6485549 Vali Loss: 1.4780648 Test Loss: 0.4617794\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 6.310887241768095e-34\n","Epoch: 99 cost time: 1.6995017528533936\n","Epoch: 99, Steps: 59 | Train Loss: 0.6485625 Vali Loss: 1.4793899 Test Loss: 0.4617226\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 3.1554436208840474e-34\n","Epoch: 100 cost time: 1.7325117588043213\n","Epoch: 100, Steps: 59 | Train Loss: 0.6486743 Vali Loss: 1.4757984 Test Loss: 0.4616857\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 1.5777218104420237e-34\n",">>>>>>>testing : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 2161\n","mse:0.46177369356155396, mae:0.4760817289352417, rse:0.6526790261268616\n",">>>>>>>predicting : ETTh1_PatchTST_ETTh1_ftM_sl336_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n"]}],"source":["arg_seq_len=336\n","arg_pred_len = 96\n","model_name='PatchTST'\n","root_path_name='./dataset/'\n","data_path_name='ETTh1.csv'\n","model_id_name='ETTh1'\n","data_name='ETTh1'\n","random_seed=2021\n","\n","class Args:\n","    random_seed = 2021\n","\n","    is_training = 1\n","    model_id = model_id_name\n","    model = model_name\n","\n","    data = data_name\n","    root_path = root_path_name\n","    data_path = data_path_name\n","    features = 'M'\n","    target = 'OT'\n","    freq = 'h'\n","    checkpoints = './checkpoints/'\n","\n","    seq_len = arg_seq_len\n","    label_len = 48\n","    pred_len = arg_pred_len\n","\n","    fc_dropout= 0.3\n","    head_dropout = 0.0\n","    patch_len = 16\n","    stride = 8\n","    padding_patch = 'end'\n","    revin = 1\n","    affine = 0\n","    subtract_last = 0\n","    decomposition = 0\n","    kernel_size = 25\n","    individual = 0\n","\n","    embed_type = 0\n","    enc_in = 7\n","    dec_in = 7\n","    c_out = 7\n","    d_model = 16\n","    n_heads = 4\n","    e_layers = 3\n","    d_layers = 1\n","    d_ff = 128\n","    moving_avg = 25\n","    factor = 1\n","    distil = True\n","    dropout = 0.3\n","    embed = 'timeF'\n","    activation = 'gelu'\n","    output_attention = False\n","    do_predict = True\n","\n","    num_workers = 10\n","    itr = 1\n","    train_epochs = 100\n","    batch_size = 128\n","    patience = 100\n","    learning_rate = 0.0001\n","    des = 'Exp'\n","    loss = 'MSE'\n","    lradj = 'type1'\n","    pct_start = 0.3\n","    use_amp = False\n","\n","    use_gpu = True\n","    gpu = 0\n","    use_multi_gpu = False\n","    devices = '0'\n","    test_flop = False\n","\n","args = Args();\n","\n","# random seed\n","fix_seed = args.random_seed\n","random.seed(fix_seed)\n","torch.manual_seed(fix_seed)\n","np.random.seed(fix_seed)\n","\n","args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.dvices = args.devices.replace(' ', '')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","print('Args in experiment:')\n","\n","for i in [96, 192, 336, 720]:\n","  Exp = Exp_Main\n","  args.pred_len = i\n","\n","  if args.is_training:\n","      for ii in range(args.itr):\n","          # setting record of experiments\n","          setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n","              args.model_id,\n","              args.model,\n","              args.data,\n","              args.features,\n","              args.seq_len,\n","              args.label_len,\n","              args.pred_len,\n","              args.d_model,\n","              args.n_heads,\n","              args.e_layers,\n","              args.d_layers,\n","              args.d_ff,\n","              args.factor,\n","              args.embed,\n","              args.distil,\n","              args.des,ii)\n","\n","          exp = Exp(args)  # set experiments\n","          print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","          exp.train(setting)\n","\n","          print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","          exp.test(setting)\n","\n","          if args.do_predict:\n","              print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","              exp.predict(setting, True)\n","\n","          torch.cuda.empty_cache()\n","  else:\n","      ii = 0\n","      setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n","                                                                                                  args.model,\n","                                                                                                  args.data,\n","                                                                                                  args.features,\n","                                                                                                  args.seq_len,\n","                                                                                                  args.label_len,\n","                                                                                                  args.pred_len,\n","                                                                                                  args.d_model,\n","                                                                                                  args.n_heads,\n","                                                                                                  args.e_layers,\n","                                                                                                  args.d_layers,\n","                                                                                                  args.d_ff,\n","                                                                                                  args.factor,\n","                                                                                                  args.embed,\n","                                                                                                  args.distil,\n","                                                                                                  args.des, ii)\n","\n","      exp = Exp(args)  # set experiments\n","      print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","      exp.test(setting, test=1)\n","      torch.cuda.empty_cache()\n"]},{"cell_type":"markdown","metadata":{"id":"6Au_vivI6AG6"},"source":["### ILI 데이터셋 실험"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":809786,"status":"ok","timestamp":1701028948282,"user":{"displayName":"박종현","userId":"16384752064104668219"},"user_tz":-540},"id":"6IrdB90AcHpN","outputId":"b5a2ba06-a5e5-4e1a-af21-6f757cd14f06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","==================== Now pred_len : 24 ============================ \n","\n"," \n","Use GPU: cuda:0\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl24_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 549\n","val 74\n","test 170\n","Epoch: 1 cost time: 2.1228740215301514\n","Epoch: 1, Steps: 34 | Train Loss: 0.9592177 Vali Loss: 0.4275682 Test Loss: 2.8507452\n","Validation loss decreased (inf --> 0.427568).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 0.9830012321472168\n","Epoch: 2, Steps: 34 | Train Loss: 0.8070758 Vali Loss: 0.3418274 Test Loss: 1.9197880\n","Validation loss decreased (0.427568 --> 0.341827).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 3 cost time: 0.9800469875335693\n","Epoch: 3, Steps: 34 | Train Loss: 0.5514452 Vali Loss: 0.3482531 Test Loss: 1.6773701\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 4 cost time: 0.9430913925170898\n","Epoch: 4, Steps: 34 | Train Loss: 0.4608145 Vali Loss: 0.3277884 Test Loss: 2.0751271\n","Validation loss decreased (0.341827 --> 0.327788).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 5 cost time: 0.8802125453948975\n","Epoch: 5, Steps: 34 | Train Loss: 0.4159365 Vali Loss: 0.2884818 Test Loss: 1.9634222\n","Validation loss decreased (0.327788 --> 0.288482).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 6 cost time: 0.8544425964355469\n","Epoch: 6, Steps: 34 | Train Loss: 0.3940696 Vali Loss: 0.2221504 Test Loss: 1.6275196\n","Validation loss decreased (0.288482 --> 0.222150).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 7 cost time: 0.8730649948120117\n","Epoch: 7, Steps: 34 | Train Loss: 0.3574232 Vali Loss: 0.2531741 Test Loss: 1.8492901\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 8 cost time: 0.8673160076141357\n","Epoch: 8, Steps: 34 | Train Loss: 0.3284238 Vali Loss: 0.3086891 Test Loss: 2.1232519\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 9 cost time: 0.8517045974731445\n","Epoch: 9, Steps: 34 | Train Loss: 0.3275146 Vali Loss: 0.2223399 Test Loss: 1.8562549\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 10 cost time: 0.8606879711151123\n","Epoch: 10, Steps: 34 | Train Loss: 0.2993129 Vali Loss: 0.2412086 Test Loss: 1.7331188\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 11 cost time: 0.9218995571136475\n","Epoch: 11, Steps: 34 | Train Loss: 0.2734575 Vali Loss: 0.2447621 Test Loss: 1.6446794\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 12 cost time: 0.9378349781036377\n","Epoch: 12, Steps: 34 | Train Loss: 0.2469407 Vali Loss: 0.2363578 Test Loss: 1.6520176\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 13 cost time: 0.8784494400024414\n","Epoch: 13, Steps: 34 | Train Loss: 0.2388282 Vali Loss: 0.2484407 Test Loss: 1.5062581\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 14 cost time: 0.8730287551879883\n","Epoch: 14, Steps: 34 | Train Loss: 0.2501998 Vali Loss: 0.2851830 Test Loss: 1.8588701\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 15 cost time: 0.8872237205505371\n","Epoch: 15, Steps: 34 | Train Loss: 0.2415078 Vali Loss: 0.2361567 Test Loss: 1.4300094\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 16 cost time: 0.8807315826416016\n","Epoch: 16, Steps: 34 | Train Loss: 0.2139495 Vali Loss: 0.2377241 Test Loss: 1.4042466\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 17 cost time: 0.8954229354858398\n","Epoch: 17, Steps: 34 | Train Loss: 0.2185116 Vali Loss: 0.2736720 Test Loss: 1.4808171\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 18 cost time: 0.8844447135925293\n","Epoch: 18, Steps: 34 | Train Loss: 0.2087069 Vali Loss: 0.2469836 Test Loss: 1.5292072\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 19 cost time: 0.9781875610351562\n","Epoch: 19, Steps: 34 | Train Loss: 0.2031153 Vali Loss: 0.2177324 Test Loss: 1.3009640\n","Validation loss decreased (0.222150 --> 0.217732).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 20 cost time: 0.9330403804779053\n","Epoch: 20, Steps: 34 | Train Loss: 0.1995822 Vali Loss: 0.3004433 Test Loss: 1.4452089\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 21 cost time: 0.9005913734436035\n","Epoch: 21, Steps: 34 | Train Loss: 0.1956692 Vali Loss: 0.2715963 Test Loss: 1.5724398\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 22 cost time: 0.8807640075683594\n","Epoch: 22, Steps: 34 | Train Loss: 0.1875793 Vali Loss: 0.2430900 Test Loss: 1.3302115\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 23 cost time: 0.938927412033081\n","Epoch: 23, Steps: 34 | Train Loss: 0.1817704 Vali Loss: 0.2597845 Test Loss: 1.5017926\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 24 cost time: 0.8876399993896484\n","Epoch: 24, Steps: 34 | Train Loss: 0.1812331 Vali Loss: 0.2682574 Test Loss: 1.2440150\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 25 cost time: 0.8624851703643799\n","Epoch: 25, Steps: 34 | Train Loss: 0.1734465 Vali Loss: 0.2797017 Test Loss: 1.2098353\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 26 cost time: 0.9462039470672607\n","Epoch: 26, Steps: 34 | Train Loss: 0.1838017 Vali Loss: 0.3080096 Test Loss: 1.3890142\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 27 cost time: 0.9276132583618164\n","Epoch: 27, Steps: 34 | Train Loss: 0.1739494 Vali Loss: 0.3055195 Test Loss: 1.2304184\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 28 cost time: 0.9344298839569092\n","Epoch: 28, Steps: 34 | Train Loss: 0.1731185 Vali Loss: 0.2999288 Test Loss: 1.3139637\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 29 cost time: 0.9001772403717041\n","Epoch: 29, Steps: 34 | Train Loss: 0.1676534 Vali Loss: 0.2801612 Test Loss: 1.2525166\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 30 cost time: 0.8866255283355713\n","Epoch: 30, Steps: 34 | Train Loss: 0.1662882 Vali Loss: 0.3304979 Test Loss: 1.2502033\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 31 cost time: 0.8765084743499756\n","Epoch: 31, Steps: 34 | Train Loss: 0.1626894 Vali Loss: 0.3010657 Test Loss: 1.3795635\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 32 cost time: 0.8705751895904541\n","Epoch: 32, Steps: 34 | Train Loss: 0.1609341 Vali Loss: 0.3044811 Test Loss: 1.2644006\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 33 cost time: 0.9120221138000488\n","Epoch: 33, Steps: 34 | Train Loss: 0.1576571 Vali Loss: 0.3140789 Test Loss: 1.3613884\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 34 cost time: 0.8978464603424072\n","Epoch: 34, Steps: 34 | Train Loss: 0.1559704 Vali Loss: 0.2937401 Test Loss: 1.2468894\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 35 cost time: 0.9433927536010742\n","Epoch: 35, Steps: 34 | Train Loss: 0.1576582 Vali Loss: 0.2978708 Test Loss: 1.2479212\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 36 cost time: 0.9455578327178955\n","Epoch: 36, Steps: 34 | Train Loss: 0.1551906 Vali Loss: 0.3054245 Test Loss: 1.2110616\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 37 cost time: 0.9027867317199707\n","Epoch: 37, Steps: 34 | Train Loss: 0.1475341 Vali Loss: 0.3302276 Test Loss: 1.2806512\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 38 cost time: 0.9032504558563232\n","Epoch: 38, Steps: 34 | Train Loss: 0.1454547 Vali Loss: 0.3057804 Test Loss: 1.3346249\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 39 cost time: 0.8713879585266113\n","Epoch: 39, Steps: 34 | Train Loss: 0.1422251 Vali Loss: 0.3045341 Test Loss: 1.1754982\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 40 cost time: 0.8633937835693359\n","Epoch: 40, Steps: 34 | Train Loss: 0.1433908 Vali Loss: 0.3215936 Test Loss: 1.2351410\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 41 cost time: 0.8395793437957764\n","Epoch: 41, Steps: 34 | Train Loss: 0.1501935 Vali Loss: 0.3113164 Test Loss: 1.3609530\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 42 cost time: 0.9397907257080078\n","Epoch: 42, Steps: 34 | Train Loss: 0.1490287 Vali Loss: 0.2718600 Test Loss: 1.2026987\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 43 cost time: 0.916372537612915\n","Epoch: 43, Steps: 34 | Train Loss: 0.1511365 Vali Loss: 0.3602575 Test Loss: 1.2731988\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 44 cost time: 0.9180257320404053\n","Epoch: 44, Steps: 34 | Train Loss: 0.1463882 Vali Loss: 0.3056992 Test Loss: 1.5126419\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 45 cost time: 0.8942861557006836\n","Epoch: 45, Steps: 34 | Train Loss: 0.1425297 Vali Loss: 0.3335114 Test Loss: 1.4761038\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 46 cost time: 0.9016673564910889\n","Epoch: 46, Steps: 34 | Train Loss: 0.1450070 Vali Loss: 0.3544749 Test Loss: 1.2169938\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 47 cost time: 0.8863062858581543\n","Epoch: 47, Steps: 34 | Train Loss: 0.1360242 Vali Loss: 0.3479126 Test Loss: 1.1784873\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 48 cost time: 0.8759927749633789\n","Epoch: 48, Steps: 34 | Train Loss: 0.1345165 Vali Loss: 0.3504451 Test Loss: 1.2997440\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 49 cost time: 0.8938894271850586\n","Epoch: 49, Steps: 34 | Train Loss: 0.1278889 Vali Loss: 0.3671303 Test Loss: 1.0536923\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 50 cost time: 0.9132966995239258\n","Epoch: 50, Steps: 34 | Train Loss: 0.1252773 Vali Loss: 0.3352494 Test Loss: 1.2406263\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 51 cost time: 0.9159727096557617\n","Epoch: 51, Steps: 34 | Train Loss: 0.1312686 Vali Loss: 0.3620377 Test Loss: 1.1510601\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 52 cost time: 0.9178712368011475\n","Epoch: 52, Steps: 34 | Train Loss: 0.1382816 Vali Loss: 0.3046833 Test Loss: 1.3241960\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 53 cost time: 0.8777470588684082\n","Epoch: 53, Steps: 34 | Train Loss: 0.1278782 Vali Loss: 0.3196691 Test Loss: 1.2063687\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 54 cost time: 0.8882083892822266\n","Epoch: 54, Steps: 34 | Train Loss: 0.1199601 Vali Loss: 0.3090815 Test Loss: 1.2347285\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 55 cost time: 0.8982696533203125\n","Epoch: 55, Steps: 34 | Train Loss: 0.1229909 Vali Loss: 0.3162872 Test Loss: 1.2227695\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 56 cost time: 0.8849852085113525\n","Epoch: 56, Steps: 34 | Train Loss: 0.1256111 Vali Loss: 0.3253867 Test Loss: 1.4003961\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 57 cost time: 0.8918056488037109\n","Epoch: 57, Steps: 34 | Train Loss: 0.1207076 Vali Loss: 0.3341725 Test Loss: 1.1429698\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 58 cost time: 0.9191670417785645\n","Epoch: 58, Steps: 34 | Train Loss: 0.1239571 Vali Loss: 0.3495389 Test Loss: 1.3665664\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 59 cost time: 0.9510190486907959\n","Epoch: 59, Steps: 34 | Train Loss: 0.1196175 Vali Loss: 0.3361844 Test Loss: 1.2806858\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 60 cost time: 0.8797173500061035\n","Epoch: 60, Steps: 34 | Train Loss: 0.1214685 Vali Loss: 0.3487956 Test Loss: 1.2494711\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 61 cost time: 0.890859842300415\n","Epoch: 61, Steps: 34 | Train Loss: 0.1178853 Vali Loss: 0.3487385 Test Loss: 1.1738006\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 62 cost time: 0.8916201591491699\n","Epoch: 62, Steps: 34 | Train Loss: 0.1191939 Vali Loss: 0.3372737 Test Loss: 1.2471864\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 63 cost time: 0.9084091186523438\n","Epoch: 63, Steps: 34 | Train Loss: 0.1153478 Vali Loss: 0.3416928 Test Loss: 1.2662971\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 64 cost time: 0.8902535438537598\n","Epoch: 64, Steps: 34 | Train Loss: 0.1179382 Vali Loss: 0.3661674 Test Loss: 1.2623149\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 65 cost time: 0.9059536457061768\n","Epoch: 65, Steps: 34 | Train Loss: 0.1171860 Vali Loss: 0.3654094 Test Loss: 1.1147697\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 66 cost time: 0.9655144214630127\n","Epoch: 66, Steps: 34 | Train Loss: 0.1187835 Vali Loss: 0.3799918 Test Loss: 1.3001356\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 67 cost time: 0.9207100868225098\n","Epoch: 67, Steps: 34 | Train Loss: 0.1154206 Vali Loss: 0.3554985 Test Loss: 1.2909566\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 68 cost time: 0.8898999691009521\n","Epoch: 68, Steps: 34 | Train Loss: 0.1173397 Vali Loss: 0.3923479 Test Loss: 1.0461222\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 69 cost time: 0.8635907173156738\n","Epoch: 69, Steps: 34 | Train Loss: 0.1137023 Vali Loss: 0.3199781 Test Loss: 1.1753300\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 70 cost time: 0.8870892524719238\n","Epoch: 70, Steps: 34 | Train Loss: 0.1142170 Vali Loss: 0.3504921 Test Loss: 1.2936527\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 71 cost time: 0.8916170597076416\n","Epoch: 71, Steps: 34 | Train Loss: 0.1126527 Vali Loss: 0.3556819 Test Loss: 1.1976793\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 72 cost time: 0.9034903049468994\n","Epoch: 72, Steps: 34 | Train Loss: 0.1092637 Vali Loss: 0.3371553 Test Loss: 1.1981390\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 73 cost time: 0.9460182189941406\n","Epoch: 73, Steps: 34 | Train Loss: 0.1088162 Vali Loss: 0.3709080 Test Loss: 1.0863422\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 74 cost time: 0.936023473739624\n","Epoch: 74, Steps: 34 | Train Loss: 0.1123306 Vali Loss: 0.3604573 Test Loss: 1.2591296\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 75 cost time: 0.9250595569610596\n","Epoch: 75, Steps: 34 | Train Loss: 0.1123751 Vali Loss: 0.3559546 Test Loss: 1.1608081\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 76 cost time: 0.8915629386901855\n","Epoch: 76, Steps: 34 | Train Loss: 0.1163397 Vali Loss: 0.3717312 Test Loss: 1.1955012\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 77 cost time: 0.8880355358123779\n","Epoch: 77, Steps: 34 | Train Loss: 0.1121880 Vali Loss: 0.3282111 Test Loss: 1.3077925\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 78 cost time: 0.920386552810669\n","Epoch: 78, Steps: 34 | Train Loss: 0.1067493 Vali Loss: 0.3200845 Test Loss: 1.2079353\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 79 cost time: 0.8911781311035156\n","Epoch: 79, Steps: 34 | Train Loss: 0.1071047 Vali Loss: 0.3410381 Test Loss: 1.2209504\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 80 cost time: 0.8904626369476318\n","Epoch: 80, Steps: 34 | Train Loss: 0.1075061 Vali Loss: 0.3596023 Test Loss: 1.3080838\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 81 cost time: 0.9881927967071533\n","Epoch: 81, Steps: 34 | Train Loss: 0.1067903 Vali Loss: 0.3439031 Test Loss: 1.2614918\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 82 cost time: 0.9529552459716797\n","Epoch: 82, Steps: 34 | Train Loss: 0.1056334 Vali Loss: 0.3543697 Test Loss: 1.2393409\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 83 cost time: 0.9469165802001953\n","Epoch: 83, Steps: 34 | Train Loss: 0.1051367 Vali Loss: 0.3601889 Test Loss: 1.2321384\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 84 cost time: 0.9052691459655762\n","Epoch: 84, Steps: 34 | Train Loss: 0.1007737 Vali Loss: 0.3407417 Test Loss: 1.1780571\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 85 cost time: 0.8906662464141846\n","Epoch: 85, Steps: 34 | Train Loss: 0.1081655 Vali Loss: 0.3315027 Test Loss: 1.4372461\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 86 cost time: 0.8714947700500488\n","Epoch: 86, Steps: 34 | Train Loss: 0.1120232 Vali Loss: 0.3845274 Test Loss: 1.1534507\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 87 cost time: 0.8776547908782959\n","Epoch: 87, Steps: 34 | Train Loss: 0.1054397 Vali Loss: 0.3167763 Test Loss: 1.2704376\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 88 cost time: 0.9362971782684326\n","Epoch: 88, Steps: 34 | Train Loss: 0.1032022 Vali Loss: 0.3417328 Test Loss: 1.3909967\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 89 cost time: 0.926877498626709\n","Epoch: 89, Steps: 34 | Train Loss: 0.1027739 Vali Loss: 0.3323386 Test Loss: 1.3034986\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 90 cost time: 0.9778842926025391\n","Epoch: 90, Steps: 34 | Train Loss: 0.1003559 Vali Loss: 0.3719171 Test Loss: 1.3592867\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 91 cost time: 0.9104325771331787\n","Epoch: 91, Steps: 34 | Train Loss: 0.1041896 Vali Loss: 0.3453160 Test Loss: 1.2276033\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 92 cost time: 0.9016427993774414\n","Epoch: 92, Steps: 34 | Train Loss: 0.1021585 Vali Loss: 0.3341956 Test Loss: 1.2110082\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 93 cost time: 0.9009742736816406\n","Epoch: 93, Steps: 34 | Train Loss: 0.1020288 Vali Loss: 0.4149760 Test Loss: 1.1961353\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 94 cost time: 0.8855688571929932\n","Epoch: 94, Steps: 34 | Train Loss: 0.0971411 Vali Loss: 0.3577784 Test Loss: 1.3925360\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 95 cost time: 0.9268124103546143\n","Epoch: 95, Steps: 34 | Train Loss: 0.1006435 Vali Loss: 0.3767973 Test Loss: 1.2595427\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 96 cost time: 0.9470949172973633\n","Epoch: 96, Steps: 34 | Train Loss: 0.1065127 Vali Loss: 0.3362639 Test Loss: 1.2421510\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 97 cost time: 0.9761388301849365\n","Epoch: 97, Steps: 34 | Train Loss: 0.1035796 Vali Loss: 0.3407681 Test Loss: 1.1609848\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 98 cost time: 0.9691152572631836\n","Epoch: 98, Steps: 34 | Train Loss: 0.1001204 Vali Loss: 0.3258835 Test Loss: 1.2307018\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 99 cost time: 0.8866736888885498\n","Epoch: 99, Steps: 34 | Train Loss: 0.0982186 Vali Loss: 0.3668153 Test Loss: 1.3979328\n","EarlyStopping counter: 80 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 100 cost time: 0.8771326541900635\n","Epoch: 100, Steps: 34 | Train Loss: 0.1046220 Vali Loss: 0.3532933 Test Loss: 1.4297106\n","EarlyStopping counter: 81 out of 100\n","Updating learning rate to 0.0025\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl24_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 170\n","mse:1.3009638786315918, mae:0.7343998551368713, rse:0.5504330992698669\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl24_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","==================== Now pred_len : 36 ============================ \n","\n"," \n","Use GPU: cuda:0\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl36_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 537\n","val 62\n","test 158\n","Epoch: 1 cost time: 0.8777117729187012\n","Epoch: 1, Steps: 33 | Train Loss: 0.8948408 Vali Loss: 0.2847714 Test Loss: 2.5717380\n","Validation loss decreased (inf --> 0.284771).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 0.8995296955108643\n","Epoch: 2, Steps: 33 | Train Loss: 0.8514591 Vali Loss: 0.3148795 Test Loss: 1.6601853\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 3 cost time: 0.9496927261352539\n","Epoch: 3, Steps: 33 | Train Loss: 0.5287418 Vali Loss: 0.2908958 Test Loss: 1.7722768\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 4 cost time: 0.9248685836791992\n","Epoch: 4, Steps: 33 | Train Loss: 0.4714811 Vali Loss: 0.2314163 Test Loss: 1.9559237\n","Validation loss decreased (0.284771 --> 0.231416).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 5 cost time: 0.9396998882293701\n","Epoch: 5, Steps: 33 | Train Loss: 0.4349714 Vali Loss: 0.3409328 Test Loss: 1.8590902\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 6 cost time: 0.9376785755157471\n","Epoch: 6, Steps: 33 | Train Loss: 0.4050054 Vali Loss: 0.2994710 Test Loss: 2.0361223\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 7 cost time: 0.9029390811920166\n","Epoch: 7, Steps: 33 | Train Loss: 0.3760752 Vali Loss: 0.2639305 Test Loss: 1.5809833\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 8 cost time: 0.9478113651275635\n","Epoch: 8, Steps: 33 | Train Loss: 0.3363826 Vali Loss: 0.2356450 Test Loss: 1.7986113\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 9 cost time: 0.9038331508636475\n","Epoch: 9, Steps: 33 | Train Loss: 0.3233644 Vali Loss: 0.2091163 Test Loss: 1.3386277\n","Validation loss decreased (0.231416 --> 0.209116).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 10 cost time: 0.9597091674804688\n","Epoch: 10, Steps: 33 | Train Loss: 0.3123112 Vali Loss: 0.2567482 Test Loss: 1.8268971\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 11 cost time: 0.9471969604492188\n","Epoch: 11, Steps: 33 | Train Loss: 0.2899000 Vali Loss: 0.1857327 Test Loss: 1.2477820\n","Validation loss decreased (0.209116 --> 0.185733).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 12 cost time: 0.9334883689880371\n","Epoch: 12, Steps: 33 | Train Loss: 0.2757562 Vali Loss: 0.2338028 Test Loss: 1.5047668\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 13 cost time: 0.9174864292144775\n","Epoch: 13, Steps: 33 | Train Loss: 0.2686139 Vali Loss: 0.2593082 Test Loss: 1.5577458\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 14 cost time: 0.9259860515594482\n","Epoch: 14, Steps: 33 | Train Loss: 0.2672291 Vali Loss: 0.2326853 Test Loss: 1.2042239\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 15 cost time: 0.8854751586914062\n","Epoch: 15, Steps: 33 | Train Loss: 0.2494979 Vali Loss: 0.1894912 Test Loss: 1.4660078\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 16 cost time: 0.9400634765625\n","Epoch: 16, Steps: 33 | Train Loss: 0.2457417 Vali Loss: 0.2334990 Test Loss: 1.1926395\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 17 cost time: 0.9588561058044434\n","Epoch: 17, Steps: 33 | Train Loss: 0.2361537 Vali Loss: 0.2072378 Test Loss: 1.4195678\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 18 cost time: 0.985501766204834\n","Epoch: 18, Steps: 33 | Train Loss: 0.2316315 Vali Loss: 0.2153819 Test Loss: 1.1233879\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 19 cost time: 0.9403543472290039\n","Epoch: 19, Steps: 33 | Train Loss: 0.2311187 Vali Loss: 0.2076247 Test Loss: 1.2855991\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 20 cost time: 0.9163591861724854\n","Epoch: 20, Steps: 33 | Train Loss: 0.2181634 Vali Loss: 0.2694993 Test Loss: 1.4239972\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 21 cost time: 0.9049026966094971\n","Epoch: 21, Steps: 33 | Train Loss: 0.2080920 Vali Loss: 0.2185994 Test Loss: 1.2535828\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 22 cost time: 1.1517696380615234\n","Epoch: 22, Steps: 33 | Train Loss: 0.2208055 Vali Loss: 0.2350163 Test Loss: 1.3790299\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 23 cost time: 0.9413220882415771\n","Epoch: 23, Steps: 33 | Train Loss: 0.2104993 Vali Loss: 0.2220842 Test Loss: 1.0967886\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 24 cost time: 0.9464473724365234\n","Epoch: 24, Steps: 33 | Train Loss: 0.2112623 Vali Loss: 0.2618198 Test Loss: 1.2542422\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 25 cost time: 1.0030577182769775\n","Epoch: 25, Steps: 33 | Train Loss: 0.1929555 Vali Loss: 0.2435934 Test Loss: 1.3154848\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 26 cost time: 0.927940845489502\n","Epoch: 26, Steps: 33 | Train Loss: 0.1938914 Vali Loss: 0.2242069 Test Loss: 1.1680700\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 27 cost time: 0.9591729640960693\n","Epoch: 27, Steps: 33 | Train Loss: 0.1980418 Vali Loss: 0.2229756 Test Loss: 1.1719489\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 28 cost time: 0.9180526733398438\n","Epoch: 28, Steps: 33 | Train Loss: 0.1855471 Vali Loss: 0.2421239 Test Loss: 1.2639422\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 29 cost time: 0.9107561111450195\n","Epoch: 29, Steps: 33 | Train Loss: 0.1889315 Vali Loss: 0.2892342 Test Loss: 1.2086658\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 30 cost time: 0.9221885204315186\n","Epoch: 30, Steps: 33 | Train Loss: 0.1756383 Vali Loss: 0.2188907 Test Loss: 1.2087085\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 31 cost time: 0.9009408950805664\n","Epoch: 31, Steps: 33 | Train Loss: 0.1786800 Vali Loss: 0.2377386 Test Loss: 1.1658025\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 32 cost time: 0.9443657398223877\n","Epoch: 32, Steps: 33 | Train Loss: 0.1939209 Vali Loss: 0.2969426 Test Loss: 1.5612799\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 33 cost time: 0.9969377517700195\n","Epoch: 33, Steps: 33 | Train Loss: 0.1852452 Vali Loss: 0.2477543 Test Loss: 1.2011716\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 34 cost time: 0.9423463344573975\n","Epoch: 34, Steps: 33 | Train Loss: 0.1967072 Vali Loss: 0.3011378 Test Loss: 1.5737494\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 35 cost time: 0.926098108291626\n","Epoch: 35, Steps: 33 | Train Loss: 0.1890203 Vali Loss: 0.2875220 Test Loss: 1.1904466\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 36 cost time: 0.8959221839904785\n","Epoch: 36, Steps: 33 | Train Loss: 0.1718640 Vali Loss: 0.2628271 Test Loss: 1.2761438\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 37 cost time: 0.9230921268463135\n","Epoch: 37, Steps: 33 | Train Loss: 0.1718540 Vali Loss: 0.2558683 Test Loss: 1.2509046\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 38 cost time: 0.9387600421905518\n","Epoch: 38, Steps: 33 | Train Loss: 0.1703676 Vali Loss: 0.2396641 Test Loss: 1.1910102\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 39 cost time: 0.9488441944122314\n","Epoch: 39, Steps: 33 | Train Loss: 0.1666929 Vali Loss: 0.2674279 Test Loss: 1.1154330\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 40 cost time: 1.0389015674591064\n","Epoch: 40, Steps: 33 | Train Loss: 0.1651178 Vali Loss: 0.2651469 Test Loss: 1.3245006\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 41 cost time: 1.0127074718475342\n","Epoch: 41, Steps: 33 | Train Loss: 0.1620249 Vali Loss: 0.2644359 Test Loss: 1.1604444\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 42 cost time: 0.9313201904296875\n","Epoch: 42, Steps: 33 | Train Loss: 0.1602664 Vali Loss: 0.2570617 Test Loss: 1.2352943\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 43 cost time: 0.9139695167541504\n","Epoch: 43, Steps: 33 | Train Loss: 0.1586155 Vali Loss: 0.2764681 Test Loss: 1.3532734\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 44 cost time: 0.921562671661377\n","Epoch: 44, Steps: 33 | Train Loss: 0.1593544 Vali Loss: 0.2685831 Test Loss: 1.1527301\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 45 cost time: 0.9212028980255127\n","Epoch: 45, Steps: 33 | Train Loss: 0.1531278 Vali Loss: 0.2605925 Test Loss: 1.1857989\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 46 cost time: 0.8991365432739258\n","Epoch: 46, Steps: 33 | Train Loss: 0.1595355 Vali Loss: 0.2765080 Test Loss: 1.3064985\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 47 cost time: 0.9406321048736572\n","Epoch: 47, Steps: 33 | Train Loss: 0.1665195 Vali Loss: 0.2793988 Test Loss: 1.1627517\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 48 cost time: 0.9548113346099854\n","Epoch: 48, Steps: 33 | Train Loss: 0.1589879 Vali Loss: 0.3064442 Test Loss: 1.3679247\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 49 cost time: 0.9671428203582764\n","Epoch: 49, Steps: 33 | Train Loss: 0.1568416 Vali Loss: 0.2964489 Test Loss: 1.1452359\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 50 cost time: 0.9274396896362305\n","Epoch: 50, Steps: 33 | Train Loss: 0.1482953 Vali Loss: 0.2999799 Test Loss: 1.0990251\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 51 cost time: 0.9290740489959717\n","Epoch: 51, Steps: 33 | Train Loss: 0.1460588 Vali Loss: 0.2684639 Test Loss: 1.2958812\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 52 cost time: 0.9085597991943359\n","Epoch: 52, Steps: 33 | Train Loss: 0.1564135 Vali Loss: 0.2710539 Test Loss: 1.1140169\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 53 cost time: 0.9670124053955078\n","Epoch: 53, Steps: 33 | Train Loss: 0.1483193 Vali Loss: 0.2600971 Test Loss: 1.2879509\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 54 cost time: 0.9235434532165527\n","Epoch: 54, Steps: 33 | Train Loss: 0.1490273 Vali Loss: 0.2822545 Test Loss: 1.2462434\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 55 cost time: 0.9907116889953613\n","Epoch: 55, Steps: 33 | Train Loss: 0.1501144 Vali Loss: 0.2512014 Test Loss: 1.1740315\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 56 cost time: 0.9877917766571045\n","Epoch: 56, Steps: 33 | Train Loss: 0.1500640 Vali Loss: 0.2480505 Test Loss: 1.1658578\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 57 cost time: 0.9053049087524414\n","Epoch: 57, Steps: 33 | Train Loss: 0.1531109 Vali Loss: 0.2981761 Test Loss: 1.0636374\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 58 cost time: 0.8807218074798584\n","Epoch: 58, Steps: 33 | Train Loss: 0.1446090 Vali Loss: 0.2653844 Test Loss: 1.2632284\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 59 cost time: 0.9074411392211914\n","Epoch: 59, Steps: 33 | Train Loss: 0.1459993 Vali Loss: 0.2735656 Test Loss: 1.1415733\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 60 cost time: 0.9310414791107178\n","Epoch: 60, Steps: 33 | Train Loss: 0.1373178 Vali Loss: 0.2875748 Test Loss: 1.1805317\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 61 cost time: 0.9073078632354736\n","Epoch: 61, Steps: 33 | Train Loss: 0.1426404 Vali Loss: 0.2610897 Test Loss: 1.2576967\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 62 cost time: 0.9405193328857422\n","Epoch: 62, Steps: 33 | Train Loss: 0.1389150 Vali Loss: 0.2581657 Test Loss: 0.9815292\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 63 cost time: 0.9512944221496582\n","Epoch: 63, Steps: 33 | Train Loss: 0.1399620 Vali Loss: 0.2656781 Test Loss: 1.1889845\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 64 cost time: 0.970768928527832\n","Epoch: 64, Steps: 33 | Train Loss: 0.1544491 Vali Loss: 0.2804239 Test Loss: 1.3104497\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 65 cost time: 0.8909385204315186\n","Epoch: 65, Steps: 33 | Train Loss: 0.1624087 Vali Loss: 0.2945803 Test Loss: 1.3611616\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 66 cost time: 0.9447965621948242\n","Epoch: 66, Steps: 33 | Train Loss: 0.1502551 Vali Loss: 0.2610814 Test Loss: 1.0882553\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 67 cost time: 0.922452449798584\n","Epoch: 67, Steps: 33 | Train Loss: 0.1404378 Vali Loss: 0.2694260 Test Loss: 1.1561053\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 68 cost time: 0.8927350044250488\n","Epoch: 68, Steps: 33 | Train Loss: 0.1325123 Vali Loss: 0.2991005 Test Loss: 1.3046556\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 69 cost time: 0.9368534088134766\n","Epoch: 69, Steps: 33 | Train Loss: 0.1419566 Vali Loss: 0.2850253 Test Loss: 1.0763874\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 70 cost time: 0.9862289428710938\n","Epoch: 70, Steps: 33 | Train Loss: 0.1392356 Vali Loss: 0.2578904 Test Loss: 1.1156524\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 71 cost time: 0.9540464878082275\n","Epoch: 71, Steps: 33 | Train Loss: 0.1306326 Vali Loss: 0.2736211 Test Loss: 1.1352379\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 72 cost time: 0.9495334625244141\n","Epoch: 72, Steps: 33 | Train Loss: 0.1374845 Vali Loss: 0.2564223 Test Loss: 1.0987673\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 73 cost time: 0.911099910736084\n","Epoch: 73, Steps: 33 | Train Loss: 0.1322512 Vali Loss: 0.3147328 Test Loss: 1.2196075\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 74 cost time: 0.8944981098175049\n","Epoch: 74, Steps: 33 | Train Loss: 0.1315868 Vali Loss: 0.3368708 Test Loss: 1.3382819\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 75 cost time: 0.9069428443908691\n","Epoch: 75, Steps: 33 | Train Loss: 0.1413439 Vali Loss: 0.2739603 Test Loss: 1.1402642\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 76 cost time: 0.9062967300415039\n","Epoch: 76, Steps: 33 | Train Loss: 0.1319837 Vali Loss: 0.2795360 Test Loss: 1.0945290\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 77 cost time: 0.9997642040252686\n","Epoch: 77, Steps: 33 | Train Loss: 0.1281040 Vali Loss: 0.2728671 Test Loss: 1.2442615\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 78 cost time: 0.9796814918518066\n","Epoch: 78, Steps: 33 | Train Loss: 0.1186350 Vali Loss: 0.2996849 Test Loss: 1.2156332\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 79 cost time: 0.9348459243774414\n","Epoch: 79, Steps: 33 | Train Loss: 0.1272743 Vali Loss: 0.2934839 Test Loss: 1.2950511\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 80 cost time: 0.9529521465301514\n","Epoch: 80, Steps: 33 | Train Loss: 0.1276675 Vali Loss: 0.2967234 Test Loss: 1.2110190\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 81 cost time: 0.9347484111785889\n","Epoch: 81, Steps: 33 | Train Loss: 0.1290913 Vali Loss: 0.3049602 Test Loss: 1.1924803\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 82 cost time: 0.9432189464569092\n","Epoch: 82, Steps: 33 | Train Loss: 0.1304635 Vali Loss: 0.2775453 Test Loss: 1.1643214\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 83 cost time: 0.9398138523101807\n","Epoch: 83, Steps: 33 | Train Loss: 0.1291510 Vali Loss: 0.3118710 Test Loss: 1.1596215\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 84 cost time: 0.9394612312316895\n","Epoch: 84, Steps: 33 | Train Loss: 0.1191218 Vali Loss: 0.2772964 Test Loss: 1.1892095\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 85 cost time: 0.9878170490264893\n","Epoch: 85, Steps: 33 | Train Loss: 0.1318712 Vali Loss: 0.2642311 Test Loss: 1.1722476\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 86 cost time: 0.9916284084320068\n","Epoch: 86, Steps: 33 | Train Loss: 0.1216921 Vali Loss: 0.2770469 Test Loss: 1.0747924\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 87 cost time: 0.8954823017120361\n","Epoch: 87, Steps: 33 | Train Loss: 0.1258567 Vali Loss: 0.3297249 Test Loss: 1.1451010\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 88 cost time: 0.9609906673431396\n","Epoch: 88, Steps: 33 | Train Loss: 0.1286372 Vali Loss: 0.2726330 Test Loss: 1.1860175\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 89 cost time: 0.889380931854248\n","Epoch: 89, Steps: 33 | Train Loss: 0.1189950 Vali Loss: 0.2801872 Test Loss: 1.1129240\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 90 cost time: 0.9047079086303711\n","Epoch: 90, Steps: 33 | Train Loss: 0.1148167 Vali Loss: 0.2930724 Test Loss: 1.1719987\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 91 cost time: 0.9010703563690186\n","Epoch: 91, Steps: 33 | Train Loss: 0.1164331 Vali Loss: 0.2576798 Test Loss: 1.1062018\n","EarlyStopping counter: 80 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 92 cost time: 0.9333248138427734\n","Epoch: 92, Steps: 33 | Train Loss: 0.1248090 Vali Loss: 0.3086470 Test Loss: 1.2181513\n","EarlyStopping counter: 81 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 93 cost time: 0.9536192417144775\n","Epoch: 93, Steps: 33 | Train Loss: 0.1155040 Vali Loss: 0.2666042 Test Loss: 1.1572480\n","EarlyStopping counter: 82 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 94 cost time: 0.9188742637634277\n","Epoch: 94, Steps: 33 | Train Loss: 0.1149947 Vali Loss: 0.3127223 Test Loss: 1.2604947\n","EarlyStopping counter: 83 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 95 cost time: 0.8710067272186279\n","Epoch: 95, Steps: 33 | Train Loss: 0.1202839 Vali Loss: 0.2874318 Test Loss: 1.1449596\n","EarlyStopping counter: 84 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 96 cost time: 0.8942992687225342\n","Epoch: 96, Steps: 33 | Train Loss: 0.1180884 Vali Loss: 0.2868890 Test Loss: 1.1614450\n","EarlyStopping counter: 85 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 97 cost time: 0.9388828277587891\n","Epoch: 97, Steps: 33 | Train Loss: 0.1166322 Vali Loss: 0.2994784 Test Loss: 1.3491449\n","EarlyStopping counter: 86 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 98 cost time: 0.9237594604492188\n","Epoch: 98, Steps: 33 | Train Loss: 0.1164147 Vali Loss: 0.3157883 Test Loss: 1.1049858\n","EarlyStopping counter: 87 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 99 cost time: 0.9485366344451904\n","Epoch: 99, Steps: 33 | Train Loss: 0.1101893 Vali Loss: 0.2948461 Test Loss: 1.2716688\n","EarlyStopping counter: 88 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 100 cost time: 0.9846992492675781\n","Epoch: 100, Steps: 33 | Train Loss: 0.1208385 Vali Loss: 0.2884065 Test Loss: 1.0223083\n","EarlyStopping counter: 89 out of 100\n","Updating learning rate to 0.0025\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl36_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 158\n","mse:1.2477819919586182, mae:0.767732560634613, rse:0.5357415676116943\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl36_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","==================== Now pred_len : 48 ============================ \n","\n"," \n","Use GPU: cuda:0\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl48_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 525\n","val 50\n","test 146\n","Epoch: 1 cost time: 0.8823626041412354\n","Epoch: 1, Steps: 32 | Train Loss: 0.9649037 Vali Loss: 0.3438688 Test Loss: 2.7743871\n","Validation loss decreased (inf --> 0.343869).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 0.8561770915985107\n","Epoch: 2, Steps: 32 | Train Loss: 0.8570002 Vali Loss: 0.3736660 Test Loss: 1.8844666\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 3 cost time: 0.8862268924713135\n","Epoch: 3, Steps: 32 | Train Loss: 0.5766101 Vali Loss: 0.2725544 Test Loss: 1.6886585\n","Validation loss decreased (0.343869 --> 0.272554).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 4 cost time: 0.8750345706939697\n","Epoch: 4, Steps: 32 | Train Loss: 0.5029668 Vali Loss: 0.2837580 Test Loss: 2.0202775\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 5 cost time: 0.8947672843933105\n","Epoch: 5, Steps: 32 | Train Loss: 0.4557462 Vali Loss: 0.2582391 Test Loss: 2.1095302\n","Validation loss decreased (0.272554 --> 0.258239).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 6 cost time: 0.9333786964416504\n","Epoch: 6, Steps: 32 | Train Loss: 0.4400783 Vali Loss: 0.2825071 Test Loss: 1.9060934\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 7 cost time: 1.0079288482666016\n","Epoch: 7, Steps: 32 | Train Loss: 0.3950828 Vali Loss: 0.2419789 Test Loss: 1.7888650\n","Validation loss decreased (0.258239 --> 0.241979).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 8 cost time: 0.9425415992736816\n","Epoch: 8, Steps: 32 | Train Loss: 0.3600409 Vali Loss: 0.2042654 Test Loss: 1.6830639\n","Validation loss decreased (0.241979 --> 0.204265).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 9 cost time: 0.8795030117034912\n","Epoch: 9, Steps: 32 | Train Loss: 0.3469095 Vali Loss: 0.2281904 Test Loss: 1.8526872\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 10 cost time: 0.8841860294342041\n","Epoch: 10, Steps: 32 | Train Loss: 0.3396557 Vali Loss: 0.2809365 Test Loss: 1.7337918\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 11 cost time: 0.884465217590332\n","Epoch: 11, Steps: 32 | Train Loss: 0.3128468 Vali Loss: 0.2667180 Test Loss: 1.6154202\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 12 cost time: 0.8789808750152588\n","Epoch: 12, Steps: 32 | Train Loss: 0.2927908 Vali Loss: 0.2187696 Test Loss: 1.7313653\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 13 cost time: 0.8801918029785156\n","Epoch: 13, Steps: 32 | Train Loss: 0.2946218 Vali Loss: 0.2944810 Test Loss: 1.7413943\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 14 cost time: 0.9335551261901855\n","Epoch: 14, Steps: 32 | Train Loss: 0.2908129 Vali Loss: 0.3416340 Test Loss: 1.8041872\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 15 cost time: 0.8982758522033691\n","Epoch: 15, Steps: 32 | Train Loss: 0.2851290 Vali Loss: 0.2343430 Test Loss: 1.5753577\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 16 cost time: 0.9434545040130615\n","Epoch: 16, Steps: 32 | Train Loss: 0.2561092 Vali Loss: 0.2364153 Test Loss: 1.4760327\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 17 cost time: 0.9134910106658936\n","Epoch: 17, Steps: 32 | Train Loss: 0.2574979 Vali Loss: 0.2428229 Test Loss: 1.5819541\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 18 cost time: 0.9033639430999756\n","Epoch: 18, Steps: 32 | Train Loss: 0.2235701 Vali Loss: 0.2384528 Test Loss: 1.4881129\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 19 cost time: 0.9447803497314453\n","Epoch: 19, Steps: 32 | Train Loss: 0.2302625 Vali Loss: 0.2671278 Test Loss: 1.4668707\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 20 cost time: 0.8883528709411621\n","Epoch: 20, Steps: 32 | Train Loss: 0.2400873 Vali Loss: 0.2998104 Test Loss: 1.6242696\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 21 cost time: 0.9336073398590088\n","Epoch: 21, Steps: 32 | Train Loss: 0.2543367 Vali Loss: 0.2317129 Test Loss: 1.5718544\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 22 cost time: 0.9316823482513428\n","Epoch: 22, Steps: 32 | Train Loss: 0.2241487 Vali Loss: 0.2661136 Test Loss: 1.5689071\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 23 cost time: 0.9234552383422852\n","Epoch: 23, Steps: 32 | Train Loss: 0.2133513 Vali Loss: 0.2654091 Test Loss: 1.5299300\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 24 cost time: 0.8656761646270752\n","Epoch: 24, Steps: 32 | Train Loss: 0.2163220 Vali Loss: 0.2763719 Test Loss: 1.4957781\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 25 cost time: 0.9065220355987549\n","Epoch: 25, Steps: 32 | Train Loss: 0.2196180 Vali Loss: 0.3124400 Test Loss: 1.4042618\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 26 cost time: 0.889735221862793\n","Epoch: 26, Steps: 32 | Train Loss: 0.2202637 Vali Loss: 0.2661212 Test Loss: 1.4674115\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 27 cost time: 0.8700177669525146\n","Epoch: 27, Steps: 32 | Train Loss: 0.2034701 Vali Loss: 0.3141384 Test Loss: 1.5628444\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 28 cost time: 0.8870258331298828\n","Epoch: 28, Steps: 32 | Train Loss: 0.2121448 Vali Loss: 0.2636376 Test Loss: 1.5154672\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 29 cost time: 0.9297196865081787\n","Epoch: 29, Steps: 32 | Train Loss: 0.2015244 Vali Loss: 0.3162813 Test Loss: 1.5077630\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 30 cost time: 0.922548770904541\n","Epoch: 30, Steps: 32 | Train Loss: 0.1975276 Vali Loss: 0.2551896 Test Loss: 1.5046201\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 31 cost time: 0.8926682472229004\n","Epoch: 31, Steps: 32 | Train Loss: 0.1895590 Vali Loss: 0.2951430 Test Loss: 1.4336118\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 32 cost time: 0.907489538192749\n","Epoch: 32, Steps: 32 | Train Loss: 0.2062545 Vali Loss: 0.2964227 Test Loss: 1.5755612\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 33 cost time: 0.901648759841919\n","Epoch: 33, Steps: 32 | Train Loss: 0.1986200 Vali Loss: 0.2816324 Test Loss: 1.4902118\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 34 cost time: 0.8595247268676758\n","Epoch: 34, Steps: 32 | Train Loss: 0.1943394 Vali Loss: 0.2712485 Test Loss: 1.4605542\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 35 cost time: 0.9096777439117432\n","Epoch: 35, Steps: 32 | Train Loss: 0.1883727 Vali Loss: 0.2948268 Test Loss: 1.4929533\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 36 cost time: 0.8885095119476318\n","Epoch: 36, Steps: 32 | Train Loss: 0.1943256 Vali Loss: 0.2900479 Test Loss: 1.4612130\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 37 cost time: 0.9266722202301025\n","Epoch: 37, Steps: 32 | Train Loss: 0.1893575 Vali Loss: 0.3048620 Test Loss: 1.4094801\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 38 cost time: 0.9108219146728516\n","Epoch: 38, Steps: 32 | Train Loss: 0.1832380 Vali Loss: 0.2543829 Test Loss: 1.5533032\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 39 cost time: 0.8900954723358154\n","Epoch: 39, Steps: 32 | Train Loss: 0.1805265 Vali Loss: 0.2943410 Test Loss: 1.4334409\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 40 cost time: 0.885568380355835\n","Epoch: 40, Steps: 32 | Train Loss: 0.1853777 Vali Loss: 0.2812903 Test Loss: 1.4752914\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 41 cost time: 0.9018597602844238\n","Epoch: 41, Steps: 32 | Train Loss: 0.1851334 Vali Loss: 0.2655347 Test Loss: 1.4834592\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 42 cost time: 0.874335527420044\n","Epoch: 42, Steps: 32 | Train Loss: 0.1751390 Vali Loss: 0.2955085 Test Loss: 1.4481533\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 43 cost time: 0.9029929637908936\n","Epoch: 43, Steps: 32 | Train Loss: 0.1714417 Vali Loss: 0.2740444 Test Loss: 1.4547030\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 44 cost time: 0.9352805614471436\n","Epoch: 44, Steps: 32 | Train Loss: 0.1679340 Vali Loss: 0.2685978 Test Loss: 1.4803834\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 45 cost time: 0.9400036334991455\n","Epoch: 45, Steps: 32 | Train Loss: 0.1682110 Vali Loss: 0.2758352 Test Loss: 1.4753288\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 46 cost time: 0.9191501140594482\n","Epoch: 46, Steps: 32 | Train Loss: 0.1651512 Vali Loss: 0.3004580 Test Loss: 1.4463207\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 47 cost time: 0.87581467628479\n","Epoch: 47, Steps: 32 | Train Loss: 0.1658922 Vali Loss: 0.2737058 Test Loss: 1.4948838\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 48 cost time: 0.8849313259124756\n","Epoch: 48, Steps: 32 | Train Loss: 0.1704653 Vali Loss: 0.2637176 Test Loss: 1.5159037\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 49 cost time: 0.8647770881652832\n","Epoch: 49, Steps: 32 | Train Loss: 0.1667876 Vali Loss: 0.2951170 Test Loss: 1.3988355\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 50 cost time: 0.8945598602294922\n","Epoch: 50, Steps: 32 | Train Loss: 0.1745650 Vali Loss: 0.3186696 Test Loss: 1.4829631\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 51 cost time: 0.8880763053894043\n","Epoch: 51, Steps: 32 | Train Loss: 0.1620352 Vali Loss: 0.2646256 Test Loss: 1.4562172\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 52 cost time: 0.9161803722381592\n","Epoch: 52, Steps: 32 | Train Loss: 0.1622318 Vali Loss: 0.2971078 Test Loss: 1.5574460\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 53 cost time: 0.967949390411377\n","Epoch: 53, Steps: 32 | Train Loss: 0.1602129 Vali Loss: 0.2550243 Test Loss: 1.4815030\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 54 cost time: 0.9009997844696045\n","Epoch: 54, Steps: 32 | Train Loss: 0.1570528 Vali Loss: 0.3453500 Test Loss: 1.4046718\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 55 cost time: 0.916517972946167\n","Epoch: 55, Steps: 32 | Train Loss: 0.1556699 Vali Loss: 0.2586482 Test Loss: 1.5720394\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 56 cost time: 0.9132096767425537\n","Epoch: 56, Steps: 32 | Train Loss: 0.1630509 Vali Loss: 0.3005161 Test Loss: 1.4682707\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 57 cost time: 0.8859107494354248\n","Epoch: 57, Steps: 32 | Train Loss: 0.1508530 Vali Loss: 0.2999972 Test Loss: 1.3897899\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 58 cost time: 0.8838369846343994\n","Epoch: 58, Steps: 32 | Train Loss: 0.1519603 Vali Loss: 0.3130381 Test Loss: 1.5347122\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 59 cost time: 0.9453535079956055\n","Epoch: 59, Steps: 32 | Train Loss: 0.1552639 Vali Loss: 0.2751592 Test Loss: 1.4338766\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 60 cost time: 0.9699585437774658\n","Epoch: 60, Steps: 32 | Train Loss: 0.1475965 Vali Loss: 0.3164042 Test Loss: 1.4178816\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 61 cost time: 0.9436039924621582\n","Epoch: 61, Steps: 32 | Train Loss: 0.1555838 Vali Loss: 0.2712232 Test Loss: 1.4515557\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 62 cost time: 0.8937733173370361\n","Epoch: 62, Steps: 32 | Train Loss: 0.1465047 Vali Loss: 0.2800283 Test Loss: 1.5358961\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 63 cost time: 0.9057133197784424\n","Epoch: 63, Steps: 32 | Train Loss: 0.1515106 Vali Loss: 0.3134390 Test Loss: 1.4727529\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 64 cost time: 0.9119601249694824\n","Epoch: 64, Steps: 32 | Train Loss: 0.1504118 Vali Loss: 0.2672975 Test Loss: 1.4659926\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 65 cost time: 0.9045331478118896\n","Epoch: 65, Steps: 32 | Train Loss: 0.1402079 Vali Loss: 0.2864770 Test Loss: 1.4670377\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 66 cost time: 0.925551176071167\n","Epoch: 66, Steps: 32 | Train Loss: 0.1459694 Vali Loss: 0.2780932 Test Loss: 1.5586795\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 67 cost time: 0.9252760410308838\n","Epoch: 67, Steps: 32 | Train Loss: 0.1404272 Vali Loss: 0.2893029 Test Loss: 1.4737875\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 68 cost time: 0.9112207889556885\n","Epoch: 68, Steps: 32 | Train Loss: 0.1394007 Vali Loss: 0.3165716 Test Loss: 1.4639478\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 69 cost time: 0.8931803703308105\n","Epoch: 69, Steps: 32 | Train Loss: 0.1509171 Vali Loss: 0.2744840 Test Loss: 1.5035144\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 70 cost time: 0.9295680522918701\n","Epoch: 70, Steps: 32 | Train Loss: 0.1357159 Vali Loss: 0.2863754 Test Loss: 1.4178810\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 71 cost time: 0.8908119201660156\n","Epoch: 71, Steps: 32 | Train Loss: 0.1380863 Vali Loss: 0.2721694 Test Loss: 1.5752079\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 72 cost time: 0.9030005931854248\n","Epoch: 72, Steps: 32 | Train Loss: 0.1402959 Vali Loss: 0.3005521 Test Loss: 1.4391652\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 73 cost time: 0.9076378345489502\n","Epoch: 73, Steps: 32 | Train Loss: 0.1388995 Vali Loss: 0.2916838 Test Loss: 1.4491249\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 74 cost time: 0.8927485942840576\n","Epoch: 74, Steps: 32 | Train Loss: 0.1281355 Vali Loss: 0.2902507 Test Loss: 1.4605685\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 75 cost time: 0.9033265113830566\n","Epoch: 75, Steps: 32 | Train Loss: 0.1446027 Vali Loss: 0.2880231 Test Loss: 1.4601067\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 76 cost time: 0.9371864795684814\n","Epoch: 76, Steps: 32 | Train Loss: 0.1552392 Vali Loss: 0.2390279 Test Loss: 1.5703168\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 77 cost time: 0.9012875556945801\n","Epoch: 77, Steps: 32 | Train Loss: 0.1520183 Vali Loss: 0.3464022 Test Loss: 1.3727670\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 78 cost time: 0.9189085960388184\n","Epoch: 78, Steps: 32 | Train Loss: 0.1377721 Vali Loss: 0.2980476 Test Loss: 1.5453972\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 79 cost time: 0.8806369304656982\n","Epoch: 79, Steps: 32 | Train Loss: 0.1363795 Vali Loss: 0.3068276 Test Loss: 1.5056249\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 80 cost time: 0.9032351970672607\n","Epoch: 80, Steps: 32 | Train Loss: 0.1426490 Vali Loss: 0.2597927 Test Loss: 1.5494312\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 81 cost time: 0.910261869430542\n","Epoch: 81, Steps: 32 | Train Loss: 0.1342393 Vali Loss: 0.2727700 Test Loss: 1.4773914\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 82 cost time: 0.9271836280822754\n","Epoch: 82, Steps: 32 | Train Loss: 0.1310708 Vali Loss: 0.3190303 Test Loss: 1.4114100\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 83 cost time: 0.9169223308563232\n","Epoch: 83, Steps: 32 | Train Loss: 0.1285922 Vali Loss: 0.2782893 Test Loss: 1.5371211\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 84 cost time: 0.9068574905395508\n","Epoch: 84, Steps: 32 | Train Loss: 0.1307982 Vali Loss: 0.2780631 Test Loss: 1.5343803\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 85 cost time: 0.8790910243988037\n","Epoch: 85, Steps: 32 | Train Loss: 0.1271374 Vali Loss: 0.2924785 Test Loss: 1.4578288\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 86 cost time: 0.9047117233276367\n","Epoch: 86, Steps: 32 | Train Loss: 0.1228845 Vali Loss: 0.2709888 Test Loss: 1.4913251\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 87 cost time: 0.8937749862670898\n","Epoch: 87, Steps: 32 | Train Loss: 0.1226024 Vali Loss: 0.2630615 Test Loss: 1.5385818\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 88 cost time: 0.8835041522979736\n","Epoch: 88, Steps: 32 | Train Loss: 0.1282968 Vali Loss: 0.2675906 Test Loss: 1.4942145\n","EarlyStopping counter: 80 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 89 cost time: 0.9225952625274658\n","Epoch: 89, Steps: 32 | Train Loss: 0.1274957 Vali Loss: 0.2790142 Test Loss: 1.5106766\n","EarlyStopping counter: 81 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 90 cost time: 0.9117238521575928\n","Epoch: 90, Steps: 32 | Train Loss: 0.1380757 Vali Loss: 0.3120461 Test Loss: 1.3825216\n","EarlyStopping counter: 82 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 91 cost time: 0.9494912624359131\n","Epoch: 91, Steps: 32 | Train Loss: 0.1329750 Vali Loss: 0.3059067 Test Loss: 1.5040357\n","EarlyStopping counter: 83 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 92 cost time: 0.8844351768493652\n","Epoch: 92, Steps: 32 | Train Loss: 0.1230483 Vali Loss: 0.2861941 Test Loss: 1.4967840\n","EarlyStopping counter: 84 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 93 cost time: 0.9046099185943604\n","Epoch: 93, Steps: 32 | Train Loss: 0.1202503 Vali Loss: 0.2780304 Test Loss: 1.4873919\n","EarlyStopping counter: 85 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 94 cost time: 0.9231953620910645\n","Epoch: 94, Steps: 32 | Train Loss: 0.1233768 Vali Loss: 0.2873424 Test Loss: 1.4921956\n","EarlyStopping counter: 86 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 95 cost time: 0.9222290515899658\n","Epoch: 95, Steps: 32 | Train Loss: 0.1233247 Vali Loss: 0.2830391 Test Loss: 1.5218163\n","EarlyStopping counter: 87 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 96 cost time: 0.903217077255249\n","Epoch: 96, Steps: 32 | Train Loss: 0.1204785 Vali Loss: 0.2982022 Test Loss: 1.4894195\n","EarlyStopping counter: 88 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 97 cost time: 0.9252254962921143\n","Epoch: 97, Steps: 32 | Train Loss: 0.1276941 Vali Loss: 0.2709248 Test Loss: 1.5164236\n","EarlyStopping counter: 89 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 98 cost time: 0.9283435344696045\n","Epoch: 98, Steps: 32 | Train Loss: 0.1184792 Vali Loss: 0.2942785 Test Loss: 1.4070584\n","EarlyStopping counter: 90 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 99 cost time: 1.1929469108581543\n","Epoch: 99, Steps: 32 | Train Loss: 0.1192407 Vali Loss: 0.2949937 Test Loss: 1.5398210\n","EarlyStopping counter: 91 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 100 cost time: 0.9137766361236572\n","Epoch: 100, Steps: 32 | Train Loss: 0.1238035 Vali Loss: 0.2974062 Test Loss: 1.4711684\n","EarlyStopping counter: 92 out of 100\n","Updating learning rate to 0.0025\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl48_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 146\n","mse:1.6830638647079468, mae:0.8623887896537781, rse:0.6205892562866211\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl48_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n","==================== Now pred_len : 60 ============================ \n","\n"," \n","Use GPU: cuda:0\n",">>>>>>>start training : national_illness_PatchTST_custom_ftM_sl104_ll48_pl60_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 513\n","val 38\n","test 134\n","Epoch: 1 cost time: 0.9207696914672852\n","Epoch: 1, Steps: 32 | Train Loss: 0.9555920 Vali Loss: 0.3152253 Test Loss: 2.7444255\n","Validation loss decreased (inf --> 0.315225).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 2 cost time: 0.912667989730835\n","Epoch: 2, Steps: 32 | Train Loss: 0.8350534 Vali Loss: 0.4814787 Test Loss: 1.8607471\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 3 cost time: 0.9049592018127441\n","Epoch: 3, Steps: 32 | Train Loss: 0.5826675 Vali Loss: 0.3739506 Test Loss: 2.2311032\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 4 cost time: 0.9162673950195312\n","Epoch: 4, Steps: 32 | Train Loss: 0.5077363 Vali Loss: 0.3720078 Test Loss: 2.3843164\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 5 cost time: 0.9677867889404297\n","Epoch: 5, Steps: 32 | Train Loss: 0.4818631 Vali Loss: 0.3701051 Test Loss: 2.6526647\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 6 cost time: 0.9291515350341797\n","Epoch: 6, Steps: 32 | Train Loss: 0.4620603 Vali Loss: 0.3295387 Test Loss: 2.2717912\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 7 cost time: 0.9169721603393555\n","Epoch: 7, Steps: 32 | Train Loss: 0.4483706 Vali Loss: 0.3384618 Test Loss: 2.0076706\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 8 cost time: 0.907768964767456\n","Epoch: 8, Steps: 32 | Train Loss: 0.4230749 Vali Loss: 0.2282652 Test Loss: 1.7806791\n","Validation loss decreased (0.315225 --> 0.228265).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 9 cost time: 0.9154176712036133\n","Epoch: 9, Steps: 32 | Train Loss: 0.3903076 Vali Loss: 0.3267054 Test Loss: 2.2367630\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 10 cost time: 0.8909351825714111\n","Epoch: 10, Steps: 32 | Train Loss: 0.3736644 Vali Loss: 0.2661970 Test Loss: 1.8796746\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 11 cost time: 0.9206504821777344\n","Epoch: 11, Steps: 32 | Train Loss: 0.3382643 Vali Loss: 0.2108760 Test Loss: 1.7086240\n","Validation loss decreased (0.228265 --> 0.210876).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 12 cost time: 0.9456911087036133\n","Epoch: 12, Steps: 32 | Train Loss: 0.3256513 Vali Loss: 0.2485026 Test Loss: 1.8303103\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 13 cost time: 0.903496503829956\n","Epoch: 13, Steps: 32 | Train Loss: 0.3140573 Vali Loss: 0.2213576 Test Loss: 2.0033348\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 14 cost time: 0.8720419406890869\n","Epoch: 14, Steps: 32 | Train Loss: 0.2829287 Vali Loss: 0.2182558 Test Loss: 1.5949706\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 15 cost time: 0.9019980430603027\n","Epoch: 15, Steps: 32 | Train Loss: 0.2716275 Vali Loss: 0.2344767 Test Loss: 1.8824240\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 16 cost time: 0.9195504188537598\n","Epoch: 16, Steps: 32 | Train Loss: 0.2583540 Vali Loss: 0.2465172 Test Loss: 1.8250636\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 17 cost time: 0.9029183387756348\n","Epoch: 17, Steps: 32 | Train Loss: 0.2678369 Vali Loss: 0.2054026 Test Loss: 1.9495840\n","Validation loss decreased (0.210876 --> 0.205403).  Saving model ...\n","Updating learning rate to 0.0025\n","Epoch: 18 cost time: 0.9071569442749023\n","Epoch: 18, Steps: 32 | Train Loss: 0.2447377 Vali Loss: 0.2159140 Test Loss: 1.6623328\n","EarlyStopping counter: 1 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 19 cost time: 0.9037880897521973\n","Epoch: 19, Steps: 32 | Train Loss: 0.2346188 Vali Loss: 0.2102723 Test Loss: 1.6460593\n","EarlyStopping counter: 2 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 20 cost time: 0.929124116897583\n","Epoch: 20, Steps: 32 | Train Loss: 0.2282742 Vali Loss: 0.2279504 Test Loss: 1.7351880\n","EarlyStopping counter: 3 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 21 cost time: 0.9257886409759521\n","Epoch: 21, Steps: 32 | Train Loss: 0.2194771 Vali Loss: 0.2487024 Test Loss: 1.5916353\n","EarlyStopping counter: 4 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 22 cost time: 0.9105706214904785\n","Epoch: 22, Steps: 32 | Train Loss: 0.2139743 Vali Loss: 0.2447606 Test Loss: 1.7243066\n","EarlyStopping counter: 5 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 23 cost time: 0.9148142337799072\n","Epoch: 23, Steps: 32 | Train Loss: 0.2069680 Vali Loss: 0.2766914 Test Loss: 1.5804855\n","EarlyStopping counter: 6 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 24 cost time: 0.9115729331970215\n","Epoch: 24, Steps: 32 | Train Loss: 0.2090021 Vali Loss: 0.2655478 Test Loss: 1.7171752\n","EarlyStopping counter: 7 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 25 cost time: 0.9204888343811035\n","Epoch: 25, Steps: 32 | Train Loss: 0.2043951 Vali Loss: 0.2432350 Test Loss: 1.6508877\n","EarlyStopping counter: 8 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 26 cost time: 0.9170284271240234\n","Epoch: 26, Steps: 32 | Train Loss: 0.1982720 Vali Loss: 0.2357347 Test Loss: 1.6540734\n","EarlyStopping counter: 9 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 27 cost time: 0.9006927013397217\n","Epoch: 27, Steps: 32 | Train Loss: 0.1865432 Vali Loss: 0.2734922 Test Loss: 1.5913720\n","EarlyStopping counter: 10 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 28 cost time: 0.975712776184082\n","Epoch: 28, Steps: 32 | Train Loss: 0.1892373 Vali Loss: 0.2388439 Test Loss: 1.6224426\n","EarlyStopping counter: 11 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 29 cost time: 0.9159550666809082\n","Epoch: 29, Steps: 32 | Train Loss: 0.1823149 Vali Loss: 0.2545723 Test Loss: 1.7029120\n","EarlyStopping counter: 12 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 30 cost time: 0.9053845405578613\n","Epoch: 30, Steps: 32 | Train Loss: 0.1800617 Vali Loss: 0.2586895 Test Loss: 1.6953510\n","EarlyStopping counter: 13 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 31 cost time: 0.9143974781036377\n","Epoch: 31, Steps: 32 | Train Loss: 0.1823545 Vali Loss: 0.2730007 Test Loss: 1.6086380\n","EarlyStopping counter: 14 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 32 cost time: 0.8893170356750488\n","Epoch: 32, Steps: 32 | Train Loss: 0.1710912 Vali Loss: 0.2600424 Test Loss: 1.6011355\n","EarlyStopping counter: 15 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 33 cost time: 0.9517543315887451\n","Epoch: 33, Steps: 32 | Train Loss: 0.1709086 Vali Loss: 0.2747223 Test Loss: 1.6186001\n","EarlyStopping counter: 16 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 34 cost time: 0.9485514163970947\n","Epoch: 34, Steps: 32 | Train Loss: 0.1932060 Vali Loss: 0.2803452 Test Loss: 1.8244333\n","EarlyStopping counter: 17 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 35 cost time: 0.9702839851379395\n","Epoch: 35, Steps: 32 | Train Loss: 0.1815664 Vali Loss: 0.2836117 Test Loss: 1.5352013\n","EarlyStopping counter: 18 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 36 cost time: 0.9497852325439453\n","Epoch: 36, Steps: 32 | Train Loss: 0.1662641 Vali Loss: 0.2645909 Test Loss: 1.6342697\n","EarlyStopping counter: 19 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 37 cost time: 0.9029951095581055\n","Epoch: 37, Steps: 32 | Train Loss: 0.1705087 Vali Loss: 0.2990537 Test Loss: 1.9725206\n","EarlyStopping counter: 20 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 38 cost time: 0.9268949031829834\n","Epoch: 38, Steps: 32 | Train Loss: 0.1785233 Vali Loss: 0.2543526 Test Loss: 1.3649642\n","EarlyStopping counter: 21 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 39 cost time: 0.9038200378417969\n","Epoch: 39, Steps: 32 | Train Loss: 0.1798713 Vali Loss: 0.2738811 Test Loss: 1.6185893\n","EarlyStopping counter: 22 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 40 cost time: 0.928485631942749\n","Epoch: 40, Steps: 32 | Train Loss: 0.1626802 Vali Loss: 0.3011096 Test Loss: 1.7795899\n","EarlyStopping counter: 23 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 41 cost time: 0.9568281173706055\n","Epoch: 41, Steps: 32 | Train Loss: 0.1607462 Vali Loss: 0.2709543 Test Loss: 1.5876071\n","EarlyStopping counter: 24 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 42 cost time: 0.9725747108459473\n","Epoch: 42, Steps: 32 | Train Loss: 0.1591136 Vali Loss: 0.2648456 Test Loss: 1.7668238\n","EarlyStopping counter: 25 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 43 cost time: 0.9322671890258789\n","Epoch: 43, Steps: 32 | Train Loss: 0.1601435 Vali Loss: 0.2744941 Test Loss: 1.4740005\n","EarlyStopping counter: 26 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 44 cost time: 0.9146006107330322\n","Epoch: 44, Steps: 32 | Train Loss: 0.1652558 Vali Loss: 0.2527303 Test Loss: 1.6749784\n","EarlyStopping counter: 27 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 45 cost time: 0.8906247615814209\n","Epoch: 45, Steps: 32 | Train Loss: 0.1652206 Vali Loss: 0.2735853 Test Loss: 1.7637202\n","EarlyStopping counter: 28 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 46 cost time: 0.9210238456726074\n","Epoch: 46, Steps: 32 | Train Loss: 0.1555790 Vali Loss: 0.2715374 Test Loss: 1.5274903\n","EarlyStopping counter: 29 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 47 cost time: 0.943972110748291\n","Epoch: 47, Steps: 32 | Train Loss: 0.1538721 Vali Loss: 0.2752942 Test Loss: 1.5108261\n","EarlyStopping counter: 30 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 48 cost time: 0.9419879913330078\n","Epoch: 48, Steps: 32 | Train Loss: 0.1457031 Vali Loss: 0.2524111 Test Loss: 1.8122227\n","EarlyStopping counter: 31 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 49 cost time: 0.9285047054290771\n","Epoch: 49, Steps: 32 | Train Loss: 0.1521311 Vali Loss: 0.2622594 Test Loss: 1.6683414\n","EarlyStopping counter: 32 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 50 cost time: 1.02341890335083\n","Epoch: 50, Steps: 32 | Train Loss: 0.1497465 Vali Loss: 0.2595454 Test Loss: 1.7118647\n","EarlyStopping counter: 33 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 51 cost time: 0.9320394992828369\n","Epoch: 51, Steps: 32 | Train Loss: 0.1460221 Vali Loss: 0.2674212 Test Loss: 1.6207383\n","EarlyStopping counter: 34 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 52 cost time: 0.937300443649292\n","Epoch: 52, Steps: 32 | Train Loss: 0.1421456 Vali Loss: 0.2859557 Test Loss: 1.6575124\n","EarlyStopping counter: 35 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 53 cost time: 0.8839199542999268\n","Epoch: 53, Steps: 32 | Train Loss: 0.1394435 Vali Loss: 0.2728826 Test Loss: 1.5670291\n","EarlyStopping counter: 36 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 54 cost time: 0.9288654327392578\n","Epoch: 54, Steps: 32 | Train Loss: 0.1344976 Vali Loss: 0.2704649 Test Loss: 1.5656459\n","EarlyStopping counter: 37 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 55 cost time: 0.8968329429626465\n","Epoch: 55, Steps: 32 | Train Loss: 0.1451585 Vali Loss: 0.2702686 Test Loss: 1.7492046\n","EarlyStopping counter: 38 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 56 cost time: 0.9719681739807129\n","Epoch: 56, Steps: 32 | Train Loss: 0.1356055 Vali Loss: 0.2878220 Test Loss: 1.5119020\n","EarlyStopping counter: 39 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 57 cost time: 0.9300296306610107\n","Epoch: 57, Steps: 32 | Train Loss: 0.1408251 Vali Loss: 0.2798977 Test Loss: 1.7214054\n","EarlyStopping counter: 40 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 58 cost time: 0.9533145427703857\n","Epoch: 58, Steps: 32 | Train Loss: 0.1466044 Vali Loss: 0.2773366 Test Loss: 1.4321523\n","EarlyStopping counter: 41 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 59 cost time: 0.9265291690826416\n","Epoch: 59, Steps: 32 | Train Loss: 0.1471422 Vali Loss: 0.2773894 Test Loss: 1.7415863\n","EarlyStopping counter: 42 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 60 cost time: 0.9195506572723389\n","Epoch: 60, Steps: 32 | Train Loss: 0.1403883 Vali Loss: 0.2793745 Test Loss: 1.6316175\n","EarlyStopping counter: 43 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 61 cost time: 0.9270806312561035\n","Epoch: 61, Steps: 32 | Train Loss: 0.1306129 Vali Loss: 0.2590770 Test Loss: 1.6637158\n","EarlyStopping counter: 44 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 62 cost time: 0.9197750091552734\n","Epoch: 62, Steps: 32 | Train Loss: 0.1307798 Vali Loss: 0.2814596 Test Loss: 1.4830284\n","EarlyStopping counter: 45 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 63 cost time: 0.9841876029968262\n","Epoch: 63, Steps: 32 | Train Loss: 0.1358081 Vali Loss: 0.2603873 Test Loss: 1.7656932\n","EarlyStopping counter: 46 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 64 cost time: 0.9967992305755615\n","Epoch: 64, Steps: 32 | Train Loss: 0.1319761 Vali Loss: 0.2720235 Test Loss: 1.6054726\n","EarlyStopping counter: 47 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 65 cost time: 0.9518764019012451\n","Epoch: 65, Steps: 32 | Train Loss: 0.1334727 Vali Loss: 0.2684436 Test Loss: 1.6107826\n","EarlyStopping counter: 48 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 66 cost time: 0.9155025482177734\n","Epoch: 66, Steps: 32 | Train Loss: 0.1340084 Vali Loss: 0.2822226 Test Loss: 1.6247892\n","EarlyStopping counter: 49 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 67 cost time: 0.9558148384094238\n","Epoch: 67, Steps: 32 | Train Loss: 0.1313904 Vali Loss: 0.3062395 Test Loss: 1.5755031\n","EarlyStopping counter: 50 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 68 cost time: 0.9355759620666504\n","Epoch: 68, Steps: 32 | Train Loss: 0.1292724 Vali Loss: 0.2870330 Test Loss: 1.5192813\n","EarlyStopping counter: 51 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 69 cost time: 0.8915929794311523\n","Epoch: 69, Steps: 32 | Train Loss: 0.1240862 Vali Loss: 0.2785679 Test Loss: 1.5701548\n","EarlyStopping counter: 52 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 70 cost time: 0.9306490421295166\n","Epoch: 70, Steps: 32 | Train Loss: 0.1287659 Vali Loss: 0.2938476 Test Loss: 1.4967711\n","EarlyStopping counter: 53 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 71 cost time: 0.9542882442474365\n","Epoch: 71, Steps: 32 | Train Loss: 0.1318797 Vali Loss: 0.2699538 Test Loss: 1.6199147\n","EarlyStopping counter: 54 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 72 cost time: 0.9808058738708496\n","Epoch: 72, Steps: 32 | Train Loss: 0.1288647 Vali Loss: 0.3078246 Test Loss: 1.4944388\n","EarlyStopping counter: 55 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 73 cost time: 0.936969518661499\n","Epoch: 73, Steps: 32 | Train Loss: 0.1345152 Vali Loss: 0.2555885 Test Loss: 1.7998389\n","EarlyStopping counter: 56 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 74 cost time: 0.9182491302490234\n","Epoch: 74, Steps: 32 | Train Loss: 0.1293357 Vali Loss: 0.3729296 Test Loss: 1.3090202\n","EarlyStopping counter: 57 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 75 cost time: 0.9265720844268799\n","Epoch: 75, Steps: 32 | Train Loss: 0.1367055 Vali Loss: 0.2639685 Test Loss: 1.6150182\n","EarlyStopping counter: 58 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 76 cost time: 0.9102654457092285\n","Epoch: 76, Steps: 32 | Train Loss: 0.1394791 Vali Loss: 0.3177732 Test Loss: 1.6571016\n","EarlyStopping counter: 59 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 77 cost time: 0.9305860996246338\n","Epoch: 77, Steps: 32 | Train Loss: 0.1263229 Vali Loss: 0.2740482 Test Loss: 1.6693124\n","EarlyStopping counter: 60 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 78 cost time: 0.9522686004638672\n","Epoch: 78, Steps: 32 | Train Loss: 0.1202238 Vali Loss: 0.2731009 Test Loss: 1.5866330\n","EarlyStopping counter: 61 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 79 cost time: 0.9642581939697266\n","Epoch: 79, Steps: 32 | Train Loss: 0.1250522 Vali Loss: 0.3078012 Test Loss: 1.4418154\n","EarlyStopping counter: 62 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 80 cost time: 0.9171407222747803\n","Epoch: 80, Steps: 32 | Train Loss: 0.1173576 Vali Loss: 0.2745707 Test Loss: 1.6500828\n","EarlyStopping counter: 63 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 81 cost time: 0.9162147045135498\n","Epoch: 81, Steps: 32 | Train Loss: 0.1193281 Vali Loss: 0.3334209 Test Loss: 1.4425765\n","EarlyStopping counter: 64 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 82 cost time: 0.9219205379486084\n","Epoch: 82, Steps: 32 | Train Loss: 0.1198952 Vali Loss: 0.2584318 Test Loss: 1.6812849\n","EarlyStopping counter: 65 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 83 cost time: 0.959693431854248\n","Epoch: 83, Steps: 32 | Train Loss: 0.1161710 Vali Loss: 0.2521903 Test Loss: 1.4936666\n","EarlyStopping counter: 66 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 84 cost time: 0.9375078678131104\n","Epoch: 84, Steps: 32 | Train Loss: 0.1188645 Vali Loss: 0.3126626 Test Loss: 1.4060602\n","EarlyStopping counter: 67 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 85 cost time: 0.9412660598754883\n","Epoch: 85, Steps: 32 | Train Loss: 0.1193056 Vali Loss: 0.2937368 Test Loss: 1.4989837\n","EarlyStopping counter: 68 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 86 cost time: 0.9832823276519775\n","Epoch: 86, Steps: 32 | Train Loss: 0.1160458 Vali Loss: 0.3076496 Test Loss: 1.5349451\n","EarlyStopping counter: 69 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 87 cost time: 0.9355270862579346\n","Epoch: 87, Steps: 32 | Train Loss: 0.1167185 Vali Loss: 0.2910698 Test Loss: 1.5668360\n","EarlyStopping counter: 70 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 88 cost time: 0.9391274452209473\n","Epoch: 88, Steps: 32 | Train Loss: 0.1194381 Vali Loss: 0.2832551 Test Loss: 1.5340834\n","EarlyStopping counter: 71 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 89 cost time: 0.9397552013397217\n","Epoch: 89, Steps: 32 | Train Loss: 0.1160796 Vali Loss: 0.3288684 Test Loss: 1.3987334\n","EarlyStopping counter: 72 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 90 cost time: 0.9514269828796387\n","Epoch: 90, Steps: 32 | Train Loss: 0.1132913 Vali Loss: 0.2769896 Test Loss: 1.4996777\n","EarlyStopping counter: 73 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 91 cost time: 0.9300050735473633\n","Epoch: 91, Steps: 32 | Train Loss: 0.1144669 Vali Loss: 0.3153760 Test Loss: 1.3867177\n","EarlyStopping counter: 74 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 92 cost time: 0.9118969440460205\n","Epoch: 92, Steps: 32 | Train Loss: 0.1142066 Vali Loss: 0.2933000 Test Loss: 1.6440263\n","EarlyStopping counter: 75 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 93 cost time: 0.9592530727386475\n","Epoch: 93, Steps: 32 | Train Loss: 0.1154916 Vali Loss: 0.2987967 Test Loss: 1.5078480\n","EarlyStopping counter: 76 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 94 cost time: 0.9816138744354248\n","Epoch: 94, Steps: 32 | Train Loss: 0.1129860 Vali Loss: 0.3172421 Test Loss: 1.4074199\n","EarlyStopping counter: 77 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 95 cost time: 0.9258050918579102\n","Epoch: 95, Steps: 32 | Train Loss: 0.1132612 Vali Loss: 0.2865085 Test Loss: 1.4845257\n","EarlyStopping counter: 78 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 96 cost time: 0.9531712532043457\n","Epoch: 96, Steps: 32 | Train Loss: 0.1091261 Vali Loss: 0.2786808 Test Loss: 1.4460056\n","EarlyStopping counter: 79 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 97 cost time: 0.9453887939453125\n","Epoch: 97, Steps: 32 | Train Loss: 0.1075199 Vali Loss: 0.3302730 Test Loss: 1.4085169\n","EarlyStopping counter: 80 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 98 cost time: 0.9268450736999512\n","Epoch: 98, Steps: 32 | Train Loss: 0.1108792 Vali Loss: 0.3026162 Test Loss: 1.5594348\n","EarlyStopping counter: 81 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 99 cost time: 0.9500250816345215\n","Epoch: 99, Steps: 32 | Train Loss: 0.1119944 Vali Loss: 0.3248155 Test Loss: 1.3761001\n","EarlyStopping counter: 82 out of 100\n","Updating learning rate to 0.0025\n","Epoch: 100 cost time: 0.9544203281402588\n","Epoch: 100, Steps: 32 | Train Loss: 0.1158177 Vali Loss: 0.3035620 Test Loss: 1.5294828\n","EarlyStopping counter: 83 out of 100\n","Updating learning rate to 0.0025\n",">>>>>>>testing : national_illness_PatchTST_custom_ftM_sl104_ll48_pl60_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 134\n","mse:1.949583888053894, mae:0.9578037858009338, rse:0.6671997904777527\n",">>>>>>>predicting : national_illness_PatchTST_custom_ftM_sl104_ll48_pl60_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","pred 1\n"]}],"source":["arg_seq_len=104\n","arg_pred_len = 24\n","model_name='PatchTST'\n","root_path_name='./dataset/'\n","data_path_name='national_illness.csv'\n","model_id_name='national_illness'\n","data_name='custom'\n","random_seed=2021\n","\n","class Args:\n","    random_seed = 2021\n","\n","    is_training = 1\n","    model_id = model_id_name\n","    model = model_name\n","\n","    data = data_name\n","    root_path = root_path_name\n","    data_path = data_path_name\n","    features = 'M'\n","    target = 'OT'\n","    freq = 'h'\n","    checkpoints = './checkpoints/'\n","\n","    seq_len = arg_seq_len\n","    label_len = 48\n","    pred_len = arg_pred_len\n","\n","    fc_dropout= 0.3\n","    head_dropout = 0.0\n","    patch_len = 24\n","    stride = 2\n","    padding_patch = 'end'\n","    revin = 1\n","    affine = 0\n","    subtract_last = 0\n","    decomposition = 0\n","    kernel_size = 25\n","    individual = 0\n","\n","    embed_type = 0\n","    enc_in = 7\n","    dec_in = 7\n","    c_out = 7\n","    d_model = 16\n","    n_heads = 4\n","    e_layers = 3\n","    d_layers = 1\n","    d_ff = 128\n","    moving_avg = 25\n","    factor = 1\n","    distil = True\n","    dropout = 0.3\n","    embed = 'timeF'\n","    activation = 'gelu'\n","    output_attention = False\n","    do_predict = True\n","\n","    num_workers = 10\n","    itr = 1\n","    train_epochs = 100\n","    batch_size = 16\n","    patience = 100\n","    learning_rate = 0.0025\n","    des = 'Exp'\n","    loss = 'MSE'\n","    lradj = 'constant'\n","    pct_start = 0.3\n","    use_amp = False\n","\n","    use_gpu = True\n","    gpu = 0\n","    use_multi_gpu = False\n","    devices = '0'\n","    test_flop = False\n","\n","args = Args();\n","\n","# random seed\n","fix_seed = args.random_seed\n","random.seed(fix_seed)\n","torch.manual_seed(fix_seed)\n","np.random.seed(fix_seed)\n","\n","args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.dvices = args.devices.replace(' ', '')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","print('Args in experiment:')\n","\n","for i in [24, 36, 48, 60]:\n","  Exp = Exp_Main\n","  args.pred_len = i\n","  print(f'==================== Now pred_len : {i} ============================ \\n\\n ')\n","\n","  if args.is_training:\n","      for ii in range(args.itr):\n","          # setting record of experiments\n","          setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n","              args.model_id,\n","              args.model,\n","              args.data,\n","              args.features,\n","              args.seq_len,\n","              args.label_len,\n","              args.pred_len,\n","              args.d_model,\n","              args.n_heads,\n","              args.e_layers,\n","              args.d_layers,\n","              args.d_ff,\n","              args.factor,\n","              args.embed,\n","              args.distil,\n","              args.des,ii)\n","\n","          exp = Exp(args)  # set experiments\n","          print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","          exp.train(setting)\n","\n","          print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","          exp.test(setting)\n","\n","          if args.do_predict:\n","              print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","              exp.predict(setting, True)\n","\n","          torch.cuda.empty_cache()\n","  else:\n","      ii = 0\n","      setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n","                                                                                                  args.model,\n","                                                                                                  args.data,\n","                                                                                                  args.features,\n","                                                                                                  args.seq_len,\n","                                                                                                  args.label_len,\n","                                                                                                  args.pred_len,\n","                                                                                                  args.d_model,\n","                                                                                                  args.n_heads,\n","                                                                                                  args.e_layers,\n","                                                                                                  args.d_layers,\n","                                                                                                  args.d_ff,\n","                                                                                                  args.factor,\n","                                                                                                  args.embed,\n","                                                                                                  args.distil,\n","                                                                                                  args.des, ii)\n","\n","      exp = Exp(args)  # set experiments\n","      print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","      exp.test(setting, test=1)\n","      torch.cuda.empty_cache()\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOy+xglRpivMxr0ERomp3cr","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
